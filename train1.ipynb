{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f83d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Graduation\n",
      "1: PhD\n",
      "2: Master\n",
      "3: Basic\n",
      "4: 2n Cycle\n",
      "0: Single\n",
      "1: Together\n",
      "2: Married\n",
      "3: Divorced\n",
      "4: Widow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\train.csv')\n",
    "test = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\test.csv')\n",
    "\n",
    "data.replace('Alone', 'Single', inplace=True)\n",
    "test.replace('Absurd', 'Single', inplace=True)\n",
    "data.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('YOLO', 'Single', inplace=True)\n",
    "# test.replace('Alone', 'Single', inplace=True)\n",
    "# data.replace('Together', 'Married', inplace=True)\n",
    "# test.replace('Together', 'Married', inplace=True)\n",
    "\n",
    "# test.replace('Basic', '2n Cycle', inplace=True)\n",
    "# data.replace('Basic', '2n Cycle', inplace=True)\n",
    "# test.replace('Widow', 'Divorced', inplace=True)\n",
    "# data.replace('Widow', 'Divorced', inplace=True)\n",
    "\n",
    "data['Dt_Customer_1'] = pd.to_datetime(data['Dt_Customer'],format='mixed')\n",
    "data['Dt_Customer_1'] = data['Dt_Customer_1']-min(data['Dt_Customer_1'])\n",
    "data['Dates']=data['Dt_Customer_1'].dt.days\n",
    "\n",
    "test['Dt_Customer_1'] = pd.to_datetime(test['Dt_Customer'],format='mixed')\n",
    "test['Dt_Customer_1'] = test['Dt_Customer_1']-min(test['Dt_Customer_1'])\n",
    "test['Dates']=test['Dt_Customer_1'].dt.days\n",
    "Education = {}\n",
    "Marital_status = {}\n",
    "A = data['Education'].unique()\n",
    "B = data['Marital_Status'].unique()\n",
    "# A = test['Education'].unique()\n",
    "# B = test['Marital_Status'].unique()\n",
    "for i, category in enumerate(A):\n",
    "    l = [0]*len(A)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Education[category] = i\n",
    "for i, category in enumerate(B):\n",
    "    l = [0]*len(B)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Marital_status[category] = i\n",
    "data['Education'] = data['Education'].map(Education)\n",
    "test['Education'] = test['Education'].map(Education)\n",
    "data['Marital_Status'] = data['Marital_Status'].map(Marital_status)\n",
    "test['Marital_Status'] = test['Marital_Status'].map(Marital_status)\n",
    "\n",
    "# data = pd.get_dummies(data, columns=['Marital_Status', 'Education'], drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=['Marital_Status', 'Education'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886dc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype          \n",
      "---  ------               --------------  -----          \n",
      " 0   ID                   1567 non-null   int64          \n",
      " 1   Year_Birth           1567 non-null   int64          \n",
      " 2   Education            1567 non-null   int64          \n",
      " 3   Marital_Status       1567 non-null   int64          \n",
      " 4   Income               1550 non-null   float64        \n",
      " 5   Kidhome              1567 non-null   int64          \n",
      " 6   Teenhome             1567 non-null   int64          \n",
      " 7   Dt_Customer          1567 non-null   object         \n",
      " 8   Recency              1567 non-null   int64          \n",
      " 9   MntWines             1544 non-null   float64        \n",
      " 10  MntFruits            1567 non-null   int64          \n",
      " 11  MntMeatProducts      1561 non-null   float64        \n",
      " 12  MntFishProducts      1567 non-null   int64          \n",
      " 13  MntSweetProducts     1567 non-null   int64          \n",
      " 14  MntGoldProds         1555 non-null   float64        \n",
      " 15  NumDealsPurchases    1567 non-null   int64          \n",
      " 16  NumWebPurchases      1567 non-null   int64          \n",
      " 17  NumCatalogPurchases  1567 non-null   int64          \n",
      " 18  NumStorePurchases    1567 non-null   int64          \n",
      " 19  NumWebVisitsMonth    1567 non-null   int64          \n",
      " 20  AcceptedCmp3         1567 non-null   int64          \n",
      " 21  AcceptedCmp4         1567 non-null   int64          \n",
      " 22  AcceptedCmp5         1567 non-null   int64          \n",
      " 23  AcceptedCmp1         1567 non-null   int64          \n",
      " 24  AcceptedCmp2         1567 non-null   int64          \n",
      " 25  Complain             1567 non-null   int64          \n",
      " 26  Z_CostContact        1567 non-null   int64          \n",
      " 27  Z_Revenue            1567 non-null   int64          \n",
      " 28  Target               1567 non-null   int64          \n",
      " 29  Dt_Customer_1        1567 non-null   timedelta64[ns]\n",
      " 30  Dates                1567 non-null   int64          \n",
      "dtypes: float64(4), int64(25), object(1), timedelta64[ns](1)\n",
      "memory usage: 379.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ca3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categorical_cols = ['Education', 'Marital_Status']\n",
    "numerical_cols = [\n",
    "    'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'Complain',\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "    'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
    "    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4',\n",
    "    'AcceptedCmp5', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumWebVisitsMonth', 'Dates'\n",
    "]\n",
    "lists = [\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    # 'Marital_Status_Married',\n",
    "    # 'Marital_Status_Single',\n",
    "    # 'Education_Graduation',\n",
    "    # 'Education_Master',\n",
    "    # 'Education_PhD',\n",
    "    'Marital_Status',\n",
    "    'Education'\n",
    "    # 'Target'\n",
    "]\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col='Target'):\n",
    "        self.X = df[feature_cols].values.astype('float32')\n",
    "        self.y = df[target_col].values.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.X[idx], dtype=torch.float),\n",
    "            'target': torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        }\n",
    "        # return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n",
    "\n",
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomerDataset(data, lists, target_col='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8387d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImputationLayer(nn.Module):\n",
    "    def __init__(self, default_values):\n",
    "        super(ImputationLayer, self).__init__()\n",
    "        self.impute = nn.Parameter(torch.tensor(default_values, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.isnan(x)\n",
    "        x[mask] = self.impute.expand(x.shape[0], -1)[mask]\n",
    "        return x\n",
    "\n",
    "class TrainableScaler(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(TrainableScaler, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(num_features))\n",
    "        self.std = nn.Parameter(torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "class MarketResearchModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, emb_sizes = [3,4], layers_list=[64, 32, 1], default_values=default_values, drop = 0.2):\n",
    "        super(MarketResearchModel, self).__init__()\n",
    "\n",
    "        # Imputation and scaling layers\n",
    "        self.imputer = ImputationLayer(default_values)  # Replace with actual means\n",
    "        self.scaler = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embedding_1 = nn.Embedding(num_embeddings=emb_sizes[0], embedding_dim=10)  # for class feature -6 to -3\n",
    "        self.embedding_2 = nn.Embedding(num_embeddings=emb_sizes[1], embedding_dim=10)  # for class feature -3 to -1\n",
    "\n",
    "        # Input size for FFN\n",
    "        input_size = num_numeric_features + 20\n",
    "\n",
    "        # Build feedforward layers dynamically\n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        for out_dim in layers_list:\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                layers.append(nn.BatchNorm1d(out_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        if layers_list[-1] != 1:\n",
    "            layers.append(nn.Linear(in_dim, 1))\n",
    "        # layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.ff = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_numeric = x[:, :-2]\n",
    "        # x_cat1 = x[:, -5:-3].long()\n",
    "        # x_cat2 = x[:, -3:-1].long()\n",
    "        x_cat1 = x[:,-2:-1].long()\n",
    "        x_cat2 = x[:,-1:].long()\n",
    "        # print(x_numeric.shape, x_cat1.shape, x_cat2.shape)\n",
    "        x_numeric = self.imputer(x_numeric)\n",
    "        x_numeric = self.scaler(x_numeric)\n",
    "\n",
    "        emb1 = self.embedding_1(x_cat1).squeeze(1)\n",
    "        emb2 = self.embedding_2(x_cat2).squeeze(1)\n",
    "        # print(emb1.shape, emb2.shape, x_numeric.shape)\n",
    "        x = torch.cat([x_numeric, emb1, emb2], dim=1)\n",
    "        return self.ff(x).squeeze(1)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GLULayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GLULayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim * 2)\n",
    "        self.bn = nn.BatchNorm1d(output_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.fc(x))\n",
    "        out, gate = x.chunk(2, dim=-1)\n",
    "        return out * torch.sigmoid(gate)\n",
    "\n",
    "class FeatureTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.bn(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.relu(x + res)\n",
    "\n",
    "class TabInspiredMarketModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_numeric_features,\n",
    "        emb_sizes=[3,4],\n",
    "        default_values=default_values,\n",
    "        hidden_dim=128,\n",
    "        depth=4,\n",
    "        layers_list=[64,32,1],\n",
    "        drop=0.6\n",
    "    ):\n",
    "        super(TabInspiredMarketModel, self).__init__()\n",
    "\n",
    "        # Imputation + scaling\n",
    "        self.imputer = ImputationLayer(default_values)\n",
    "        self.scaler  = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # Embeddings\n",
    "        self.embedding_1 = nn.Embedding(emb_sizes[0], 5)\n",
    "        self.embedding_2 = nn.Embedding(emb_sizes[1], 5)\n",
    "\n",
    "        # Initial GLU block\n",
    "        input_dim = num_numeric_features + 10\n",
    "        self.glu_layer = GLULayer(input_dim, hidden_dim)\n",
    "\n",
    "        # TabNet‑style transformer blocks\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[FeatureTransformerBlock(hidden_dim) for _ in range(depth)]\n",
    "        )\n",
    "\n",
    "        # Dynamically built FF head\n",
    "        ff_layers = []\n",
    "        in_dim = hidden_dim\n",
    "        for out_dim in layers_list:\n",
    "            ff_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                ff_layers.append(nn.BatchNorm1d(out_dim))\n",
    "                ff_layers.append(nn.ReLU())\n",
    "                ff_layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        # if the last layer isn’t single‑unit, add one more\n",
    "        if layers_list[-1] != 1:\n",
    "            ff_layers.append(nn.Linear(in_dim, 1))\n",
    "        # ff_layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.output = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # split numeric / cat\n",
    "        x_num  = x[:, :-2]\n",
    "        cat1   = x[:, -2:-1].long()\n",
    "        cat2   = x[:, -1:  ].long()\n",
    "\n",
    "        # impute + scale\n",
    "        x_num = self.imputer(x_num)\n",
    "        x_num = self.scaler(x_num)\n",
    "\n",
    "        # embed cats\n",
    "        e1 = self.embedding_1(cat1).squeeze(1)\n",
    "        e2 = self.embedding_2(cat2).squeeze(1)\n",
    "\n",
    "        # concat\n",
    "        x = torch.cat([x_num, e1, e2], dim=1)\n",
    "\n",
    "        # GLU + transformer blocks\n",
    "        x = self.glu_layer(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "\n",
    "        # final head\n",
    "        return self.output(x).squeeze(1)\n",
    "\n",
    "class TabInspiredMarketModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_numeric_features,\n",
    "        emb_sizes=[3,4],\n",
    "        default_values=default_values,\n",
    "        hidden_dim=128,\n",
    "        depth=4,\n",
    "        layers_list=[64,32,1],\n",
    "        drop=0.3,\n",
    "        n_heads=8\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Imputation & Scaling\n",
    "        self.imputer = ImputationLayer(default_values)\n",
    "        self.scaler  = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # 2) Categoricals → Embeddings\n",
    "        self.embedding_1 = nn.Embedding(emb_sizes[0], 5)\n",
    "        self.embedding_2 = nn.Embedding(emb_sizes[1], 5)\n",
    "\n",
    "        # 3) Project each scalar feature → hidden_dim token\n",
    "        self.num_proj  = nn.Linear(1,     hidden_dim)\n",
    "        self.cat_proj1 = nn.Linear(5,     hidden_dim)\n",
    "        self.cat_proj2 = nn.Linear(5,     hidden_dim)\n",
    "\n",
    "        # 4) Self‑Attention across the (N_numeric + 2) tokens\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=n_heads,\n",
    "            dropout=drop,\n",
    "            batch_first=False  # nn.MultiheadAttention defaults to (seq_len, batch, embed_dim)\n",
    "        )\n",
    "\n",
    "        # 5) GLU + TabNet‑style blocks\n",
    "        self.glu_layer         = GLULayer(hidden_dim, hidden_dim)\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[FeatureTransformerBlock(hidden_dim) for _ in range(depth)]\n",
    "        )\n",
    "\n",
    "        # 6) Dynamically built FFN head\n",
    "        ff_layers = []\n",
    "        in_dim = hidden_dim\n",
    "        for out_dim in layers_list:\n",
    "            ff_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                ff_layers.append(nn.BatchNorm1d(out_dim))\n",
    "                ff_layers.append(nn.ReLU())\n",
    "                ff_layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        if layers_list[-1] != 1:\n",
    "            ff_layers.append(nn.Linear(in_dim, 1))\n",
    "        self.output = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split numeric vs. categorical indices\n",
    "        x_num = x[:, :-2]                     # [B, N_num]\n",
    "        cat1  = x[:, -2:-1].long()            # [B, 1]\n",
    "        cat2  = x[:, -1:  ].long()            # [B, 1]\n",
    "\n",
    "        # 1) Impute & scale\n",
    "        x_num = self.imputer(x_num)           # [B, N_num]\n",
    "        x_num = self.scaler(x_num)            # [B, N_num]\n",
    "\n",
    "        # 2) Embed categories\n",
    "        e1 = self.embedding_1(cat1).squeeze(1)  # [B, 5]\n",
    "        e2 = self.embedding_2(cat2).squeeze(1)  # [B, 5]\n",
    "\n",
    "        # 3) Build token sequence\n",
    "        num_tokens = self.num_proj(x_num.unsqueeze(-1))  # [B, N_num, H]\n",
    "        c1_token   = self.cat_proj1(e1).unsqueeze(1)     # [B, 1, H]\n",
    "        c2_token   = self.cat_proj2(e2).unsqueeze(1)     # [B, 1, H]\n",
    "\n",
    "        tokens = torch.cat([num_tokens, c1_token, c2_token], dim=1)  # [B, N_num+2, H]\n",
    "        tokens_t = tokens.transpose(0, 1)                            # [seq_len, B, H]\n",
    "\n",
    "        # 4) Self-attention\n",
    "        attn_out, _ = self.attention(tokens_t, tokens_t, tokens_t)  # [seq_len, B, H]\n",
    "        x = attn_out.mean(dim=0)                                    # [B, H]\n",
    "\n",
    "        # 5) GLU + Transformer blocks\n",
    "        x = self.glu_layer(x)                                       # [B, H]\n",
    "        x = self.transformer_blocks(x)                              # [B, H]\n",
    "\n",
    "        # 6) Final FF head\n",
    "        return self.output(x).squeeze(1)                            # [B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "408b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketResearchModel = TabInspiredMarketModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0381df59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TabInspiredMarketModel.__init__(self, num_numeric_features, emb_sizes=[3, 4], default_values=Year_Birth              1968.838545\n",
       "Income                 52024.465806\n",
       "Kidhome                    0.449904\n",
       "Teenhome                   0.499681\n",
       "Dates                    549.746011\n",
       "Recency                   49.345884\n",
       "MntWines                 304.301813\n",
       "MntFruits                 25.941289\n",
       "MntMeatProducts          165.313901\n",
       "MntFishProducts           37.271219\n",
       "MntSweetProducts          27.125080\n",
       "MntGoldProds              44.187781\n",
       "NumWebPurchases            4.032546\n",
       "NumCatalogPurchases        2.674537\n",
       "NumStorePurchases          5.776005\n",
       "NumDealsPurchases          2.332482\n",
       "NumWebVisitsMonth          5.325463\n",
       "AcceptedCmp1               0.063178\n",
       "AcceptedCmp2               0.012125\n",
       "AcceptedCmp3               0.072112\n",
       "AcceptedCmp4               0.076579\n",
       "AcceptedCmp5               0.070198\n",
       "Complain                   0.010211\n",
       "dtype: float64, hidden_dim=128, depth=4, layers_list=[64, 32, 1], drop=0.3, n_heads=8)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarketResearchModel.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e77973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-2]]\n",
    "model = MarketResearchModel(num_numeric_features=len(lists)-2, emb_sizes=[3,4], layers_list=[64, 32, 1], default_values=default_values).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27ed6e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "TabInspiredMarketModel                   [3, 25]                   [3]                       --                        --                        --\n",
       "├─ImputationLayer: 1-1                   [3, 23]                   [3, 23]                   23                        --                        --\n",
       "├─TrainableScaler: 1-2                   [3, 23]                   [3, 23]                   46                        --                        --\n",
       "├─Embedding: 1-3                         [3, 1]                    [3, 1, 5]                 15                        --                        45\n",
       "├─Embedding: 1-4                         [3, 1]                    [3, 1, 5]                 20                        --                        60\n",
       "├─Linear: 1-5                            [3, 23, 1]                [3, 23, 128]              256                       --                        768\n",
       "├─Linear: 1-6                            [3, 5]                    [3, 128]                  768                       --                        2,304\n",
       "├─Linear: 1-7                            [3, 5]                    [3, 128]                  768                       --                        2,304\n",
       "├─MultiheadAttention: 1-8                [25, 3, 128]              [25, 3, 128]              66,048                    --                        --\n",
       "├─GLULayer: 1-9                          [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    └─Linear: 2-1                       [3, 128]                  [3, 256]                  33,024                    --                        99,072\n",
       "│    └─BatchNorm1d: 2-2                  [3, 256]                  [3, 256]                  512                       --                        1,536\n",
       "├─Sequential: 1-10                       [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    └─FeatureTransformerBlock: 2-3      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-1                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-2             [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-3                 [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-4                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-4      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-5                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-6             [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-7                 [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-8                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-5      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-9                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-10            [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-11                [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-12                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-6      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-13                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-14            [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-15                [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-16                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "├─Sequential: 1-11                       [3, 128]                  [3, 1]                    --                        --                        --\n",
       "│    └─Linear: 2-7                       [3, 128]                  [3, 64]                   8,256                     --                        24,768\n",
       "│    └─BatchNorm1d: 2-8                  [3, 64]                   [3, 64]                   128                       --                        384\n",
       "│    └─ReLU: 2-9                         [3, 64]                   [3, 64]                   --                        --                        --\n",
       "│    └─Dropout: 2-10                     [3, 64]                   [3, 64]                   --                        --                        --\n",
       "│    └─Linear: 2-11                      [3, 64]                   [3, 32]                   2,080                     --                        6,240\n",
       "│    └─BatchNorm1d: 2-12                 [3, 32]                   [3, 32]                   64                        --                        192\n",
       "│    └─ReLU: 2-13                        [3, 32]                   [3, 32]                   --                        --                        --\n",
       "│    └─Dropout: 2-14                     [3, 32]                   [3, 32]                   --                        --                        --\n",
       "│    └─Linear: 2-15                      [3, 32]                   [3, 1]                    33                        --                        99\n",
       "=====================================================================================================================================================================\n",
       "Total params: 245,161\n",
       "Trainable params: 245,161\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.54\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.13\n",
       "Params size (MB): 0.72\n",
       "Estimated Total Size (MB): 0.85\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "summary(model, input_size=(3, len(lists)), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06a631e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21020\\2073335113.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m     from . import (\n\u001b[0;32m     81\u001b[0m         \u001b[0m__check_build\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     __all__ = [\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Make _safe_indexing importable from here for backward compat as this particular\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchunk_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mInvalidParameterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_isfinite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFiniteStatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy_isfinite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"array_api_compat.numpy\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    606\u001b[0m \"\"\"  # noqa: E501\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 610\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_morestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Import unused here but needs to stay until end of deprecation periode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_mstats_common\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_find_repeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheilslopes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiegelslopes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_continuous_distns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m  12166\u001b[0m \u001b[0mrel_breitwigner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_breitwigner_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rel_breitwigner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12169\u001b[0m \u001b[1;31m# Collect names of classes and objects in this module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 12170\u001b[1;33m \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  12171\u001b[0m \u001b[0m_distn_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_distn_gen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_distribution_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12173\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_distn_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_distn_gen_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'rv_histogram'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_acc = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "        # print(dataset[0][\"features\"].shape[0] - 2, emb_sizes, config['layers_list'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "            best_config = config\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Validation Accuracy: {best_acc:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [15, 25],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d25ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import warnings\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Suppose your DataFrame is df and your binary target column is 'Target'\n",
    "y = data['Target'].values\n",
    "\n",
    "# Compute weights for each class label (0 and 1)\n",
    "classes = np.unique(y)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "w0, w1 = class_weights\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Reuse evaluate for both train and validation\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            # Apply sigmoid activation to get probabilities\n",
    "            pred = torch.sigmoid(pred)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_global_score = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(w1/w0).to(device))\n",
    "\n",
    "        best_config_score = 0\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            train_acc = evaluate(model, train_loader, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            epoch_score = min(train_acc, val_acc)\n",
    "            best_config_score = max(best_config_score, epoch_score)\n",
    "            # print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} | Train Acc={train_acc:.4f} | Val Acc={val_acc:.4f} | Min Acc={epoch_score:.4f}\")\n",
    "            if epoch_score > best_global_score:\n",
    "                best_global_score = best_config_score\n",
    "                best_model_state = model.state_dict()\n",
    "                best_config = config\n",
    "\n",
    "        print(f\"Best Min(train, val) accuracy for config: {best_config_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Min Acc: {best_global_score:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 1e-2],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [25, 35],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8256466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7807\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7831\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7855\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7951\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8147\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7879\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7815\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7687\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7831\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8006\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7891\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8006\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7668\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8054\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7568\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7520\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7380\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7815\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8022\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7636\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7767\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7700\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Best Config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001} | Best Min Acc: 0.8307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('imputer.impute',\n",
       "               tensor([1.9688e+03, 5.2024e+04, 4.4990e-01, 4.9968e-01, 5.4975e+02, 4.9346e+01,\n",
       "                       3.0460e+02, 2.5941e+01, 1.6541e+02, 3.7271e+01, 2.7125e+01, 4.4283e+01,\n",
       "                       4.0325e+00, 2.6745e+00, 5.7760e+00, 2.3325e+00, 5.3255e+00, 6.3178e-02,\n",
       "                       1.2125e-02, 7.2112e-02, 7.6579e-02, 7.0198e-02, 1.0211e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('scaler.mean',\n",
       "               tensor([-3.0499e-05, -1.0238e-06, -4.2948e-05, -2.2048e-03,  4.6394e-05,\n",
       "                       -1.6666e-03,  5.8338e-05,  1.7489e-05,  3.7192e-05, -1.0846e-05,\n",
       "                        6.0739e-05, -4.4894e-06,  1.9130e-03,  1.4218e-05, -3.3947e-05,\n",
       "                       -1.9254e-04, -2.5995e-03, -2.0811e-03,  9.2507e-05,  2.1943e-02,\n",
       "                       -4.3273e-03, -1.0172e-02, -6.3790e-05], device='cuda:0')),\n",
       "              ('scaler.std',\n",
       "               tensor([ 0.8879,  1.6519,  0.6460,  0.0257,  1.1131,  0.1214,  0.6902,  0.9798,\n",
       "                        1.0779,  1.0050,  1.0284,  0.8863,  0.0212,  0.8693,  0.8083,  0.0710,\n",
       "                        0.0286,  0.0205,  0.4811,  0.0038, -0.0318, -0.0276,  0.9499],\n",
       "                      device='cuda:0')),\n",
       "              ('embedding_1.weight',\n",
       "               tensor([[ 0.6738, -0.9576,  1.7890, -1.0090, -0.7615,  0.0515,  0.3811, -1.2652,\n",
       "                         0.1315,  1.0034],\n",
       "                       [-0.2761,  2.3895,  0.0605,  0.5959, -0.2769,  0.0128, -0.4977,  0.2234,\n",
       "                         0.2883,  0.8804],\n",
       "                       [ 0.7641,  0.6655,  0.2201,  0.2389, -0.1426, -0.0164, -0.7585, -0.9290,\n",
       "                         0.9223, -0.8896],\n",
       "                       [-0.1291,  0.8222, -0.0918,  0.8704,  0.1889,  0.5084, -0.1828,  0.7833,\n",
       "                        -1.3526, -0.8706],\n",
       "                       [-0.5510,  0.0860, -2.5076, -2.1432,  0.6094,  0.5707,  1.8806, -0.7619,\n",
       "                        -0.0121, -1.4607]], device='cuda:0')),\n",
       "              ('embedding_2.weight',\n",
       "               tensor([[-0.9614,  2.1056, -0.1725,  0.5816,  0.7110,  1.3269,  0.6279, -1.0441,\n",
       "                        -0.4217,  0.3220],\n",
       "                       [ 0.1105, -1.8366, -1.1718, -0.2642, -3.2714,  0.5886,  0.0455,  0.3020,\n",
       "                         0.9831, -1.3934],\n",
       "                       [ 1.5168,  1.5172,  0.9976,  2.7821,  1.0010,  0.1280, -0.7838, -1.6063,\n",
       "                        -1.7559,  0.3571],\n",
       "                       [-0.1545, -0.0257,  0.9410, -0.3492, -0.7850,  0.4516, -0.9435,  0.1995,\n",
       "                        -2.3640, -0.1665],\n",
       "                       [ 1.3486, -0.8951,  1.5955, -0.9024, -0.2621,  1.5015,  1.1351, -0.4718,\n",
       "                         0.0099, -0.3581]], device='cuda:0')),\n",
       "              ('ff.0.weight',\n",
       "               tensor([[-0.0153,  0.0377, -0.1321,  ..., -0.1531, -0.0999,  0.1166],\n",
       "                       [-0.0741,  0.1396, -0.1383,  ..., -0.0234, -0.0472, -0.0195],\n",
       "                       [ 0.2014, -0.0042,  0.0351,  ...,  0.2349,  0.0887, -0.1953],\n",
       "                       ...,\n",
       "                       [ 0.1746, -0.0209,  0.2962,  ...,  0.1153, -0.0235, -0.0857],\n",
       "                       [-0.1959, -0.0138, -0.0171,  ..., -0.2682,  0.0013,  0.0291],\n",
       "                       [-0.1603, -0.0351, -0.0271,  ...,  0.0747,  0.0379,  0.2212]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.0.bias',\n",
       "               tensor([ 0.1388, -0.1026,  0.1045,  0.0150,  0.0731, -0.1186,  0.0797,  0.0462,\n",
       "                       -0.1324,  0.0612,  0.0667,  0.1379, -0.1106,  0.1313, -0.1479, -0.1190,\n",
       "                        0.1461, -0.0559,  0.0093,  0.0994, -0.1187,  0.1441,  0.0193, -0.0832,\n",
       "                        0.0825, -0.1375,  0.1034,  0.0692, -0.0202, -0.0345,  0.0433, -0.1241,\n",
       "                        0.0826, -0.0668, -0.0817,  0.1048,  0.0831,  0.0852,  0.0885,  0.1221,\n",
       "                        0.1265,  0.0752, -0.0937, -0.0316,  0.1483,  0.0707, -0.1345,  0.0124,\n",
       "                       -0.0757, -0.0897, -0.1397,  0.0060,  0.0375,  0.0618, -0.1187,  0.1486,\n",
       "                        0.0784, -0.0273, -0.1179,  0.0682,  0.0513, -0.0133,  0.0772, -0.0436,\n",
       "                        0.0762,  0.0543, -0.0064,  0.0543,  0.0703, -0.0083, -0.0149, -0.1243,\n",
       "                       -0.1409,  0.1342, -0.1368, -0.1057,  0.0405, -0.0865, -0.0002, -0.1320,\n",
       "                        0.1370, -0.0159, -0.1270,  0.1387, -0.0764,  0.0118, -0.1364,  0.0267,\n",
       "                       -0.0975,  0.0626, -0.1496, -0.0200, -0.1501,  0.0487,  0.0285, -0.1242,\n",
       "                        0.0692,  0.0359, -0.0800,  0.0186, -0.1117, -0.0599,  0.1164,  0.1126,\n",
       "                       -0.0169,  0.1085,  0.0195,  0.0633,  0.0455, -0.1424,  0.0322,  0.1093,\n",
       "                       -0.0672, -0.1005, -0.1196,  0.0635,  0.1468,  0.0054,  0.0826,  0.0249,\n",
       "                        0.0090, -0.1136,  0.0933, -0.1105,  0.1475,  0.0784,  0.0723,  0.0032],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.weight',\n",
       "               tensor([0.9365, 0.9454, 0.9674, 1.0082, 0.9969, 0.9729, 0.9958, 0.9286, 0.9647,\n",
       "                       0.9667, 1.0443, 0.9424, 0.9184, 0.9242, 0.9492, 1.0762, 1.0240, 0.9731,\n",
       "                       1.0187, 0.9581, 0.8987, 0.9984, 0.9535, 1.0016, 1.0106, 0.9906, 1.0743,\n",
       "                       1.0446, 1.0455, 1.0011, 1.0058, 1.1167, 0.9857, 1.0648, 1.0335, 0.9806,\n",
       "                       1.0887, 0.9308, 0.9795, 0.9738, 1.1179, 0.9540, 0.9734, 1.0192, 1.1706,\n",
       "                       1.0699, 1.0078, 1.0615, 0.9758, 0.9439, 0.9470, 0.8924, 1.0828, 0.9635,\n",
       "                       0.9871, 1.0027, 0.9662, 0.9316, 0.9660, 1.1013, 1.0313, 0.9842, 1.1299,\n",
       "                       1.0853, 1.0591, 1.0509, 1.1226, 0.9650, 0.9600, 0.9640, 0.9162, 0.9456,\n",
       "                       0.9889, 0.9665, 0.9669, 0.9523, 1.0657, 1.0636, 1.0565, 0.9477, 0.9222,\n",
       "                       0.9966, 0.9465, 0.9792, 1.0122, 0.9940, 1.0543, 0.9795, 0.9641, 1.0102,\n",
       "                       0.9987, 0.9387, 0.9686, 0.9332, 0.9366, 0.9563, 1.0374, 1.0581, 1.0294,\n",
       "                       0.9326, 0.9570, 0.9700, 0.9758, 1.0335, 0.9661, 0.9688, 1.1512, 0.9907,\n",
       "                       0.9938, 0.9272, 0.9466, 0.9220, 0.9807, 0.9371, 0.9366, 0.8990, 0.9887,\n",
       "                       0.9781, 1.0241, 0.9519, 1.0223, 1.0507, 0.9810, 0.9718, 0.9414, 1.0065,\n",
       "                       1.0051, 1.0004], device='cuda:0')),\n",
       "              ('ff.1.bias',\n",
       "               tensor([-0.0790, -0.0345, -0.0835, -0.0364, -0.0536, -0.0484, -0.0390, -0.0418,\n",
       "                       -0.0564, -0.0615,  0.0126, -0.0575, -0.0639, -0.1185, -0.0547,  0.1546,\n",
       "                       -0.0166, -0.0803, -0.0479, -0.0151, -0.1001,  0.0459, -0.0296, -0.0036,\n",
       "                       -0.0026, -0.0112,  0.0550,  0.0651,  0.0377, -0.0148, -0.0027,  0.0394,\n",
       "                       -0.0440,  0.0535,  0.0688, -0.0245, -0.0037, -0.0743, -0.0552, -0.0573,\n",
       "                       -0.0082, -0.0681, -0.0168,  0.0349,  0.0440,  0.0582, -0.0002,  0.0358,\n",
       "                       -0.0083, -0.0273, -0.0504, -0.1125,  0.0725, -0.0248, -0.0344, -0.0450,\n",
       "                       -0.0213, -0.0684, -0.0388,  0.0269,  0.0363, -0.0423, -0.0028,  0.0866,\n",
       "                        0.1400, -0.0290,  0.0691, -0.0173, -0.0671, -0.0964, -0.1112, -0.0648,\n",
       "                       -0.0334, -0.0491, -0.0741, -0.0430, -0.0416, -0.0212, -0.0167, -0.0702,\n",
       "                       -0.0715,  0.0004, -0.0792, -0.0587, -0.0552, -0.0402, -0.0106, -0.0559,\n",
       "                       -0.0430, -0.0424, -0.0004, -0.0365, -0.0666, -0.0679, -0.0615, -0.0776,\n",
       "                        0.0433,  0.0864, -0.0027, -0.0883, -0.0615, -0.0205, -0.0380,  0.0251,\n",
       "                       -0.0568, -0.0154,  0.0372, -0.0552, -0.0108, -0.0661, -0.0857, -0.1022,\n",
       "                       -0.0343, -0.0838, -0.0528, -0.1011, -0.0043, -0.0360,  0.0011, -0.0557,\n",
       "                       -0.0091, -0.0406, -0.0505,  0.0307, -0.0714, -0.0694, -0.0026, -0.0487],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.running_mean',\n",
       "               tensor([ 1.2678e+03,  4.1540e+03,  2.1833e+02,  8.8464e+01, -1.0896e+03,\n",
       "                        2.8589e+02, -6.2235e+02, -1.1087e+03,  1.1923e+02,  8.7652e+02,\n",
       "                        7.9491e+01,  6.8681e+02, -2.9427e+03,  8.7178e+01,  1.4407e+03,\n",
       "                        3.1589e+02, -4.6027e+01,  1.6800e+03,  5.0187e-01, -1.7306e+02,\n",
       "                        1.7363e+03,  4.9755e+01, -2.7658e+03, -7.5177e+02, -3.8425e+02,\n",
       "                       -3.9649e+02,  8.8864e+00, -4.2275e+02,  5.1950e+02,  2.8739e+02,\n",
       "                       -6.6489e+02,  1.5200e+02,  7.5964e+02,  8.3537e+01,  2.0543e+02,\n",
       "                        8.3780e+02, -4.4082e+02, -8.7719e+02, -2.9328e+03,  1.5990e+03,\n",
       "                       -1.2624e+02, -1.1254e+03, -2.7586e+02,  1.7255e+02,  9.6181e+01,\n",
       "                       -4.2030e+02,  2.8976e+03,  2.1386e+02,  2.1627e+03, -7.9045e+02,\n",
       "                       -5.5540e+02,  1.5230e+03,  2.8895e+02,  2.6919e+02, -3.8052e+02,\n",
       "                       -4.8536e+02,  4.3938e+03, -1.0189e+03,  1.0715e+03, -2.5125e+02,\n",
       "                        1.2375e+01, -3.0733e+02, -2.1008e+02, -1.6462e+02, -1.8514e+02,\n",
       "                        6.8781e+02, -3.4896e+01, -8.0393e+02, -5.4800e+02,  1.9929e+02,\n",
       "                        1.1337e+03, -9.8913e+02, -1.5830e+03,  4.0014e+02, -1.1026e+03,\n",
       "                       -1.1012e+03,  2.0123e+02, -5.6520e+02,  3.1983e+02,  8.3797e+02,\n",
       "                       -8.7363e+02, -1.3800e+03, -3.3241e+03, -4.4260e+02, -2.0255e+02,\n",
       "                       -3.2894e+03, -4.3283e+02,  6.6941e+02,  5.6881e+02, -2.1035e+02,\n",
       "                        7.7004e+01, -4.4910e+02,  3.2087e+02,  1.8002e+03,  1.2150e+02,\n",
       "                        3.6361e+03, -2.3157e+02, -3.7785e+02,  3.0674e+01,  3.6897e+02,\n",
       "                       -1.0848e+03, -2.3520e+03, -5.9709e+03, -2.5080e+02, -3.8653e+02,\n",
       "                       -4.7220e+03, -2.3164e+02, -1.1622e+03,  7.1302e+02,  2.0215e+03,\n",
       "                        7.4185e+02, -4.7445e+02,  3.1291e+03, -8.6610e+02, -8.8784e+02,\n",
       "                        1.6566e+02, -5.3228e+03, -8.8626e+02,  7.1053e+01,  9.9477e+02,\n",
       "                       -3.9861e+02, -3.2267e+02,  2.6448e+03, -7.0516e+01,  1.7366e+03,\n",
       "                       -2.8982e+02, -8.0081e+02, -1.4984e+03], device='cuda:0')),\n",
       "              ('ff.1.running_var',\n",
       "               tensor([ 308481.9688, 3597737.5000,   36302.9883,   42614.3672,  115320.6484,\n",
       "                         12905.2676,  111862.4375,  200724.9688,   32762.7109,  153666.0938,\n",
       "                         19590.6289,  116956.5469, 1242820.5000,   55804.9609,  191226.7969,\n",
       "                         25154.1113,   36291.1094,  529913.5000,   43026.5391,   37986.9844,\n",
       "                        604531.7500,   23491.0527, 1682277.3750,  135560.5000,   75117.9219,\n",
       "                         44788.3750,   23010.7031,   64919.3516,   26381.4473,   58965.8945,\n",
       "                         53056.7656,   43338.3281,   49526.9375,   28741.7695,   27670.5098,\n",
       "                         75422.3047,   44973.7695,  136582.3281, 1945436.3750,  493797.2812,\n",
       "                         25478.8633,  407616.3438,   70775.2109,   45130.9570,   21676.2090,\n",
       "                         58730.6992, 1272456.0000,   32252.7227,  993355.3750,   91789.8828,\n",
       "                         99094.7734,  395703.7500,   24112.3633,   40155.2891,   79601.3750,\n",
       "                         19450.0098, 3887782.0000,  242391.1875,  184362.0625,   39719.0703,\n",
       "                         34014.7852,   38563.1133,   32776.7656,   39392.4727,   28993.9258,\n",
       "                        141313.4844,   21545.9883,   65602.8672,   79690.1875,   40204.5898,\n",
       "                        188081.7031,  197076.3750,  663767.3125,   16341.4160,  251337.6719,\n",
       "                        157805.4062,   23460.4688,   34842.7031,   32952.2031,   64947.5469,\n",
       "                        198734.7344,  346371.1875, 2100010.7500,   42522.3867,   40668.8750,\n",
       "                       2266202.0000,   28734.8652,  110998.1172,   89251.7109,   67566.8750,\n",
       "                         32992.4375,   80427.7500,   19302.6387,  667835.1875,   28158.5918,\n",
       "                       2160923.7500,   51322.7852,   66893.3203,   68493.2109,   32523.8301,\n",
       "                         88309.6406, 1207158.7500, 7845741.0000,   32095.1172,   47744.8867,\n",
       "                       5270218.5000,   43006.8672,  262567.5625,  112219.7344,  874053.6875,\n",
       "                         95556.1016,  107376.7344, 2312760.0000,  135800.7188,  205992.0000,\n",
       "                         49673.5625, 4963264.0000,  144201.2500,   72338.9844,  167428.5625,\n",
       "                         95733.5078,   28838.6270, 1168695.6250,   67084.5625,  665431.7500,\n",
       "                         89512.0703,   44920.7656,  250527.9844], device='cuda:0')),\n",
       "              ('ff.1.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.4.weight',\n",
       "               tensor([[ 0.0231, -0.0411, -0.0074,  ..., -0.0575,  0.0884, -0.0068],\n",
       "                       [ 0.0487, -0.1084, -0.0050,  ..., -0.1030, -0.0229,  0.0756],\n",
       "                       [ 0.0338, -0.0537, -0.0461,  ..., -0.0527, -0.0328,  0.0201],\n",
       "                       ...,\n",
       "                       [ 0.0849,  0.0232,  0.0644,  ...,  0.0437,  0.0754, -0.0562],\n",
       "                       [-0.0310,  0.0591, -0.0496,  ...,  0.0112,  0.0171, -0.0016],\n",
       "                       [-0.0458, -0.0053, -0.0472,  ..., -0.0866, -0.0701,  0.0134]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.4.bias',\n",
       "               tensor([-0.0019,  0.0757, -0.0601, -0.0152, -0.0262, -0.0716, -0.0178,  0.0785,\n",
       "                        0.0344,  0.0577,  0.0598,  0.0575, -0.0692, -0.0316, -0.0004,  0.0785,\n",
       "                       -0.0358,  0.0611, -0.0560,  0.0761, -0.0147,  0.0348, -0.0400, -0.0298,\n",
       "                       -0.0252,  0.0504, -0.0073,  0.0345,  0.0438,  0.0827, -0.0115,  0.0065,\n",
       "                        0.0447, -0.0032,  0.0575, -0.0030, -0.0482,  0.0061,  0.0903,  0.0541,\n",
       "                       -0.0474,  0.0477, -0.0166, -0.0529,  0.0710,  0.0475, -0.0894, -0.0392,\n",
       "                        0.0754, -0.0798,  0.0733,  0.0332,  0.0585, -0.0764, -0.0024,  0.0314,\n",
       "                       -0.0704,  0.0697,  0.0841, -0.0210,  0.0061, -0.0471,  0.0166,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.weight',\n",
       "               tensor([1.0172, 0.9867, 1.0310, 0.9092, 1.0172, 0.9907, 0.9738, 1.0065, 1.0041,\n",
       "                       1.0419, 0.9785, 0.9960, 1.0007, 1.0319, 0.9358, 1.0870, 0.9787, 0.9530,\n",
       "                       1.0533, 1.0156, 0.9809, 1.0297, 0.9898, 0.9704, 1.0538, 0.9821, 0.9820,\n",
       "                       1.0502, 1.0351, 1.0158, 1.0465, 1.0322, 1.0394, 0.9975, 0.8932, 0.8989,\n",
       "                       0.9820, 0.9756, 0.9560, 1.0347, 0.9981, 0.9908, 1.0326, 1.0189, 1.0537,\n",
       "                       1.0095, 0.9478, 1.0474, 1.0289, 0.9109, 1.0272, 0.9866, 0.9885, 0.9816,\n",
       "                       1.0116, 1.0632, 1.0461, 1.0042, 1.0054, 1.0133, 1.0062, 0.9279, 0.9360,\n",
       "                       1.0385], device='cuda:0')),\n",
       "              ('ff.5.bias',\n",
       "               tensor([-0.0047, -0.0232, -0.0446, -0.0858,  0.0282, -0.0193, -0.0004,  0.0033,\n",
       "                       -0.0084,  0.0441, -0.0473, -0.0390,  0.0089, -0.0147, -0.0345,  0.0667,\n",
       "                        0.0149, -0.0374, -0.0034, -0.0439, -0.0597,  0.0041, -0.0139, -0.0529,\n",
       "                        0.0639, -0.0011, -0.0025, -0.0339,  0.0033, -0.0163,  0.0149,  0.0067,\n",
       "                        0.0884, -0.0206, -0.1129, -0.0784, -0.0226, -0.0250, -0.0111,  0.0572,\n",
       "                        0.0024,  0.0692,  0.0104, -0.0290,  0.0210,  0.0121, -0.0427,  0.0783,\n",
       "                        0.0033, -0.0790,  0.0213, -0.0446, -0.0331, -0.0034,  0.0156,  0.0134,\n",
       "                        0.1029, -0.0194, -0.0152, -0.0081,  0.0470, -0.0643, -0.0400,  0.0142],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_mean',\n",
       "               tensor([ 0.0819,  0.1804, -0.4772, -0.6101, -0.3008,  0.2108,  0.2133,  0.5344,\n",
       "                       -0.4505, -0.1833,  0.5550,  0.0989, -0.0590,  0.0618, -0.4867, -0.1422,\n",
       "                        0.3214, -0.4065, -0.5887, -0.2406,  0.2547, -0.5363, -0.6108,  0.3373,\n",
       "                       -0.6399,  0.0154, -0.6820, -0.1368, -0.0172,  0.4684,  0.0887,  0.7985,\n",
       "                        0.1810, -0.3006, -0.0334,  0.1870,  0.2057, -0.1851,  0.2099,  0.6588,\n",
       "                        0.1316, -0.0559, -0.2391, -0.1731,  0.5077, -0.1250,  0.2248, -0.4493,\n",
       "                        0.7387,  0.0762, -0.1371,  0.1984,  0.5650, -0.6038, -0.6098, -0.1977,\n",
       "                       -0.1055, -0.2997, -0.3490,  0.0093,  0.4037, -0.6665,  0.1693,  0.1043],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_var',\n",
       "               tensor([0.9847, 1.2156, 2.1239, 0.8790, 1.1754, 1.7929, 2.0417, 2.6536, 1.6806,\n",
       "                       2.4264, 1.6802, 1.2156, 1.4891, 1.6398, 1.1587, 2.3768, 1.9464, 1.7519,\n",
       "                       2.8961, 2.4059, 1.5341, 1.7140, 1.3100, 1.2945, 1.3361, 0.9477, 1.5960,\n",
       "                       2.0894, 1.4907, 2.0492, 1.6629, 2.1529, 1.1154, 2.0109, 0.5045, 0.3666,\n",
       "                       2.0824, 1.8649, 1.8414, 2.5514, 1.9924, 2.5713, 1.8918, 1.8980, 3.2337,\n",
       "                       2.3881, 1.3412, 1.2353, 1.6173, 0.7498, 1.2050, 1.0480, 1.6487, 1.2789,\n",
       "                       1.0237, 2.0882, 1.0804, 2.0189, 2.7277, 2.1238, 2.1056, 1.4677, 1.9589,\n",
       "                       2.0727], device='cuda:0')),\n",
       "              ('ff.5.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.8.weight',\n",
       "               tensor([[-0.0940, -0.1412,  0.0479,  ..., -0.1060,  0.0275, -0.0107],\n",
       "                       [ 0.0663,  0.0273, -0.0108,  ..., -0.0078, -0.0203, -0.0399],\n",
       "                       [ 0.1064, -0.0102,  0.0807,  ...,  0.0379,  0.0032, -0.0586],\n",
       "                       ...,\n",
       "                       [ 0.0433,  0.1190,  0.1905,  ...,  0.1097, -0.0569, -0.1091],\n",
       "                       [ 0.0609, -0.1010, -0.0400,  ...,  0.0064,  0.0003, -0.0401],\n",
       "                       [ 0.1131,  0.0386,  0.1315,  ..., -0.0408, -0.0828,  0.0161]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.8.bias',\n",
       "               tensor([-7.7659e-02, -5.5473e-05,  1.5628e-02, -1.8603e-02,  1.0167e-01,\n",
       "                        2.9450e-02, -6.3916e-02,  1.2605e-01,  5.1127e-03, -8.5162e-02,\n",
       "                       -4.1072e-02, -1.0402e-01, -1.1317e-01,  2.5333e-02,  1.0930e-01,\n",
       "                        5.4927e-02, -4.7519e-03, -9.9562e-02,  1.2116e-01,  4.8417e-02,\n",
       "                        1.1597e-01, -1.0592e-01,  1.5283e-02,  3.5716e-02,  1.1558e-01,\n",
       "                        8.9208e-02,  2.3907e-02, -6.4477e-02, -1.0990e-01, -5.9243e-03,\n",
       "                       -9.1548e-02,  2.8768e-02], device='cuda:0')),\n",
       "              ('ff.9.weight',\n",
       "               tensor([1.0148, 0.9851, 0.9617, 1.0823, 0.9513, 1.0514, 1.1191, 0.9480, 1.0477,\n",
       "                       0.9582, 1.0312, 1.1536, 1.0778, 1.1251, 1.1587, 1.0389, 1.0505, 1.0042,\n",
       "                       1.0199, 1.0685, 0.9751, 1.2015, 1.0797, 1.1402, 1.0111, 1.1202, 1.0796,\n",
       "                       1.0193, 0.9703, 1.0362, 1.0682, 0.9796], device='cuda:0')),\n",
       "              ('ff.9.bias',\n",
       "               tensor([ 5.5272e-02, -3.6396e-03, -8.0552e-03,  7.0043e-02, -4.4919e-02,\n",
       "                        3.5666e-02,  1.0308e-01, -5.9634e-02,  5.7273e-02, -5.7233e-02,\n",
       "                        5.4829e-02,  1.5220e-01,  7.4164e-02,  8.4681e-02,  1.2034e-01,\n",
       "                        7.6376e-02,  9.3998e-02,  2.2328e-02,  5.3214e-02,  5.7039e-02,\n",
       "                       -1.6607e-05,  1.9520e-01,  9.0955e-02,  1.5454e-01,  3.1493e-03,\n",
       "                        1.3814e-01,  7.3680e-02,  4.1650e-02, -4.6734e-02,  5.2859e-02,\n",
       "                        9.6464e-02, -2.0020e-02], device='cuda:0')),\n",
       "              ('ff.9.running_mean',\n",
       "               tensor([-1.0197e-01, -1.0460e-01, -2.8072e-02, -1.6518e-01, -1.3431e-01,\n",
       "                       -2.8967e-01, -3.8401e-01, -8.5669e-02, -1.3851e-01, -2.2051e-01,\n",
       "                       -2.5291e-01,  8.7660e-02, -4.1551e-01, -1.7487e-01,  3.3998e-02,\n",
       "                       -2.7326e-02,  1.7139e-01, -1.2011e-01,  1.3437e-01,  4.2134e-02,\n",
       "                       -3.6449e-02, -1.0544e-01, -3.9150e-04,  9.2810e-02,  1.5923e-02,\n",
       "                       -2.0545e-01,  2.1977e-01, -3.5611e-01, -3.8920e-01,  7.5240e-02,\n",
       "                       -3.1362e-01, -1.0082e-01], device='cuda:0')),\n",
       "              ('ff.9.running_var',\n",
       "               tensor([2.4231, 2.5473, 1.9340, 2.3294, 1.6164, 2.0636, 2.5954, 1.6030, 2.5339,\n",
       "                       2.1966, 2.3131, 3.0338, 2.4262, 3.4352, 3.1029, 2.8732, 1.9828, 2.2973,\n",
       "                       1.7869, 2.1666, 1.8796, 3.1645, 1.3817, 2.4135, 2.1650, 2.0257, 2.0509,\n",
       "                       2.2713, 1.7819, 1.9557, 1.9880, 1.6861], device='cuda:0')),\n",
       "              ('ff.9.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.12.weight',\n",
       "               tensor([[-0.1817,  0.1327,  0.0970,  0.0835,  0.1234,  0.0954, -0.1327,  0.1218,\n",
       "                         0.1129,  0.0946, -0.2065,  0.1163, -0.1990,  0.0999, -0.1337, -0.2089,\n",
       "                        -0.1794,  0.1133, -0.1729,  0.0711,  0.1101, -0.1575, -0.1300, -0.1586,\n",
       "                         0.0757, -0.1332, -0.1437,  0.0811,  0.1173,  0.0905, -0.1078,  0.1241]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.12.bias', tensor([-0.2138], device='cuda:0'))]),\n",
       " {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tuning(dataset, emb_sizes=[5, 5], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2487f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8435\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8070\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8403\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 256, 512], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 256, 512], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 128, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8466\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 128, 256], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 128, 256], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32, 16], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32, 16], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8403\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32, 16], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32, 16], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8435\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 128, 256, 512], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8403\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 128, 256, 512], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [32, 64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8466\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [32, 64, 128, 256, 512], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [32, 64, 128, 256, 512], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 256, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 256, 256], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 256, 256], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8403\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 256, 128, 256, 128], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 256, 128, 256, 128], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8094\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 128, 256, 512], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 128, 256, 512], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16, 8], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16, 8], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16, 8], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7891\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 256, 128, 256, 128], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 256, 128, 256, 128], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8466\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8243\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 61\u001b[0m\n\u001b[0;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m5e-4\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m],                          \u001b[38;5;66;03m# Learning rates\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],                       \u001b[38;5;66;03m# Batch sizes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m],                                \u001b[38;5;66;03m# Training duration\u001b[39;00m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     17\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m5e-4\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m],                          \u001b[38;5;66;03m# Learning rates\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m250\u001b[39m],\n\u001b[0;32m     59\u001b[0m }\n\u001b[1;32m---> 61\u001b[0m best_state, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 92\u001b[0m, in \u001b[0;36mrun_tuning\u001b[1;34m(dataset, emb_sizes, param_grid, device)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     91\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[1;32m---> 92\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[0;32m     94\u001b[0m     epoch_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(train_acc, val_acc)\n",
      "Cell \u001b[1;32mIn[20], line 52\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m     50\u001b[0m x_all, y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m x_all[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 52\u001b[0m cat1 \u001b[38;5;241m=\u001b[39m \u001b[43mx_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m cat2 \u001b[38;5;241m=\u001b[39m x_all[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     54\u001b[0m x, y, cat1, cat2 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device), cat1\u001b[38;5;241m.\u001b[39mto(device), cat2\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128, 256],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths (shallow → deep)\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32],\n",
    "        [256, 256, 128, 64, 32],                       # New: deeper and wider\n",
    "        [512, 256, 128, 64, 32],                       # New: even wider\n",
    "        [512, 512, 256, 128, 64, 32],                  # New: deeper\n",
    "        [1024, 512, 256, 128, 64, 32],                 # New: very deep\n",
    "        [512, 512, 512, 256, 128, 64, 32],             # New: 7-layer net\n",
    "    ],\n",
    "    'epochs': [100],                                # Training duration\n",
    "}\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [64, 128, 256],\n",
    "    'layers_list': [\n",
    "        # Baseline and shallow\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32],\n",
    "\n",
    "        # Deeper & wider\n",
    "        [256, 256, 128, 64, 32],\n",
    "        [512, 256, 128, 64, 32],\n",
    "        [512, 512, 256, 128, 64, 32],\n",
    "        [1024, 512, 256, 128, 64, 32],\n",
    "        [512, 512, 512, 256, 128, 64, 32],\n",
    "\n",
    "        # 🧱 Bottleneck-style (wide → narrow → wide)\n",
    "        [512, 256, 128, 256, 512],\n",
    "        [256, 128, 64, 128, 256],\n",
    "\n",
    "        # 🔻 Pyramidal (gradually reducing width)\n",
    "        [1024, 512, 256, 128, 64, 32, 16],\n",
    "        [512, 256, 128, 64, 32, 16],\n",
    "        [256, 128, 64, 32, 16],\n",
    "\n",
    "        # 🔺 Inverse pyramid (upscaling – not typical, but may help for expressive tasks)\n",
    "        [64, 128, 256, 512],\n",
    "        [32, 64, 128, 256, 512],\n",
    "\n",
    "        # 🌀 Residual-style symmetry (no skips, just same-sized stages)\n",
    "        [256, 256, 256, 256],\n",
    "        [128, 256, 128, 256, 128],\n",
    "        [512, 256, 128, 128, 256, 512],\n",
    "\n",
    "        # 🪜 Steady downstep\n",
    "        [1024, 512, 256, 128, 64, 32, 16, 8],\n",
    "\n",
    "        # 🔁 Repeating block pattern\n",
    "        [256, 128, 256, 128, 256, 128],\n",
    "    ],\n",
    "    'epochs': [250],\n",
    "}\n",
    "\n",
    "best_state, best_params = run_tuning(dataset, emb_sizes=[5, 5], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d1e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = torch.load('best_state.pth')\n",
    "best_params = torch.load('best_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state, 'best_state.pth')\n",
    "torch.save(best_params, 'best_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f41850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the model using best_config and load weights\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_model = MarketResearchModel(\n",
    "    num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "    emb_sizes=[3, 4],  # Use the same emb_sizes you used during tuning\n",
    "    layers_list=best_params['layers_list']\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "best_model.load_state_dict(best_state)\n",
    "best_model.eval()\n",
    "test_set = CustomerDataset(test, lists, target_col='ID')\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ada728",
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketResearchModel = TabInspiredMarketModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81f436f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "TabInspiredMarketModel                             --\n",
       "├─ImputationLayer: 1-1                             23\n",
       "├─TrainableScaler: 1-2                             46\n",
       "├─Embedding: 1-3                                   25\n",
       "├─Embedding: 1-4                                   25\n",
       "├─Linear: 1-5                                      64\n",
       "├─Linear: 1-6                                      192\n",
       "├─Linear: 1-7                                      192\n",
       "├─MultiheadAttention: 1-8                          3,168\n",
       "│    └─NonDynamicallyQuantizableLinear: 2-1        1,056\n",
       "├─GLULayer: 1-9                                    --\n",
       "│    └─Linear: 2-2                                 2,112\n",
       "│    └─BatchNorm1d: 2-3                            128\n",
       "├─Sequential: 1-10                                 --\n",
       "│    └─FeatureTransformerBlock: 2-4                --\n",
       "│    │    └─Linear: 3-1                            1,056\n",
       "│    │    └─Linear: 3-2                            1,056\n",
       "│    │    └─BatchNorm1d: 3-3                       64\n",
       "│    │    └─Dropout: 3-4                           --\n",
       "├─Sequential: 1-11                                 --\n",
       "│    └─Linear: 2-5                                 528\n",
       "│    └─BatchNorm1d: 2-6                            32\n",
       "│    └─ReLU: 2-7                                   --\n",
       "│    └─Dropout: 2-8                                --\n",
       "│    └─Linear: 2-9                                 544\n",
       "│    └─BatchNorm1d: 2-10                           64\n",
       "│    └─ReLU: 2-11                                  --\n",
       "│    └─Dropout: 2-12                               --\n",
       "│    └─Linear: 2-13                                33\n",
       "===========================================================================\n",
       "Total params: 10,408\n",
       "Trainable params: 10,408\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120537bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     73\u001b[0m train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 75\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m [Train]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m, in \u001b[0;36mCustomerDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m---> 63\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     65\u001b[0m     }\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# layers_list_now = [512,256,128,128,256,512]\n",
    "# layers_list_now = [512, 256, 64, 256, 512]\n",
    "# layers_list_now = [64, 32]\n",
    "# # bt_size = 32\n",
    "# bt_size = 128\n",
    "# lr = 0.001\n",
    "layers_list_now = best_params['layers_list']\n",
    "bt_size = best_params['batch_size']\n",
    "lr=best_params['lr']\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from altair import layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "# For progress bars (optional)\n",
    "from tqdm import tqdm\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "best_val_acc = 0\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Reproducibility & Device\n",
    "# -----------------------------------------------------------------------------\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Train/Validation Split\n",
    "# -----------------------------------------------------------------------------\n",
    "# `train` is your full DataFrame\n",
    "train_df, val_df = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Datasets & Loaders\n",
    "# -----------------------------------------------------------------------------\n",
    "# `lists` is your list of feature columns in order; target_col='ID'\n",
    "train_set = CustomerDataset(train_df, lists, target_col='Target')\n",
    "val_set   = CustomerDataset(val_df,   lists, target_col='Target')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=bt_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=bt_size, shuffle=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Model, Loss, Optimizer\n",
    "# -----------------------------------------------------------------------------\n",
    "model = MarketResearchModel(\n",
    "    num_numeric_features=train_set[0][\"features\"].shape[0] - 2,\n",
    "    emb_sizes=[5, 5],\n",
    "    layers_list=layers_list_now,\n",
    "    # depth=2,  # Set to 2 for the new model\n",
    "    # hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(w1/w0).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Training Loop (inline, no helper funcs)\n",
    "# -----------------------------------------------------------------------------\n",
    "# epochs = best_params['epochs']\n",
    "epochs = 3000  # Set to 100 epochs for training\n",
    "higest_state = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False):\n",
    "        x_all = batch[\"features\"].to(device)\n",
    "        y_all = batch[\"target\"].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_all)\n",
    "        loss = criterion(outputs, y_all)\n",
    "        outputs = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * y_all.size(0)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        train_correct += (preds == y_all).sum().item()\n",
    "        train_total += y_all.size(0)\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # — Validate —\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]  \", leave=False):\n",
    "            x_all = batch[\"features\"].to(device)\n",
    "            y_all = batch[\"target\"].float().to(device)\n",
    "\n",
    "            outputs = model(x_all)\n",
    "            loss = criterion(outputs, y_all)\n",
    "            outputs = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            val_loss += loss.item() * y_all.size(0)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            val_correct += (preds == y_all).sum().item()\n",
    "            val_total += y_all.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_list.append(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_model_state = model.state_dict()\n",
    "    best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    # Clear previous output and plot\n",
    "    clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epoch + 1), train_acc_list, label='Train Accuracy')\n",
    "    plt.plot(range(1, epoch + 1), val_acc_list, label='Validation Accuracy')\n",
    "    plt.title(f'Epoch {epoch}/{epochs}  |  Best Val Acc: {best_val_acc:.4f}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Also print current and best in compact form\n",
    "    # print(f'Epoch {epoch}/{epochs} → Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Best Val Acc: {best_val_acc:.4f}')\n",
    "    # print(f\"Epoch {epoch}/{epochs} → \"\n",
    "    #       f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "    #       f\"Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Save Final Model\n",
    "# -----------------------------------------------------------------------------\n",
    "torch.save(model.state_dict(), \"final_best_model.pt\")\n",
    "print(\"✅ Model trained and saved to 'final_best_model.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5943360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarketResearchModel(\n",
       "  (imputer): ImputationLayer()\n",
       "  (scaler): TrainableScaler()\n",
       "  (embedding_1): Embedding(5, 10)\n",
       "  (embedding_2): Embedding(5, 10)\n",
       "  (ff): Sequential(\n",
       "    (0): Linear(in_features=43, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.6, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.6, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.6, inplace=False)\n",
       "    (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout(p=0.6, inplace=False)\n",
       "    (16): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (17): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Dropout(p=0.6, inplace=False)\n",
       "    (20): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "test_set = CustomerDataset(test, lists, target_col='ID')\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "best_model = model\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa2775ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093610698365527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs = []\n",
    "Targets = []\n",
    "for i in test_loader:\n",
    "    x_all = i['features'].to(device)\n",
    "    x_all = x_all.to(device)\n",
    "    pred = best_model(x_all)\n",
    "    pred = pred > 0.5\n",
    "    pred = pred.int().cpu().numpy()\n",
    "    Targets += pred.tolist()\n",
    "    IDs += i['target'].tolist()\n",
    "submission = pd.DataFrame({'ID': IDs, 'Target': Targets})\n",
    "# comp = pd.read_csv(r'submission1.csv')\n",
    "comp = pd.read_csv(r'MLP_embed-84.csv')\n",
    "comp = comp.sort_values(by='ID', ignore_index=True)\n",
    "submission = submission.sort_values(by='ID', ignore_index=True)\n",
    "(comp['Target'] == submission['Target']).mean()  # Check accuracy of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a91aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'MLP_embed-83_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d98a571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data2 = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\train.csv')\n",
    "test2 = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\test.csv')\n",
    "\n",
    "data2.replace('Alone', 'Single', inplace=True)\n",
    "test2.replace('Absurd', 'Single', inplace=True)\n",
    "data2.replace('YOLO', 'Single', inplace=True)\n",
    "test2.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('Alone', 'Single', inplace=True)\n",
    "data.replace('Together', 'Married', inplace=True)\n",
    "test.replace('Together', 'Married', inplace=True)\n",
    "\n",
    "test.replace('Basic', '2n Cycle', inplace=True)\n",
    "data.replace('Basic', '2n Cycle', inplace=True)\n",
    "test.replace('Widow', 'Divorced', inplace=True)\n",
    "data.replace('Widow', 'Divorced', inplace=True)\n",
    "\n",
    "data2['Dt_Customer_1'] = pd.to_datetime(data2['Dt_Customer'],format='mixed')\n",
    "data2['Dt_Customer_1'] = data2['Dt_Customer_1']-min(data2['Dt_Customer_1'])\n",
    "data2['Dates']=data2['Dt_Customer_1'].dt.days\n",
    "\n",
    "test2['Dt_Customer_1'] = pd.to_datetime(test2['Dt_Customer'],format='mixed')\n",
    "test2['Dt_Customer_1'] = test2['Dt_Customer_1']-min(test2['Dt_Customer_1'])\n",
    "test2['Dates']=test2['Dt_Customer_1'].dt.days\n",
    "Education = {}\n",
    "Marital_status = {}\n",
    "A = data2['Education'].unique()\n",
    "B = data2['Marital_Status'].unique()\n",
    "\n",
    "# for i in range(len(A)):\n",
    "#     Education[A[i]] = i\n",
    "# for i in range(len(B)):\n",
    "#     Marital_status[B[i]] = i\n",
    "# data2['Education'] = data2['Education'].map(Education)\n",
    "# data2['Marital_Status'] = data2['Marital_Status'].map(Marital_status)\n",
    "\n",
    "spend_cols = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n",
    "data2['TotalSpend']       = data2[spend_cols].sum(axis=1)\n",
    "for col in spend_cols:\n",
    "    data2[col + '_Pct']   = data2[col] / (data2['TotalSpend'] + 1e-6)\n",
    "\n",
    "data2['TotalAccepted']    = data2[['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5']].sum(axis=1)\n",
    "data2['DealAcceptanceRate']= data2['NumDealsPurchases'] / (data2['NumStorePurchases'] + data2['NumWebPurchases'] + data2['NumCatalogPurchases'] + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3728dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import X\n",
    "from catboost import train\n",
    "\n",
    "\n",
    "# lists = [\n",
    "#     'Year_Birth',\n",
    "#     'Income',\n",
    "#     'Kidhome',\n",
    "#     'Teenhome',\n",
    "#     'Dates',\n",
    "#     'Recency',\n",
    "#     'MntWines',\n",
    "#     'MntFruits',\n",
    "#     'MntMeatProducts',\n",
    "#     'MntFishProducts',\n",
    "#     'MntSweetProducts',\n",
    "#     'MntGoldProds',\n",
    "#     'NumWebPurchases',\n",
    "#     'NumCatalogPurchases',\n",
    "#     'NumStorePurchases',\n",
    "#     'NumDealsPurchases',\n",
    "#     'NumWebVisitsMonth',\n",
    "#     'AcceptedCmp1',\n",
    "#     'AcceptedCmp2',\n",
    "#     'AcceptedCmp3',\n",
    "#     'AcceptedCmp4',\n",
    "#     'AcceptedCmp5',\n",
    "#     'Complain',\n",
    "#     # 'Marital_Status_Married',\n",
    "#     # 'Marital_Status_Single',\n",
    "#     # 'Education_Graduation',\n",
    "#     # 'Education_Master',\n",
    "#     # 'Education_PhD',\n",
    "#     'Marital_Status',\n",
    "#     'Education'\n",
    "#     # 'Target'\n",
    "# ]\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Create the new features on your DataFrame (here called `data2`):\n",
    "data2 = data2.copy()\n",
    "data2['Age'] = 2025 - data2['Year_Birth']\n",
    "\n",
    "q1, q99 = data2['Income'].quantile([0.01, 0.99])\n",
    "data2['Income_clipped'] = data2['Income'].clip(q1, q99)\n",
    "data2['Income_log'] = np.log1p(data2['Income_clipped'])\n",
    "\n",
    "# If your “Dates” column is already a numeric “days since enrollment” use it directly;\n",
    "# otherwise convert a datetime:\n",
    "# data2['Dates'] = (pd.to_datetime('2025-04-18') - pd.to_datetime(data2['Dt_Customer'])).dt.days\n",
    "data2['Tenure'] = data2['Dates']  # assuming 'Dates' already gives days since enrollment\n",
    "\n",
    "# Total spend and spend percentages\n",
    "spend_cols = [\n",
    "    'MntWines','MntFruits','MntMeatProducts',\n",
    "    'MntFishProducts','MntSweetProducts','MntGoldProds'\n",
    "]\n",
    "data2['TotalSpend'] = data2[spend_cols].sum(axis=1)\n",
    "for c in spend_cols:\n",
    "    data2[c + '_Pct'] = data2[c] / (data2['TotalSpend'] + 1e-6)\n",
    "\n",
    "# Campaign response rates\n",
    "cmp_cols = ['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5']\n",
    "data2['TotalAccepted']     = data2[cmp_cols].sum(axis=1)\n",
    "data2['DealAcceptanceRate']= data2['NumDealsPurchases'] / (\n",
    "    data2[['NumWebPurchases','NumCatalogPurchases','NumStorePurchases']].sum(axis=1) + 1e-6\n",
    ")\n",
    "\n",
    "# 2) Now define your new feature list (in the exact order you want):\n",
    "lists = [\n",
    "    # Demographics & tenure\n",
    "    'Age',\n",
    "    'Income_log',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Tenure',\n",
    "    'Recency',\n",
    "    'Complain',\n",
    "\n",
    "    # Raw spends\n",
    "    *spend_cols,           # expands to the six spend columns\n",
    "    'TotalSpend',\n",
    "    *[c + '_Pct' for c in spend_cols],\n",
    "\n",
    "    # Web/store/catalog activity\n",
    "    'NumWebVisitsMonth',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "\n",
    "    # Deal/campaign history\n",
    "    'NumDealsPurchases',\n",
    "    'DealAcceptanceRate',\n",
    "    *cmp_cols,             # the five AcceptedCmp# columns\n",
    "    'TotalAccepted',\n",
    "\n",
    "    # Categorical\n",
    "    'Marital_Status',\n",
    "    'Education'\n",
    "]\n",
    "\n",
    "cat_features = ['Education','Marital_Status']\n",
    "# cat_features = []\n",
    "x = data2[lists].copy()\n",
    "y = data2['Target'].copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val,X_test, y_val, y_test = train_test_split(X_val,y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c650f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8371907\ttest: 0.7643312\tbest: 0.7643312 (0)\ttotal: 73.3ms\tremaining: 1m 13s\n",
      "100:\tlearn: 0.9265762\ttest: 0.8216561\tbest: 0.8343949 (12)\ttotal: 6.5s\tremaining: 57.8s\n",
      "200:\tlearn: 0.9624900\ttest: 0.8343949\tbest: 0.8535032 (165)\ttotal: 13.1s\tremaining: 52.1s\n",
      "300:\tlearn: 0.9832402\ttest: 0.8535032\tbest: 0.8535032 (165)\ttotal: 20s\tremaining: 46.5s\n",
      "400:\tlearn: 0.9880287\ttest: 0.8535032\tbest: 0.8535032 (165)\ttotal: 27s\tremaining: 40.3s\n",
      "bestTest = 0.8535031847\n",
      "bestIteration = 165\n",
      "Shrink model to first 166 iterations.\n",
      "Val Accuracy: 0.8280254777070064\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create CatBoost Pool objects (handles cat features & missing values)\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "val_pool   = Pool(X_val,   y_val,   cat_features=cat_features)\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    use_best_model=True,\n",
    "\n",
    "    l2_leaf_reg=3,\n",
    "    bagging_temperature=0.3,\n",
    "    random_strength=1.0,\n",
    "\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    eval_metric='Accuracy',\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=300,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "# Fit on train, evaluate on validation\n",
    "cat_model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# Predict & report\n",
    "preds = cat_model.predict(X_test)\n",
    "print(\"Val Accuracy:\", accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a72ccd0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_gpu_device_count' from 'catboost' (c:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\catboost\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gpu_device_count\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable GPUs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, get_gpu_device_count())\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_gpu_device_count' from 'catboost' (c:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\catboost\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from catboost import get_gpu_device_count\n",
    "print(\"Available GPUs:\", get_gpu_device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb57778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 9\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 102\n",
      "→ CV Acc 0.8356 @ iter 102 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 41\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8356 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 11\n",
      "→ CV Acc 0.8348 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 31\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 25\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 52\n",
      "→ CV Acc 0.8499 @ iter 19 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 30\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8499 @ iter 30 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 33\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 15\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 43\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 11\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8475 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 62\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 39\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8364 @ iter 62 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 70\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 91\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8372 @ iter 91 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 23\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 26\n",
      "→ CV Acc 0.8348 @ iter 43 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 15\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 106\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 21\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8491 @ iter 106 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 32\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 42\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 59\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 36\n",
      "→ CV Acc 0.8531 @ iter 59 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 47\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 27\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 14\n",
      "→ CV Acc 0.8483 @ iter 49 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 72\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8324 @ iter 72 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 60\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 61\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 33\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 18\n",
      "→ CV Acc 0.8372 @ iter 61 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 64\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 36\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 26\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8372 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 49\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 18\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 93\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 26\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8483 @ iter 54 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 56\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 67\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 14\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8491 @ iter 28 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 46\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 32\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 56\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8515 @ iter 72 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 9\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 102\n",
      "→ CV Acc 0.8356 @ iter 102 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 41\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8356 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 11\n",
      "→ CV Acc 0.8348 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 31\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 25\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 52\n",
      "→ CV Acc 0.8499 @ iter 19 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 30\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8499 @ iter 30 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 33\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 15\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 43\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 11\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8475 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 62\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 39\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8364 @ iter 62 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 70\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 91\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8372 @ iter 91 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 23\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 26\n",
      "→ CV Acc 0.8348 @ iter 43 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 15\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 106\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 21\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8491 @ iter 106 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 32\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 42\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 59\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 36\n",
      "→ CV Acc 0.8531 @ iter 59 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 47\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 27\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 14\n",
      "→ CV Acc 0.8483 @ iter 49 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 72\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8324 @ iter 72 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 60\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 61\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 33\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 18\n",
      "→ CV Acc 0.8372 @ iter 61 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 64\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 36\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 26\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8372 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 49\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 18\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 93\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 26\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8483 @ iter 54 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 56\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 67\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 14\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8491 @ iter 28 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 46\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 32\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 56\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8515 @ iter 72 for {'bagging_temperature': 0.2, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 47\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8420 @ iter 32 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 39\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 31\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 97\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8428 @ iter 71 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 12\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8372 @ iter 38 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 38\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8964143426\n",
      "bestIteration = 50\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 33\n",
      "→ CV Acc 0.8563 @ iter 47 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 33\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 29\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8507 @ iter 33 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 8\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8964143426\n",
      "bestIteration = 109\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8531 @ iter 109 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 74\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 14\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 24\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 24\n",
      "→ CV Acc 0.8340 @ iter 74 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 52\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 69\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8412 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 32\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8364 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 27\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 78\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 32\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8523 @ iter 78 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 25\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 21\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 22\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 59\n",
      "→ CV Acc 0.8476 @ iter 59 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 73\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 37\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 86\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 47\n",
      "→ CV Acc 0.8571 @ iter 86 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 73\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 27\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8348 @ iter 73 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 70\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8372 @ iter 2 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.812749004\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 3\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 12\n",
      "→ CV Acc 0.8276 @ iter 28 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 17\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8483 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 124\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8539 @ iter 124 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 61\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 18\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 69\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 62\n",
      "→ CV Acc 0.8515 @ iter 76 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 47\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8420 @ iter 32 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 39\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 31\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 97\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8428 @ iter 71 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 12\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8372 @ iter 38 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 38\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8964143426\n",
      "bestIteration = 50\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 33\n",
      "→ CV Acc 0.8563 @ iter 47 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 33\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 29\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8507 @ iter 33 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 8\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8964143426\n",
      "bestIteration = 109\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8531 @ iter 109 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 74\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 14\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 24\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 24\n",
      "→ CV Acc 0.8340 @ iter 74 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 52\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 69\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8412 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 32\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8364 @ iter 52 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 27\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 78\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 32\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8523 @ iter 78 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 25\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 21\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 22\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 59\n",
      "→ CV Acc 0.8476 @ iter 59 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 73\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 37\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 86\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 47\n",
      "→ CV Acc 0.8571 @ iter 86 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 73\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 27\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 27\n",
      "→ CV Acc 0.8348 @ iter 73 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 70\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8372 @ iter 2 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.812749004\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 3\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 12\n",
      "→ CV Acc 0.8276 @ iter 28 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 17\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8483 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 124\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8539 @ iter 124 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 61\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 18\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 69\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 62\n",
      "→ CV Acc 0.8515 @ iter 76 for {'bagging_temperature': 0.2, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 65\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 67\n",
      "→ CV Acc 0.8420 @ iter 65 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 27\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 34\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 29\n",
      "→ CV Acc 0.8404 @ iter 27 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 81\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 16\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 50\n",
      "→ CV Acc 0.8452 @ iter 66 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 35\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8459 @ iter 19 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 13\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 77\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 30\n",
      "→ CV Acc 0.8451 @ iter 77 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 65\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 33\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 59\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8499 @ iter 66 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8324 @ iter 43 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 17\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 35\n",
      "→ CV Acc 0.8340 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 57\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8364 @ iter 57 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 31\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 38\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 9\n",
      "→ CV Acc 0.8483 @ iter 25 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 14\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.9003984064\n",
      "bestIteration = 103\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 7\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 73\n",
      "→ CV Acc 0.8555 @ iter 100 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 43\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 21\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 18\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8467 @ iter 45 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 65\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 12\n",
      "→ CV Acc 0.8308 @ iter 65 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 14\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 6\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8348 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 20\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 39\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 64\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 33\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8388 @ iter 62 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 53\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 11\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 115\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 9\n",
      "→ CV Acc 0.8507 @ iter 115 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 21\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 105\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 37\n",
      "→ CV Acc 0.8531 @ iter 105 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 51\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 19\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 7\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 48\n",
      "→ CV Acc 0.8467 @ iter 48 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 65\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 67\n",
      "→ CV Acc 0.8420 @ iter 65 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 27\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 34\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 29\n",
      "→ CV Acc 0.8404 @ iter 27 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 81\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 16\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 50\n",
      "→ CV Acc 0.8452 @ iter 66 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 35\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8459 @ iter 19 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 13\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 77\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 30\n",
      "→ CV Acc 0.8451 @ iter 77 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 65\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 33\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 59\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8499 @ iter 66 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8324 @ iter 43 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 17\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 35\n",
      "→ CV Acc 0.8340 @ iter 42 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 57\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 19\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8364 @ iter 57 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 31\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 38\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 9\n",
      "→ CV Acc 0.8483 @ iter 25 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 14\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.9003984064\n",
      "bestIteration = 103\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 7\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 73\n",
      "→ CV Acc 0.8555 @ iter 100 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 43\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 21\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 18\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8467 @ iter 45 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 65\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 12\n",
      "→ CV Acc 0.8308 @ iter 65 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 14\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 6\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8348 @ iter 37 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 20\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 39\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 64\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 33\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 28\n",
      "→ CV Acc 0.8388 @ iter 62 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 53\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 11\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 115\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 9\n",
      "→ CV Acc 0.8507 @ iter 115 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 21\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 105\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 37\n",
      "→ CV Acc 0.8531 @ iter 105 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 51\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 19\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 7\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 48\n",
      "→ CV Acc 0.8467 @ iter 48 for {'bagging_temperature': 0.2, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 68\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 42\n",
      "→ CV Acc 0.8404 @ iter 59 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 21\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 20\n",
      "→ CV Acc 0.8380 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 23\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 25\n",
      "→ CV Acc 0.8380 @ iter 22 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 19\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 7\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 30\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 33\n",
      "→ CV Acc 0.8459 @ iter 33 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 25\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 37\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 8\n",
      "→ CV Acc 0.8507 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 4\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 78\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 35\n",
      "→ CV Acc 0.8507 @ iter 78 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 41\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8308 @ iter 41 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 49 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8420 @ iter 4 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 65\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 36\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8499 @ iter 47 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 45\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 38\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8555 @ iter 42 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 61\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 45\n",
      "→ CV Acc 0.8531 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 64\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 64 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 46\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 58\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 66\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8356 @ iter 8 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 51\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 54\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 48\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 48\n",
      "→ CV Acc 0.8523 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 24\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 51\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8515 @ iter 51 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 35\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 51\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8507 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 68\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 42\n",
      "→ CV Acc 0.8404 @ iter 59 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8167330677\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 21\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 20\n",
      "→ CV Acc 0.8380 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 23\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 25\n",
      "→ CV Acc 0.8380 @ iter 22 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 19\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 7\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 30\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 33\n",
      "→ CV Acc 0.8459 @ iter 33 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 25\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 0\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 37\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 13\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 8\n",
      "→ CV Acc 0.8507 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 4\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 78\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 35\n",
      "→ CV Acc 0.8507 @ iter 78 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 41\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8308 @ iter 41 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 49\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 49 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 16\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8420 @ iter 4 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 65\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 36\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8499 @ iter 47 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 45\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 24\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 38\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8555 @ iter 42 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 61\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 45\n",
      "→ CV Acc 0.8531 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 64\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 64 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 46\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 58\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8332 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 66\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 6\n",
      "→ CV Acc 0.8356 @ iter 8 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 51\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 54\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 48\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 48\n",
      "→ CV Acc 0.8523 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 24\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 51\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8515 @ iter 51 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 35\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 29\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 51\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 34\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8507 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 6, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 17\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 52\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 8\n",
      "→ CV Acc 0.8380 @ iter 52 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 57\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 1\n",
      "→ CV Acc 0.8404 @ iter 2 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 60\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 11\n",
      "→ CV Acc 0.8388 @ iter 61 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 42\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 20\n",
      "→ CV Acc 0.8483 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 36\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 15\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8475 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 47\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 52\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8491 @ iter 52 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 38\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 37\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8348 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 54\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 37\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8404 @ iter 63 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 16\n",
      "→ CV Acc 0.8340 @ iter 27 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 30\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 38\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8467 @ iter 19 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 40\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 47\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 42\n",
      "→ CV Acc 0.8539 @ iter 56 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 10\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 62\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8499 @ iter 31 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 77\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8356 @ iter 77 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 79\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 28\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8372 @ iter 79 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8087649402\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 75\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 46\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8356 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 14\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8451 @ iter 31 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 27\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 49\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8459 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 37\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 111\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8491 @ iter 111 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 17\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 52\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 2\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 8\n",
      "→ CV Acc 0.8380 @ iter 52 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 57\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 1\n",
      "→ CV Acc 0.8404 @ iter 2 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 60\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 61\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 11\n",
      "→ CV Acc 0.8388 @ iter 61 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 42\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 20\n",
      "→ CV Acc 0.8483 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 36\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 2\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 15\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "→ CV Acc 0.8475 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 47\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 52\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.856\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8491 @ iter 52 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 38\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 37\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8348 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 54\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 37\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 2\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8404 @ iter 63 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 16\n",
      "→ CV Acc 0.8340 @ iter 27 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 30\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 38\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8467 @ iter 19 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 40\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 47\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 39\n",
      "→ CV Acc 0.8531 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 10\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 62\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8499 @ iter 31 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 1\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 77\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 4\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 22\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 5\n",
      "→ CV Acc 0.8356 @ iter 77 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 79\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 28\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 3\n",
      "→ CV Acc 0.8372 @ iter 79 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8087649402\n",
      "bestIteration = 4\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 75\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 46\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 13\n",
      "→ CV Acc 0.8356 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 35\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 14\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8451 @ iter 31 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 27\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 49\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8459 @ iter 48 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 37\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 111\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 7\n",
      "→ CV Acc 0.8491 @ iter 111 for {'bagging_temperature': 0.5, 'depth': 8, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 40\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 44\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 75\n",
      "→ CV Acc 0.8436 @ iter 75 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 81\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 0\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 54\n",
      "→ CV Acc 0.8491 @ iter 61 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 29\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 3\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8340 @ iter 20 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 27\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 14\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 92\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 18\n",
      "→ CV Acc 0.8491 @ iter 92 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 0\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8507 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 39\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 52\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8491 @ iter 21 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 58\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 25\n",
      "→ CV Acc 0.8332 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 7\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 45\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 10\n",
      "→ CV Acc 0.8388 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 52\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 38\n",
      "→ CV Acc 0.8348 @ iter 40 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 30\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 72\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8475 @ iter 40 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 81\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8491 @ iter 81 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 11\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 56\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 1\n",
      "→ CV Acc 0.8404 @ iter 37 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 17\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 26\n",
      "→ CV Acc 0.8300 @ iter 9 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 28\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 87\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 10\n",
      "→ CV Acc 0.8388 @ iter 87 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 37\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 53\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 28\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8388 @ iter 53 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 20\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 112\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 54\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8499 @ iter 112 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 22\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 7\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 64\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 24\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 39\n",
      "→ CV Acc 0.8507 @ iter 66 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 18\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 40\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 63\n",
      "→ CV Acc 0.8468 @ iter 75 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 40\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8605577689\n",
      "bestIteration = 44\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 1\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 75\n",
      "→ CV Acc 0.8436 @ iter 75 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 81\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 0\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 20\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 54\n",
      "→ CV Acc 0.8491 @ iter 61 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 29\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 3\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8340 @ iter 20 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 27\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 14\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8924302789\n",
      "bestIteration = 92\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.828\n",
      "bestIteration = 18\n",
      "→ CV Acc 0.8491 @ iter 92 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 26\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 26\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8685258964\n",
      "bestIteration = 0\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 34\n",
      "→ CV Acc 0.8507 @ iter 39 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 39\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 20\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 52\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.852\n",
      "bestIteration = 4\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 43\n",
      "→ CV Acc 0.8491 @ iter 21 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 1, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.828685259\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 58\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 11\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 5\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 25\n",
      "→ CV Acc 0.8332 @ iter 58 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 7\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 45\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.84\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 10\n",
      "→ CV Acc 0.8388 @ iter 45 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 2\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8804780876\n",
      "bestIteration = 52\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 16\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.824\n",
      "bestIteration = 38\n",
      "→ CV Acc 0.8348 @ iter 40 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8366533865\n",
      "bestIteration = 9\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 30\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8725099602\n",
      "bestIteration = 72\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 25\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.832\n",
      "bestIteration = 23\n",
      "→ CV Acc 0.8475 @ iter 40 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8446215139\n",
      "bestIteration = 44\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 81\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 15\n",
      "→ CV Acc 0.8491 @ iter 81 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8326693227\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8645418327\n",
      "bestIteration = 11\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 56\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 1\n",
      "→ CV Acc 0.8404 @ iter 37 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 3, 'learning_rate': 0.05, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8207171315\n",
      "bestIteration = 3\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8565737052\n",
      "bestIteration = 1\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8406374502\n",
      "bestIteration = 17\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.836\n",
      "bestIteration = 9\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.816\n",
      "bestIteration = 26\n",
      "→ CV Acc 0.8300 @ iter 9 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 0.5}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 59\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8525896414\n",
      "bestIteration = 28\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.848\n",
      "bestIteration = 87\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 10\n",
      "→ CV Acc 0.8388 @ iter 87 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 1.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8247011952\n",
      "bestIteration = 37\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8764940239\n",
      "bestIteration = 53\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 28\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 23\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.82\n",
      "bestIteration = 4\n",
      "→ CV Acc 0.8388 @ iter 53 for {'bagging_temperature': 0.5, 'depth': 10, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_strength': 2.0}\n",
      "Training on fold [0/5]\n",
      "bestTest = 0.8486055777\n",
      "bestIteration = 20\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.8884462151\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.8844621514\n",
      "bestIteration = 112\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.844\n",
      "bestIteration = 54\n",
      "Training on fold [4/5]\n"
     ]
    }
   ],
   "source": [
    "from catboost import cv, Pool, CatBoostClassifier\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 0) Your feature matrix X and labels y, plus cat_features list\n",
    "\n",
    "# 1) Split off 10% for test\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    x, y, test_size=0.10, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2) Split remaining 90% into 80% train (i.e. 80/90=0.8889) and 10% val (i.e. 10/90=0.1111)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.1111111, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# 3) Prepare Pools\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "val_pool   = Pool(X_val,   y_val,   cat_features=cat_features)\n",
    "\n",
    "# 4) Define grid (omit rsm for GPU mode)\n",
    "param_grid = {\n",
    "    'iterations':       [500, 1000],\n",
    "    'depth':            [6, 8, 10],\n",
    "    'learning_rate':    [0.01, 0.05],\n",
    "    'l2_leaf_reg':      [1, 3, 5],\n",
    "    'bagging_temperature': [0.2, 0.5, 1.0],\n",
    "    # 'subsample':        [0.7, 0.8, 1.0],\n",
    "    'random_strength':  [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "best = {'best_cv_accuracy': 0.0}\n",
    "\n",
    "# 5) 5‑fold CV grid search on GPU\n",
    "for p in ParameterGrid(param_grid):\n",
    "    params = {\n",
    "        **p,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric':   'Accuracy',\n",
    "        'verbose':       False,\n",
    "        'task_type':     'GPU',\n",
    "        'devices':       '0'\n",
    "    }\n",
    "\n",
    "    cv_df = cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=5,\n",
    "        partition_random_seed=42,\n",
    "        early_stopping_rounds=30,\n",
    "        as_pandas=True,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    acc = cv_df['test-Accuracy-mean'].max()\n",
    "    it  = int(cv_df['test-Accuracy-mean'].idxmax())\n",
    "\n",
    "    if acc > best['best_cv_accuracy']:\n",
    "        best = {**params, 'best_iter': it, 'best_cv_accuracy': acc}\n",
    "\n",
    "    print(f\"→ CV Acc {acc:.4f} @ iter {it} for {p}\")\n",
    "\n",
    "print(\"\\n✅ Best CV run:\")\n",
    "for k, v in best.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 6) Final model: train on train + early stop on val, rollback to best iteration\n",
    "final_model = CatBoostClassifier(\n",
    "    iterations           = best['best_iter'],\n",
    "    depth                = best['depth'],\n",
    "    learning_rate        = best['learning_rate'],\n",
    "    l2_leaf_reg          = best['l2_leaf_reg'],\n",
    "    bagging_temperature  = best['bagging_temperature'],\n",
    "    # subsample            = best['subsample'],\n",
    "    random_strength      = best['random_strength'],\n",
    "    loss_function        = 'Logloss',\n",
    "    eval_metric          = 'Accuracy',\n",
    "    # use_best_model       = True,\n",
    "    task_type            = 'GPU',\n",
    "    devices              = '0',\n",
    "    random_seed          = 42,\n",
    "    early_stopping_rounds=30,\n",
    "    verbose              = 100\n",
    ")\n",
    "\n",
    "final_model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# 7) Evaluate on held‑out test set\n",
    "preds = final_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "print(f\"\\n📊 Held‑out Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0672f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
