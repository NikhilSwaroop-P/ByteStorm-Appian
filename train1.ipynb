{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f83d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Graduation\n",
      "1: PhD\n",
      "2: Master\n",
      "3: 2n Cycle\n",
      "0: Single\n",
      "1: Married\n",
      "2: Divorced\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\train.csv')\n",
    "test = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\test.csv')\n",
    "\n",
    "data.replace('Alone', 'Single', inplace=True)\n",
    "test.replace('Absurd', 'Single', inplace=True)\n",
    "data.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('Alone', 'Single', inplace=True)\n",
    "data.replace('Together', 'Married', inplace=True)\n",
    "test.replace('Together', 'Married', inplace=True)\n",
    "\n",
    "test.replace('Basic', '2n Cycle', inplace=True)\n",
    "data.replace('Basic', '2n Cycle', inplace=True)\n",
    "test.replace('Widow', 'Divorced', inplace=True)\n",
    "data.replace('Widow', 'Divorced', inplace=True)\n",
    "\n",
    "data['Dt_Customer_1'] = pd.to_datetime(data['Dt_Customer'],format='mixed')\n",
    "data['Dt_Customer_1'] = data['Dt_Customer_1']-min(data['Dt_Customer_1'])\n",
    "data['Dates']=data['Dt_Customer_1'].dt.days\n",
    "\n",
    "test['Dt_Customer_1'] = pd.to_datetime(test['Dt_Customer'],format='mixed')\n",
    "test['Dt_Customer_1'] = test['Dt_Customer_1']-min(test['Dt_Customer_1'])\n",
    "test['Dates']=test['Dt_Customer_1'].dt.days\n",
    "Education = {}\n",
    "Marital_status = {}\n",
    "A = data['Education'].unique()\n",
    "B = data['Marital_Status'].unique()\n",
    "# A = test['Education'].unique()\n",
    "# B = test['Marital_Status'].unique()\n",
    "for i, category in enumerate(A):\n",
    "    l = [0]*len(A)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Education[category] = i\n",
    "for i, category in enumerate(B):\n",
    "    l = [0]*len(B)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Marital_status[category] = i\n",
    "data['Education'] = data['Education'].map(Education)\n",
    "test['Education'] = test['Education'].map(Education)\n",
    "data['Marital_Status'] = data['Marital_Status'].map(Marital_status)\n",
    "test['Marital_Status'] = test['Marital_Status'].map(Marital_status)\n",
    "\n",
    "# data = pd.get_dummies(data, columns=['Marital_Status', 'Education'], drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=['Marital_Status', 'Education'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886dc5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ca3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categorical_cols = ['Education', 'Marital_Status']\n",
    "numerical_cols = [\n",
    "    'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'Complain',\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "    'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
    "    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4',\n",
    "    'AcceptedCmp5', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumWebVisitsMonth', 'Dates'\n",
    "]\n",
    "lists = [\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    # 'Marital_Status_Married',\n",
    "    # 'Marital_Status_Single',\n",
    "    # 'Education_Graduation',\n",
    "    # 'Education_Master',\n",
    "    # 'Education_PhD',\n",
    "    'Marital_Status',\n",
    "    'Education'\n",
    "    # 'Target'\n",
    "]\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col='Target'):\n",
    "        self.X = df[feature_cols].values.astype('float32')\n",
    "        self.y = df[target_col].values.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.X[idx], dtype=torch.float),\n",
    "            'target': torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        }\n",
    "        # return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n",
    "\n",
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomerDataset(data, lists, target_col='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8387d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImputationLayer(nn.Module):\n",
    "    def __init__(self, default_values):\n",
    "        super(ImputationLayer, self).__init__()\n",
    "        self.impute = nn.Parameter(torch.tensor(default_values, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.isnan(x)\n",
    "        x[mask] = self.impute.expand(x.shape[0], -1)[mask]\n",
    "        return x\n",
    "\n",
    "class TrainableScaler(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(TrainableScaler, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(num_features))\n",
    "        self.std = nn.Parameter(torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "class MarketResearchModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, emb_sizes = [3,4], layers_list=[64, 32, 1], default_values=default_values):\n",
    "        super(MarketResearchModel, self).__init__()\n",
    "\n",
    "        # Imputation and scaling layers\n",
    "        self.imputer = ImputationLayer(default_values)  # Replace with actual means\n",
    "        self.scaler = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embedding_1 = nn.Embedding(num_embeddings=emb_sizes[0], embedding_dim=5)  # for class feature -6 to -3\n",
    "        self.embedding_2 = nn.Embedding(num_embeddings=emb_sizes[1], embedding_dim=5)  # for class feature -3 to -1\n",
    "\n",
    "        # Input size for FFN\n",
    "        input_size = num_numeric_features + 10\n",
    "\n",
    "        # Build feedforward layers dynamically\n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        for out_dim in layers_list:\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                layers.append(nn.BatchNorm1d(out_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(0.3))\n",
    "            in_dim = out_dim\n",
    "        if layers_list[-1] != 1:\n",
    "            layers.append(nn.Linear(in_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.ff = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_numeric = x[:, :-2]\n",
    "        # x_cat1 = x[:, -5:-3].long()\n",
    "        # x_cat2 = x[:, -3:-1].long()\n",
    "        x_cat1 = x[:,-2:-1].long()\n",
    "        x_cat2 = x[:,-1:].long()\n",
    "        # print(x_numeric.shape, x_cat1.shape, x_cat2.shape)\n",
    "        x_numeric = self.imputer(x_numeric)\n",
    "        x_numeric = self.scaler(x_numeric)\n",
    "\n",
    "        emb1 = self.embedding_1(x_cat1).squeeze(1)\n",
    "        emb2 = self.embedding_2(x_cat2).squeeze(1)\n",
    "        # print(emb1.shape, emb2.shape, x_numeric.shape)\n",
    "        x = torch.cat([x_numeric, emb1, emb2], dim=1)\n",
    "        return self.ff(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0381df59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(default_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e77973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monar\\AppData\\Local\\Temp\\ipykernel_17244\\2147856230.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.impute = nn.Parameter(torch.tensor(default_values, dtype=torch.float32), requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-2]]\n",
    "model = MarketResearchModel(num_numeric_features=len(lists)-2, emb_sizes=[3,4], layers_list=[64, 32, 1], default_values=default_values).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "summary(model, input_size=(3, len(lists)), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06a631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_acc = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "        # print(dataset[0][\"features\"].shape[0] - 2, emb_sizes, config['layers_list'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "            best_config = config\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Validation Accuracy: {best_acc:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [15, 25],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d25ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Reuse evaluate for both train and validation\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_global_score = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        best_config_score = 0\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            train_acc = evaluate(model, train_loader, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            epoch_score = min(train_acc, val_acc)\n",
    "            best_config_score = max(best_config_score, epoch_score)\n",
    "            # print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} | Train Acc={train_acc:.4f} | Val Acc={val_acc:.4f} | Min Acc={epoch_score:.4f}\")\n",
    "\n",
    "        print(f\"Best Min(train, val) accuracy for config: {best_config_score:.4f}\")\n",
    "\n",
    "        if best_config_score > best_global_score:\n",
    "            best_global_score = best_config_score\n",
    "            best_model_state = model.state_dict()\n",
    "            best_config = config\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Min Acc: {best_global_score:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [25, 35],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8256466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7879\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7321\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7380\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8179\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7348\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7448\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8179\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7560\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8211\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7891\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7380\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8147\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7572\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8270\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7855\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7380\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7732\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7616\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7348\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7700\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7368\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7735\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7348\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7305\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7764\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7412\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7412\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7764\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7412\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7540\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7764\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7552\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7093\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7572\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7560\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7252\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7668\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7412\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7316\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7572\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7528\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7225\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7759\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7604\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7284\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7855\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7281\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7700\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7412\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7732\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.7679\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7265\n",
      "\n",
      "Best Config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001} | Best Min Acc: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('imputer.impute',\n",
       "               tensor([1.9688e+03, 5.2024e+04, 4.4990e-01, 4.9968e-01, 5.4975e+02, 4.9346e+01,\n",
       "                       3.0460e+02, 2.5941e+01, 1.6529e+02, 3.7271e+01, 2.7125e+01, 4.4287e+01,\n",
       "                       4.0325e+00, 2.6745e+00, 5.7760e+00, 2.3325e+00, 5.3255e+00, 6.3178e-02,\n",
       "                       1.2125e-02, 7.2112e-02, 7.6579e-02, 7.0198e-02, 1.0211e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('scaler.mean',\n",
       "               tensor([ 3.0355e-06,  4.4914e-06,  1.0357e-04, -3.9557e-03,  8.1649e-05,\n",
       "                        8.7585e-04, -2.2649e-04,  2.5198e-05,  1.0561e-04, -7.4984e-05,\n",
       "                       -3.9970e-05, -8.2520e-05, -7.2387e-03, -5.3955e-06, -7.2013e-05,\n",
       "                        2.2740e-04, -1.4244e-03, -6.2914e-03, -2.7806e-04, -1.3730e-02,\n",
       "                       -4.5411e-03, -4.1318e-04,  2.6653e-05], device='cuda:0')),\n",
       "              ('scaler.std',\n",
       "               tensor([ 0.8242,  1.6737,  0.6330,  0.0128,  1.1425,  0.2536,  0.9191,  0.9766,\n",
       "                        1.1258,  0.9980,  0.9846,  0.9163,  0.0345,  0.9808,  0.8372,  0.2993,\n",
       "                        0.0572, -0.0845,  0.2580,  0.0051, -0.0339, -0.0291,  0.8871],\n",
       "                      device='cuda:0')),\n",
       "              ('embedding_1.weight',\n",
       "               tensor([[-0.0529,  0.4155, -0.6247,  0.8979,  0.9326],\n",
       "                       [ 1.3933, -0.7458,  0.3588,  0.2284, -0.3946],\n",
       "                       [ 0.2223,  0.9558,  0.2135,  0.3317, -0.3719]], device='cuda:0')),\n",
       "              ('embedding_2.weight',\n",
       "               tensor([[ 0.2608,  0.5797, -1.1012,  0.0275, -0.1803],\n",
       "                       [ 0.4497,  0.3285,  0.2917, -1.6507,  2.0480],\n",
       "                       [ 0.9171,  0.6188,  1.9010, -0.0123,  0.8319],\n",
       "                       [-0.6549,  1.3137,  1.4921,  0.7926,  0.6144]], device='cuda:0')),\n",
       "              ('ff.0.weight',\n",
       "               tensor([[-0.0284,  0.1239, -0.1668,  ..., -0.1706,  0.2420, -0.2521],\n",
       "                       [ 0.1516,  0.0792, -0.1283,  ..., -0.2511,  0.1347,  0.1220],\n",
       "                       [-0.0713, -0.0331,  0.1128,  ..., -0.1198, -0.3332,  0.0782],\n",
       "                       ...,\n",
       "                       [ 0.2240, -0.0076,  0.3295,  ..., -0.1735, -0.1753,  0.2361],\n",
       "                       [-0.0037,  0.0783,  0.1017,  ...,  0.0444,  0.1272, -0.1868],\n",
       "                       [ 0.0211,  0.0862,  0.1108,  ..., -0.0597,  0.1240,  0.1302]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.0.bias',\n",
       "               tensor([-0.1461, -0.0510, -0.0621, -0.0652, -0.0383,  0.0598, -0.1209, -0.0982,\n",
       "                       -0.0217,  0.0904, -0.1369, -0.0346, -0.1737,  0.1260, -0.0602,  0.0326,\n",
       "                        0.0700,  0.1437,  0.0808, -0.1348, -0.0302, -0.0456, -0.0348, -0.0380,\n",
       "                        0.0889,  0.1273, -0.0603,  0.0375,  0.0600,  0.1522,  0.1004,  0.0372,\n",
       "                       -0.0567,  0.1716,  0.1013,  0.1159, -0.1267, -0.0542,  0.1417, -0.0811,\n",
       "                        0.0364, -0.0285,  0.0372, -0.0742, -0.1536, -0.1217,  0.0690, -0.0706,\n",
       "                       -0.0570, -0.0505, -0.1012,  0.0982,  0.0962, -0.1448,  0.1710, -0.0652,\n",
       "                       -0.0520,  0.0715,  0.1563,  0.1321,  0.1395, -0.0929,  0.1131, -0.1134,\n",
       "                        0.0634,  0.1393,  0.0218, -0.0848, -0.1274,  0.0971, -0.1356,  0.0252,\n",
       "                       -0.1735, -0.0537,  0.1170,  0.1639, -0.0308, -0.0787,  0.0099, -0.0810,\n",
       "                       -0.1093, -0.0547, -0.0696, -0.1202,  0.1294, -0.1439,  0.0184,  0.0076,\n",
       "                       -0.0600, -0.1036,  0.0582, -0.0735,  0.0479, -0.0756,  0.1381,  0.0564,\n",
       "                        0.1450,  0.0250,  0.0107,  0.0521,  0.0343,  0.0689, -0.1426,  0.0337,\n",
       "                       -0.1630, -0.0904,  0.1461,  0.1025,  0.0991,  0.0239, -0.1541, -0.1453,\n",
       "                       -0.0519, -0.1142,  0.0956, -0.1613, -0.1272, -0.0944, -0.0947,  0.1093,\n",
       "                       -0.1705,  0.0438,  0.0572,  0.0085, -0.1015, -0.1611,  0.0610,  0.0150],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.weight',\n",
       "               tensor([0.9821, 0.9972, 1.0011, 0.9833, 0.9570, 1.0115, 0.9648, 1.0100, 0.9956,\n",
       "                       0.9287, 0.9730, 0.9531, 0.9735, 0.9385, 0.9495, 0.9826, 1.0020, 1.0817,\n",
       "                       1.1177, 0.9728, 0.9652, 1.0025, 0.9655, 0.9273, 0.9168, 0.9599, 0.9028,\n",
       "                       0.9556, 1.1135, 0.9707, 1.0260, 0.9691, 0.9532, 0.9746, 0.9627, 0.9490,\n",
       "                       1.0677, 0.9755, 1.0386, 1.1520, 0.9593, 0.9570, 1.0637, 1.0971, 1.0283,\n",
       "                       1.0353, 0.9265, 0.9923, 1.0034, 0.9942, 0.9927, 0.9598, 0.9971, 0.9978,\n",
       "                       1.0609, 0.9518, 0.9450, 0.9758, 1.0013, 1.0000, 0.9658, 0.9716, 0.9943,\n",
       "                       0.9790, 0.9028, 1.0256, 0.9522, 0.9932, 0.9471, 0.9619, 0.9522, 1.1428,\n",
       "                       0.9605, 0.9855, 0.9558, 0.9822, 0.9988, 1.0418, 0.9561, 0.9936, 0.9902,\n",
       "                       0.9560, 0.9272, 0.9768, 0.9849, 0.9567, 1.0580, 0.9817, 0.9711, 0.9423,\n",
       "                       0.9388, 0.9565, 0.9761, 1.0510, 0.9742, 1.0057, 0.9906, 0.9421, 0.9504,\n",
       "                       1.0017, 1.1055, 1.0289, 0.9289, 0.9577, 1.1684, 0.9664, 1.0821, 0.9351,\n",
       "                       0.9767, 0.9893, 0.9449, 0.9828, 1.1171, 1.0341, 0.9918, 0.9255, 1.0011,\n",
       "                       0.9757, 0.9486, 0.9664, 1.0767, 1.0267, 0.9397, 1.0415, 0.9523, 1.0133,\n",
       "                       0.9078, 0.9768], device='cuda:0')),\n",
       "              ('ff.1.bias',\n",
       "               tensor([-0.0589, -0.0361, -0.0551, -0.0354, -0.0275,  0.0286, -0.0257, -0.0103,\n",
       "                       -0.0064, -0.0860, -0.0517, -0.0021, -0.0651, -0.0378, -0.0648,  0.0163,\n",
       "                       -0.0229,  0.0629,  0.0296, -0.0343, -0.0599, -0.0031, -0.0474, -0.1074,\n",
       "                       -0.0606, -0.0600, -0.0931, -0.0221,  0.0303, -0.0494, -0.0580, -0.0571,\n",
       "                       -0.0529, -0.0658, -0.0278, -0.0100,  0.0339, -0.0412, -0.0241,  0.1236,\n",
       "                       -0.0268, -0.0423,  0.0037, -0.0133,  0.0129,  0.0304, -0.0677, -0.0689,\n",
       "                       -0.0287, -0.0343, -0.0540, -0.0866, -0.0422, -0.0152, -0.0255, -0.0462,\n",
       "                       -0.0756, -0.0035, -0.0217,  0.0384, -0.0998, -0.0573, -0.0577, -0.0106,\n",
       "                       -0.0604,  0.0042, -0.0744, -0.0085, -0.0061, -0.0310,  0.0044,  0.0239,\n",
       "                       -0.0351, -0.0822, -0.0509, -0.0566, -0.0473,  0.0160, -0.0040, -0.0631,\n",
       "                       -0.0432, -0.0252, -0.0592, -0.0622, -0.0172, -0.0098,  0.0148, -0.0339,\n",
       "                       -0.0385, -0.0391, -0.0385, -0.0065,  0.0002, -0.0362, -0.0735, -0.0468,\n",
       "                       -0.0229, -0.0739, -0.0689, -0.0334, -0.0324, -0.0346, -0.0520, -0.0926,\n",
       "                        0.0231, -0.0265,  0.0888, -0.0738, -0.0101, -0.0415, -0.0178, -0.0491,\n",
       "                        0.0513,  0.0299, -0.0201, -0.0550, -0.0234, -0.0051, -0.0596, -0.0024,\n",
       "                        0.0448,  0.0168, -0.0191, -0.0282, -0.0576, -0.0714, -0.0730, -0.0042],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.running_mean',\n",
       "               tensor([ 3.6953e+03,  2.8929e+03, -1.4022e+03, -6.7670e+02,  3.5049e+03,\n",
       "                        6.7488e+02, -7.8651e+02,  4.6644e+02, -1.0305e+03,  3.5034e+03,\n",
       "                       -2.0462e+03,  2.6242e+03,  2.1490e+02,  8.0550e+02,  1.8479e+03,\n",
       "                       -1.8317e+03, -4.4032e+02,  4.0122e+02,  1.6279e+02, -4.8462e+03,\n",
       "                       -3.0511e+03,  2.3363e+02, -5.5670e+02,  2.7458e+03,  3.5029e+03,\n",
       "                        7.5753e+02, -1.0426e+03, -1.0889e+03, -2.8398e+02,  8.5238e+02,\n",
       "                        7.7129e+01,  2.6804e+03, -2.2599e+03, -8.9700e+02, -9.3925e+02,\n",
       "                        2.7867e+02,  3.1631e+01, -2.2132e+03,  4.2843e+02,  4.3787e+02,\n",
       "                       -3.0372e+03,  1.1204e+03,  8.8608e+01, -4.6877e+02,  9.2707e+02,\n",
       "                        6.9779e+02,  4.8510e+03,  3.2276e+03, -9.8721e+02,  6.3630e+02,\n",
       "                        2.1932e+03, -3.7104e+02, -9.5637e+02,  3.8783e+02, -7.4764e+02,\n",
       "                       -6.0818e+02,  3.4142e+03,  3.8815e+02,  2.7729e+03, -1.0013e+03,\n",
       "                        4.0257e+03,  3.7053e+03, -1.8852e+02,  1.4162e+03,  1.0045e+03,\n",
       "                       -8.4550e+02, -5.5219e+02, -1.3439e+03, -1.6559e+03,  1.7626e+03,\n",
       "                        2.5031e+03, -5.7000e+02,  7.3302e+02,  1.6257e+03, -9.2726e+02,\n",
       "                       -2.8427e+02, -7.6782e+02,  8.5275e+02,  1.0574e+03, -5.0941e+02,\n",
       "                       -1.2730e+03,  1.3342e+03, -1.8045e+03,  9.0145e+02,  6.1887e+02,\n",
       "                       -1.1511e+03,  4.5981e+02,  9.3572e+01, -3.2493e+03,  3.7725e+02,\n",
       "                       -3.6872e+03, -3.2596e+03, -1.9660e+03, -3.0879e+02,  6.4548e+02,\n",
       "                        5.6787e+03, -3.9594e+02, -5.1981e+02, -1.6392e+03, -6.2972e+02,\n",
       "                       -3.9422e+02,  3.0364e+02, -1.9442e+03, -6.7923e+02,  2.1336e+02,\n",
       "                       -2.7884e+02,  7.3883e+02,  1.0830e+03, -1.8725e+03,  8.5959e+02,\n",
       "                       -1.8746e+03,  3.9894e+03,  2.6635e+01, -4.3741e+02,  2.6055e+03,\n",
       "                        3.6835e+03,  1.3600e+01, -2.9578e+03, -1.3197e+03,  2.1456e+03,\n",
       "                       -4.8212e+00, -2.1317e+02,  6.4494e+02, -1.1485e+03, -2.4826e+02,\n",
       "                        2.1013e+02,  2.3502e+03,  2.7397e+03], device='cuda:0')),\n",
       "              ('ff.1.running_var',\n",
       "               tensor([2392601.5000, 1016045.0625,  280426.5000,  131998.1719, 2017310.1250,\n",
       "                         22402.7734,   18721.1016,   75603.4219,   39367.7461, 2078234.7500,\n",
       "                        496881.8750,  879843.6875,   24287.3535,   58166.3906,  398387.9062,\n",
       "                        254956.7188,   58120.1875,   18094.5391,   19067.6074, 3491227.7500,\n",
       "                       1463975.2500,   17867.0703,   60647.0391,  846618.5000, 1849677.7500,\n",
       "                        115064.5938,  130316.6484,  369438.7188,    6767.9556,   34363.1172,\n",
       "                         24881.6660, 1251833.2500,  321536.5625,   89926.2734,   79182.2891,\n",
       "                         33817.5586,   11954.2646,  745514.6875,   33267.0391,   12226.2900,\n",
       "                       1870495.5000,  125624.9453,   35052.9297,    7196.3628,   75141.7344,\n",
       "                         10738.5693, 3326329.7500, 2124038.2500,  157764.3438,   84603.2344,\n",
       "                        675852.2500,   49187.5938,  203980.6250,   30847.8945,   24542.4648,\n",
       "                         41531.7852, 1946293.2500,   14494.7090, 1481834.5000,  296584.4688,\n",
       "                       2701542.0000, 2024349.1250,   53561.4883,  482126.5938,  120768.3906,\n",
       "                         27617.2734,  103453.7266,  452010.2188,  330617.5000,  333164.1562,\n",
       "                       1109455.1250,   17980.6953,   21131.9551,  534625.6875,  154772.7656,\n",
       "                         20152.0020,   62674.8516,   13043.1660,   29020.3711,   21271.3887,\n",
       "                        229026.8906,   37741.7461,  298154.8125,  230414.5156,   19199.4941,\n",
       "                        229499.5000,   10561.5928,   20362.7461, 2206290.5000,    7549.0161,\n",
       "                       1840497.7500, 1859347.3750,  432076.3750,   29324.3223,   28809.7207,\n",
       "                       5961455.5000,   22440.9395,   69122.1641,  336514.9375,   28795.9746,\n",
       "                         13526.7344,   15083.3623,  354888.7500,   17808.2598,   11956.6719,\n",
       "                         23136.4473,   16020.4160,  328102.7500,  582626.9375,   93690.9609,\n",
       "                        831361.1250, 2783509.2500,    6373.8584,   19085.6543,  693552.6250,\n",
       "                       2190216.7500,   33660.9805, 1835308.0000,  296345.6562,  678948.8125,\n",
       "                         25379.1172,   12325.3584,   37974.1836,  218282.8125,  138858.5312,\n",
       "                         18420.2500,  913368.5625, 1156298.2500], device='cuda:0')),\n",
       "              ('ff.1.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.4.weight',\n",
       "               tensor([[ 0.0664,  0.0046,  0.0560,  ..., -0.0040, -0.0126,  0.0893],\n",
       "                       [ 0.0422,  0.0324,  0.0190,  ..., -0.0327,  0.0619, -0.0458],\n",
       "                       [-0.0605, -0.0553,  0.0428,  ...,  0.0015, -0.0946, -0.0287],\n",
       "                       ...,\n",
       "                       [ 0.0492, -0.0645, -0.0318,  ..., -0.0280,  0.0441, -0.0183],\n",
       "                       [-0.0682, -0.0760,  0.0348,  ..., -0.0053,  0.0767, -0.0404],\n",
       "                       [-0.0700, -0.0051,  0.0629,  ..., -0.0239,  0.0431, -0.0865]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.4.bias',\n",
       "               tensor([ 0.0839, -0.0602, -0.0125, -0.0182,  0.0249,  0.0221,  0.0871,  0.0756,\n",
       "                        0.0368, -0.0462, -0.0624,  0.0450,  0.0446,  0.0306,  0.0703, -0.0371,\n",
       "                        0.0685,  0.0308, -0.0490, -0.0664,  0.0200,  0.0061, -0.0772,  0.0500,\n",
       "                       -0.0323, -0.0553,  0.0637, -0.0437, -0.0558, -0.0865, -0.0791,  0.0409,\n",
       "                       -0.0624, -0.0516, -0.0053,  0.0205, -0.0404, -0.0611, -0.0354,  0.0187,\n",
       "                       -0.0801,  0.0655,  0.0077, -0.0857,  0.0592,  0.0334, -0.0623, -0.0139,\n",
       "                        0.0791, -0.0176, -0.0065,  0.0704,  0.0257,  0.0128, -0.0229,  0.0718,\n",
       "                       -0.0621, -0.0787, -0.0793, -0.0753, -0.0562, -0.0634,  0.0331,  0.0471,\n",
       "                        0.0048, -0.0417, -0.0661,  0.0609,  0.0632,  0.0708,  0.0357, -0.0375,\n",
       "                        0.0475, -0.0726, -0.0033,  0.0687, -0.0598,  0.0550,  0.0024,  0.0597,\n",
       "                        0.0113, -0.0161, -0.0523,  0.0342, -0.0013,  0.0132, -0.0891,  0.0716,\n",
       "                       -0.0070, -0.0355, -0.0119, -0.0200, -0.0836,  0.0852, -0.0370, -0.0213,\n",
       "                       -0.0272,  0.0187, -0.0438,  0.0263, -0.0245,  0.0077, -0.0464, -0.0717,\n",
       "                        0.0012,  0.0531,  0.0114,  0.0757,  0.0206,  0.0297,  0.0167, -0.0592,\n",
       "                       -0.0097,  0.0417,  0.0647, -0.0541,  0.0288, -0.0694, -0.0569, -0.0914,\n",
       "                        0.0735, -0.0260, -0.0239, -0.0428, -0.0215, -0.0753, -0.0740, -0.0550],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.weight',\n",
       "               tensor([0.9714, 1.0178, 0.9760, 0.9941, 0.9864, 0.9685, 0.9410, 1.0528, 0.9678,\n",
       "                       0.9755, 1.0110, 1.0130, 1.0556, 1.0310, 0.9834, 0.9878, 1.0522, 0.9942,\n",
       "                       0.9404, 1.0082, 1.0363, 0.9696, 1.0356, 0.9978, 0.9983, 1.0429, 1.0238,\n",
       "                       0.9682, 1.0077, 1.0133, 0.9953, 1.0409, 0.9823, 1.0034, 0.9614, 0.9832,\n",
       "                       0.9816, 0.9687, 1.0273, 1.0302, 1.0121, 1.0145, 1.0016, 1.0113, 1.0413,\n",
       "                       0.9796, 1.0069, 0.9950, 0.9410, 0.9839, 0.9948, 0.9384, 0.9889, 1.0112,\n",
       "                       0.9988, 1.0336, 1.0618, 1.0174, 0.9517, 0.9698, 0.9710, 0.9984, 0.9636,\n",
       "                       0.9750, 0.9827, 0.9852, 0.9834, 1.0423, 0.9807, 0.9844, 1.0486, 1.0090,\n",
       "                       1.0447, 0.9406, 1.0765, 0.9578, 1.0324, 0.9580, 1.0120, 1.0367, 0.9799,\n",
       "                       0.9907, 0.9500, 0.9972, 1.0063, 0.9457, 0.9905, 0.9911, 1.0454, 1.0685,\n",
       "                       0.9928, 0.9991, 0.9419, 1.0229, 1.0086, 1.0032, 1.0369, 0.9922, 0.9769,\n",
       "                       1.0328, 0.9682, 1.0379, 1.0275, 0.9667, 1.0451, 0.9998, 0.9902, 0.9912,\n",
       "                       1.0452, 1.0305, 0.9885, 0.9998, 1.0270, 0.9715, 0.9725, 1.0313, 0.9376,\n",
       "                       1.0016, 0.9944, 1.0116, 1.0164, 1.0259, 1.0033, 1.0238, 0.9825, 1.0182,\n",
       "                       0.9755, 1.0010], device='cuda:0')),\n",
       "              ('ff.5.bias',\n",
       "               tensor([-0.0170, -0.0116, -0.0248, -0.0042, -0.0343, -0.0530, -0.0774,  0.0532,\n",
       "                       -0.0511, -0.0065,  0.0435,  0.0367,  0.0748, -0.0039, -0.0119, -0.0095,\n",
       "                        0.0334,  0.0197, -0.0372,  0.0142,  0.0110, -0.0299,  0.0158,  0.0185,\n",
       "                       -0.0057,  0.0633,  0.0135, -0.0403, -0.0252, -0.0332, -0.0229, -0.0109,\n",
       "                       -0.0140,  0.0170, -0.0434, -0.0080,  0.0057, -0.0264,  0.0027,  0.0253,\n",
       "                        0.0010,  0.0403,  0.0148,  0.0211,  0.0454, -0.0359, -0.0175, -0.0103,\n",
       "                       -0.0758,  0.0314,  0.0163, -0.0496, -0.0413, -0.0230, -0.0182,  0.0215,\n",
       "                        0.0135, -0.0006, -0.0506, -0.0723, -0.0244,  0.0130, -0.0151, -0.0453,\n",
       "                       -0.0166, -0.0273,  0.0147,  0.0291, -0.0065, -0.0071,  0.0327,  0.0400,\n",
       "                        0.0440, -0.0485,  0.0950, -0.0525,  0.0205, -0.0276, -0.0023,  0.0154,\n",
       "                       -0.0349, -0.0149, -0.0307, -0.0434, -0.0318, -0.0524, -0.0268,  0.0250,\n",
       "                       -0.0093,  0.0090, -0.0284,  0.0295, -0.0326,  0.0367,  0.0348, -0.0354,\n",
       "                        0.0521, -0.0261, -0.0051,  0.0290, -0.0200,  0.0445,  0.0341, -0.0481,\n",
       "                        0.0206,  0.0125,  0.0059, -0.0443,  0.0011, -0.0148, -0.0219, -0.0047,\n",
       "                        0.0460, -0.0141,  0.0579,  0.0294, -0.0366, -0.0254,  0.0019, -0.0106,\n",
       "                        0.0180,  0.0353, -0.0019, -0.0129,  0.0237,  0.0648, -0.0266,  0.0145],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_mean',\n",
       "               tensor([ 0.3109, -0.2399,  0.4147,  0.5002,  0.7236,  0.2470,  0.0652,  0.0330,\n",
       "                       -0.0737, -0.6792,  0.0562, -0.1072, -0.0904, -0.0497,  0.3313,  0.7197,\n",
       "                        0.2558,  0.1239,  0.2937, -0.8662, -0.2737,  0.2525, -0.1865,  0.3674,\n",
       "                        0.5187, -0.6938,  0.0276, -0.4010, -0.1121,  0.0457, -0.3573,  1.1503,\n",
       "                        0.2840,  0.0584, -0.8447, -0.0262, -0.2277,  0.3676, -0.0241,  0.3753,\n",
       "                        0.4810, -0.7553,  0.3096, -0.3705, -0.1714,  0.5792,  0.1056, -0.0701,\n",
       "                        0.1838, -0.6791,  0.3085, -0.0975, -0.0319,  0.4185,  0.1059,  0.0719,\n",
       "                       -0.1753,  0.8250,  0.7362,  0.2725, -1.3091, -0.7595,  0.5340, -0.1647,\n",
       "                       -1.1545,  0.6093, -0.8474, -0.1871, -0.3321,  0.8458,  0.0803, -0.6326,\n",
       "                        0.1393, -0.7239,  0.1893, -0.3394,  0.8538, -0.2799, -0.7759, -0.3637,\n",
       "                        0.0882, -0.4162, -0.3346,  1.0009, -0.5796,  0.3411, -1.0232,  0.9948,\n",
       "                        0.0084,  0.2689, -0.1817, -0.1184, -0.9042, -0.3376, -0.3482,  0.5327,\n",
       "                       -0.0541,  0.4616, -0.3119,  0.2303, -0.5130, -0.2139, -0.1480,  0.1464,\n",
       "                        0.0224, -0.6773, -0.8741,  0.0039,  0.6194,  0.0879,  0.3370,  0.0634,\n",
       "                        0.0573, -0.2583, -0.3119, -0.2150, -0.1935,  0.3476, -0.3885, -0.3049,\n",
       "                       -1.1236,  0.4721, -0.5556,  0.9247, -0.1161,  0.0079,  0.1493,  0.0393],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_var',\n",
       "               tensor([0.3590, 1.2961, 0.9401, 0.4495, 0.9845, 0.7973, 0.5576, 1.2184, 0.2093,\n",
       "                       0.3077, 0.2834, 1.4627, 0.9840, 0.9870, 0.4393, 0.3673, 0.9853, 1.0652,\n",
       "                       0.3638, 1.8199, 0.5684, 0.2943, 1.4066, 0.8486, 0.6443, 0.8407, 0.9342,\n",
       "                       0.5413, 0.4720, 0.7542, 0.6403, 0.6072, 0.9332, 0.4088, 0.4565, 0.5859,\n",
       "                       0.7321, 1.1669, 1.3340, 0.6087, 0.7894, 1.8473, 0.6326, 0.9554, 1.4231,\n",
       "                       0.8001, 0.7744, 0.5476, 0.4036, 1.0108, 1.3124, 0.6080, 0.5196, 0.6889,\n",
       "                       0.8915, 0.7007, 0.8441, 1.1348, 0.7093, 0.3156, 0.8842, 0.8440, 0.8875,\n",
       "                       0.5752, 0.6901, 0.8814, 0.7993, 1.7415, 0.4803, 1.2359, 0.7529, 0.7462,\n",
       "                       0.6967, 0.2696, 1.2466, 0.5016, 1.0016, 1.4542, 0.6899, 1.4047, 0.6787,\n",
       "                       0.5368, 0.4199, 0.6205, 1.6920, 0.5330, 0.3743, 0.6412, 0.9739, 1.1211,\n",
       "                       0.7462, 0.8384, 0.3561, 0.8212, 2.2001, 0.5360, 1.1993, 0.7001, 1.3109,\n",
       "                       1.0463, 0.2460, 0.8983, 0.8180, 0.1657, 1.0415, 0.6218, 0.7594, 1.7525,\n",
       "                       0.3084, 0.5426, 0.8199, 0.4040, 0.9864, 0.3180, 0.4080, 0.7871, 0.8439,\n",
       "                       2.0084, 1.0481, 1.0028, 0.8210, 0.4578, 0.7161, 0.5820, 0.4431, 0.8928,\n",
       "                       1.1398, 1.2469], device='cuda:0')),\n",
       "              ('ff.5.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.8.weight',\n",
       "               tensor([[-0.0603,  0.0171, -0.0339,  ..., -0.0044,  0.0376,  0.0700],\n",
       "                       [-0.0065, -0.0860,  0.0738,  ...,  0.0758, -0.0359,  0.1097],\n",
       "                       [-0.0809,  0.0568, -0.1048,  ...,  0.0382,  0.0644, -0.0352],\n",
       "                       ...,\n",
       "                       [-0.0284,  0.0358, -0.0748,  ...,  0.1216,  0.0125, -0.0129],\n",
       "                       [-0.0485, -0.0449,  0.0763,  ..., -0.0564,  0.0534, -0.0469],\n",
       "                       [ 0.0223,  0.0618, -0.0413,  ..., -0.0270, -0.0247,  0.0009]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.8.bias',\n",
       "               tensor([-0.0021,  0.0172, -0.0855, -0.0346,  0.0560, -0.0892, -0.0597,  0.0299,\n",
       "                        0.0031,  0.0902,  0.0509, -0.0308,  0.0432,  0.0690,  0.0139,  0.0635,\n",
       "                        0.0242,  0.0620, -0.0453, -0.0182, -0.0532, -0.0858,  0.0443,  0.0339,\n",
       "                       -0.0583, -0.0568, -0.0200,  0.0771, -0.0013, -0.0698, -0.0797, -0.0616,\n",
       "                       -0.0096, -0.0808, -0.0164,  0.0623, -0.0235, -0.0399, -0.0392, -0.0037,\n",
       "                       -0.0558,  0.0125, -0.0224,  0.0673, -0.0555, -0.0679,  0.0383,  0.0143,\n",
       "                        0.0555,  0.0227, -0.0885,  0.0536, -0.0360,  0.0203, -0.0785,  0.0863,\n",
       "                       -0.0099,  0.0108,  0.0020,  0.0414,  0.0251, -0.0163, -0.0090,  0.0557],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.9.weight',\n",
       "               tensor([0.9842, 0.9905, 1.0132, 0.9546, 1.0233, 1.0163, 0.9939, 0.9908, 1.0282,\n",
       "                       1.0161, 0.9979, 1.0438, 1.0030, 0.9821, 0.9498, 0.9905, 1.0149, 1.0473,\n",
       "                       0.9697, 1.0256, 0.9915, 1.0005, 1.0354, 0.9425, 1.0378, 1.0457, 1.0114,\n",
       "                       0.9799, 1.0267, 1.0213, 0.9685, 0.9932, 1.0112, 1.0104, 1.0194, 0.9866,\n",
       "                       0.9968, 1.0018, 0.9274, 0.9369, 0.9867, 1.0492, 0.9976, 1.0411, 0.9914,\n",
       "                       1.0347, 1.0336, 0.9772, 0.9818, 0.9897, 0.9822, 1.0077, 1.0359, 1.0438,\n",
       "                       0.9666, 1.0286, 0.9528, 1.0344, 0.9798, 0.9679, 1.0033, 0.9956, 0.9248,\n",
       "                       0.9513], device='cuda:0')),\n",
       "              ('ff.9.bias',\n",
       "               tensor([-0.0439, -0.0090,  0.0575, -0.0661,  0.0156,  0.0415, -0.0262,  0.0434,\n",
       "                        0.0145,  0.0174,  0.0352,  0.0418,  0.0145, -0.0281, -0.0376, -0.0532,\n",
       "                        0.0141, -0.0071, -0.0271,  0.0382,  0.0422, -0.0063,  0.0553, -0.0440,\n",
       "                        0.0246,  0.0395,  0.0112, -0.0595,  0.0747,  0.0260, -0.0131, -0.0311,\n",
       "                        0.0179,  0.0681,  0.0291,  0.0121, -0.0286,  0.0271, -0.0680, -0.0647,\n",
       "                       -0.0086,  0.0273,  0.0381,  0.0454, -0.0016,  0.0344,  0.0184, -0.0363,\n",
       "                       -0.0652, -0.0211, -0.0082, -0.0088,  0.0561,  0.0499, -0.0234,  0.0062,\n",
       "                       -0.0741,  0.0675, -0.0422, -0.0077,  0.0192, -0.0019, -0.0490, -0.0587],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.9.running_mean',\n",
       "               tensor([-0.0720,  0.2657, -0.3473,  0.4225,  0.0384,  0.3671, -0.3486, -0.6926,\n",
       "                       -0.4337,  0.2770, -0.1795, -0.2678, -0.3912,  0.0673,  0.0221,  0.3990,\n",
       "                       -0.3575, -0.0201, -0.7880, -0.8441, -0.4633, -0.0956,  0.2481, -0.3210,\n",
       "                       -0.3245,  0.5260, -0.1909,  0.3445, -0.1318,  0.0236,  0.0157, -0.2341,\n",
       "                       -0.3241, -0.4553, -0.0506,  0.2834,  0.5212, -0.1477, -0.1020, -0.5203,\n",
       "                       -0.0735, -0.1216,  0.2166, -0.2119,  0.0096, -0.6662,  0.0569, -0.2890,\n",
       "                        0.3065, -0.1089, -0.1170,  0.0012, -0.4658, -0.5119, -0.2467,  0.0987,\n",
       "                       -0.3771, -0.3564, -0.3904,  0.0930, -0.1503,  0.1275,  0.2957,  0.1078],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.9.running_var',\n",
       "               tensor([2.0411, 0.3382, 1.6407, 0.3262, 1.7804, 1.4321, 1.4916, 1.0758, 1.4209,\n",
       "                       0.2282, 2.2213, 1.6215, 1.9213, 0.3319, 1.0987, 1.4360, 2.1323, 2.4215,\n",
       "                       1.7488, 2.2351, 1.7436, 1.0140, 1.9494, 0.8770, 2.1607, 1.0991, 2.3307,\n",
       "                       0.9184, 2.5508, 1.3930, 1.2947, 1.8955, 1.5449, 2.3868, 1.9016, 1.9166,\n",
       "                       1.1238, 1.0361, 1.7129, 0.4941, 0.5501, 1.1577, 1.6055, 2.2971, 1.2686,\n",
       "                       1.8910, 0.8644, 1.6662, 0.6873, 1.4245, 2.4926, 1.2474, 2.1475, 2.2148,\n",
       "                       1.5946, 1.7355, 1.6062, 3.1608, 1.3996, 0.9412, 1.4210, 1.0157, 0.3534,\n",
       "                       0.8034], device='cuda:0')),\n",
       "              ('ff.9.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.12.weight',\n",
       "               tensor([[-0.0835, -0.0965, -0.0200,  ...,  0.0605, -0.1097,  0.0468],\n",
       "                       [-0.1241,  0.0101,  0.0090,  ...,  0.0514,  0.0654,  0.0751],\n",
       "                       [-0.0194,  0.0388, -0.0473,  ..., -0.1208, -0.0755, -0.0089],\n",
       "                       ...,\n",
       "                       [ 0.1044, -0.0274,  0.1098,  ..., -0.1092, -0.0288, -0.0686],\n",
       "                       [ 0.0514, -0.0668, -0.0902,  ...,  0.0284, -0.0884,  0.0241],\n",
       "                       [-0.0577,  0.0913, -0.0998,  ...,  0.1126,  0.0449,  0.0101]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.12.bias',\n",
       "               tensor([-0.0449,  0.1163, -0.0939, -0.1213, -0.0814, -0.0501, -0.0022,  0.0438,\n",
       "                       -0.0763,  0.0255,  0.0083, -0.0699, -0.0998,  0.1105,  0.0559,  0.0825,\n",
       "                       -0.0272, -0.0558,  0.0233, -0.1150, -0.0413,  0.1042,  0.1073,  0.0156,\n",
       "                        0.0544, -0.0942,  0.0620,  0.0321,  0.0279, -0.0339, -0.0096, -0.0974],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.13.weight',\n",
       "               tensor([0.9776, 1.0049, 1.0603, 1.1085, 1.0964, 1.1242, 1.0731, 1.0905, 1.0042,\n",
       "                       1.0426, 1.0759, 1.0485, 1.0055, 1.0755, 1.0194, 1.0018, 0.9886, 1.0737,\n",
       "                       1.0037, 0.9706, 0.9717, 1.1188, 0.9592, 1.0681, 0.9876, 1.0882, 1.1360,\n",
       "                       1.1063, 1.0465, 1.0023, 1.0926, 1.0672], device='cuda:0')),\n",
       "              ('ff.13.bias',\n",
       "               tensor([-0.0525, -0.0055,  0.1009,  0.1139,  0.1345,  0.1443,  0.1009,  0.0858,\n",
       "                        0.0143, -0.0208,  0.1031,  0.0815,  0.0151,  0.1097, -0.0052, -0.0142,\n",
       "                       -0.0463,  0.0914, -0.0089, -0.0148, -0.0046,  0.1694, -0.0385,  0.0994,\n",
       "                       -0.0145,  0.0860,  0.1767,  0.1673,  0.1233, -0.0293,  0.1316,  0.0962],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.13.running_mean',\n",
       "               tensor([-0.1024,  0.2445, -0.2643, -0.5624, -0.4416, -0.6169, -0.3465,  0.3175,\n",
       "                        0.0031,  0.3323, -0.4803,  0.5294,  0.0871, -0.2075,  0.2431,  0.2495,\n",
       "                        0.0133, -0.4509,  0.2130,  0.1285,  0.1822, -0.2769,  0.0503,  0.4118,\n",
       "                        0.2969, -0.1654,  0.1044, -0.2561, -0.1292,  0.0113, -0.0484,  0.1210],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.13.running_var',\n",
       "               tensor([1.0543, 1.3533, 1.6699, 1.1192, 1.1781, 1.6566, 0.5819, 1.0152, 1.1426,\n",
       "                       0.5316, 1.9020, 0.8862, 1.9448, 1.5167, 1.2294, 1.6290, 1.3560, 1.5138,\n",
       "                       1.4497, 0.9701, 1.0327, 1.7317, 0.8951, 0.9136, 1.1664, 1.6090, 1.4134,\n",
       "                       1.6005, 1.2931, 1.5319, 1.5790, 1.0930], device='cuda:0')),\n",
       "              ('ff.13.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.16.weight',\n",
       "               tensor([[ 0.0685,  0.0579, -0.1900, -0.1261, -0.1917, -0.2178, -0.0907, -0.1454,\n",
       "                         0.1123,  0.0764, -0.1361, -0.2015,  0.1140, -0.1197,  0.0917,  0.1394,\n",
       "                         0.1460, -0.2300,  0.1109,  0.1153,  0.0943, -0.2000,  0.0886, -0.2123,\n",
       "                         0.0888, -0.2203, -0.1189, -0.1298, -0.1944,  0.0407, -0.2126, -0.2092]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.16.bias', tensor([-0.0310], device='cuda:0'))]),\n",
       " {'batch_size': 32,\n",
       "  'epochs': 35,\n",
       "  'layers_list': [128, 128, 64, 32],\n",
       "  'lr': 0.001})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f2487f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8405\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8062\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7735\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8413\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8110\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7783\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8445\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8118\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7783\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8421\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8086\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [128, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7648\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8405\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8110\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7711\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8469\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8190\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7775\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8466\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8246\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7799\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8594\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8230\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7855\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8445\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.0005}\n",
      "Best Min(train, val) accuracy for config: 0.8147\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 100, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.0001}\n",
      "Best Min(train, val) accuracy for config: 0.7751\n",
      "\n",
      "Best Config: {'batch_size': 128, 'epochs': 100, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.001} | Best Min Acc: 0.8594\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths (shallow → deep)\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32],\n",
    "        [256, 256, 128, 64, 32],                       # New: deeper and wider\n",
    "        [512, 256, 128, 64, 32],                       # New: even wider\n",
    "        [512, 512, 256, 128, 64, 32],                  # New: deeper\n",
    "        [1024, 512, 256, 128, 64, 32],                 # New: very deep\n",
    "        [512, 512, 512, 256, 128, 64, 32],             # New: 7-layer net\n",
    "    ],\n",
    "    'epochs': [100],                                # Training duration\n",
    "}\n",
    "best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
