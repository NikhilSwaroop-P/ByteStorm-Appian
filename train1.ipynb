{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f83d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Graduation\n",
      "1: PhD\n",
      "2: Master\n",
      "3: Basic\n",
      "4: 2n Cycle\n",
      "0: Single\n",
      "1: Together\n",
      "2: Married\n",
      "3: Divorced\n",
      "4: Widow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\train.csv')\n",
    "test = pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\test.csv')\n",
    "\n",
    "data.replace('Alone', 'Single', inplace=True)\n",
    "test.replace('Absurd', 'Single', inplace=True)\n",
    "data.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('YOLO', 'Single', inplace=True)\n",
    "# test.replace('Alone', 'Single', inplace=True)\n",
    "# data.replace('Together', 'Married', inplace=True)\n",
    "# test.replace('Together', 'Married', inplace=True)\n",
    "\n",
    "# test.replace('Basic', '2n Cycle', inplace=True)\n",
    "# data.replace('Basic', '2n Cycle', inplace=True)\n",
    "# test.replace('Widow', 'Divorced', inplace=True)\n",
    "# data.replace('Widow', 'Divorced', inplace=True)\n",
    "\n",
    "data['Dt_Customer_1'] = pd.to_datetime(data['Dt_Customer'],format='mixed')\n",
    "data['Dt_Customer_1'] = data['Dt_Customer_1']-min(data['Dt_Customer_1'])\n",
    "data['Dates']=data['Dt_Customer_1'].dt.days\n",
    "\n",
    "test['Dt_Customer_1'] = pd.to_datetime(test['Dt_Customer'],format='mixed')\n",
    "test['Dt_Customer_1'] = test['Dt_Customer_1']-min(test['Dt_Customer_1'])\n",
    "test['Dates']=test['Dt_Customer_1'].dt.days\n",
    "Education = {}\n",
    "Marital_status = {}\n",
    "A = data['Education'].unique()\n",
    "B = data['Marital_Status'].unique()\n",
    "# A = test['Education'].unique()\n",
    "# B = test['Marital_Status'].unique()\n",
    "for i, category in enumerate(A):\n",
    "    l = [0]*len(A)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Education[category] = i\n",
    "for i, category in enumerate(B):\n",
    "    l = [0]*len(B)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Marital_status[category] = i\n",
    "data['Education'] = data['Education'].map(Education)\n",
    "test['Education'] = test['Education'].map(Education)\n",
    "data['Marital_Status'] = data['Marital_Status'].map(Marital_status)\n",
    "test['Marital_Status'] = test['Marital_Status'].map(Marital_status)\n",
    "\n",
    "# data = pd.get_dummies(data, columns=['Marital_Status', 'Education'], drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=['Marital_Status', 'Education'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886dc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype          \n",
      "---  ------               --------------  -----          \n",
      " 0   ID                   1567 non-null   int64          \n",
      " 1   Year_Birth           1567 non-null   int64          \n",
      " 2   Education            1567 non-null   int64          \n",
      " 3   Marital_Status       1567 non-null   int64          \n",
      " 4   Income               1550 non-null   float64        \n",
      " 5   Kidhome              1567 non-null   int64          \n",
      " 6   Teenhome             1567 non-null   int64          \n",
      " 7   Dt_Customer          1567 non-null   object         \n",
      " 8   Recency              1567 non-null   int64          \n",
      " 9   MntWines             1544 non-null   float64        \n",
      " 10  MntFruits            1567 non-null   int64          \n",
      " 11  MntMeatProducts      1561 non-null   float64        \n",
      " 12  MntFishProducts      1567 non-null   int64          \n",
      " 13  MntSweetProducts     1567 non-null   int64          \n",
      " 14  MntGoldProds         1555 non-null   float64        \n",
      " 15  NumDealsPurchases    1567 non-null   int64          \n",
      " 16  NumWebPurchases      1567 non-null   int64          \n",
      " 17  NumCatalogPurchases  1567 non-null   int64          \n",
      " 18  NumStorePurchases    1567 non-null   int64          \n",
      " 19  NumWebVisitsMonth    1567 non-null   int64          \n",
      " 20  AcceptedCmp3         1567 non-null   int64          \n",
      " 21  AcceptedCmp4         1567 non-null   int64          \n",
      " 22  AcceptedCmp5         1567 non-null   int64          \n",
      " 23  AcceptedCmp1         1567 non-null   int64          \n",
      " 24  AcceptedCmp2         1567 non-null   int64          \n",
      " 25  Complain             1567 non-null   int64          \n",
      " 26  Z_CostContact        1567 non-null   int64          \n",
      " 27  Z_Revenue            1567 non-null   int64          \n",
      " 28  Target               1567 non-null   int64          \n",
      " 29  Dt_Customer_1        1567 non-null   timedelta64[ns]\n",
      " 30  Dates                1567 non-null   int64          \n",
      "dtypes: float64(4), int64(25), object(1), timedelta64[ns](1)\n",
      "memory usage: 379.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ca3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categorical_cols = ['Education', 'Marital_Status']\n",
    "numerical_cols = [\n",
    "    'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'Complain',\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "    'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
    "    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4',\n",
    "    'AcceptedCmp5', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumWebVisitsMonth', 'Dates'\n",
    "]\n",
    "lists = [\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    # 'Marital_Status_Married',\n",
    "    # 'Marital_Status_Single',\n",
    "    # 'Education_Graduation',\n",
    "    # 'Education_Master',\n",
    "    # 'Education_PhD',\n",
    "    'Marital_Status',\n",
    "    'Education'\n",
    "    # 'Target'\n",
    "]\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col='Target'):\n",
    "        self.X = df[feature_cols].values.astype('float32')\n",
    "        self.y = df[target_col].values.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.X[idx], dtype=torch.float),\n",
    "            'target': torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        }\n",
    "        # return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n",
    "\n",
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomerDataset(data, lists, target_col='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8387d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImputationLayer(nn.Module):\n",
    "    def __init__(self, default_values):\n",
    "        super(ImputationLayer, self).__init__()\n",
    "        self.impute = nn.Parameter(torch.tensor(default_values, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.isnan(x)\n",
    "        x[mask] = self.impute.expand(x.shape[0], -1)[mask]\n",
    "        return x\n",
    "\n",
    "class TrainableScaler(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(TrainableScaler, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(num_features))\n",
    "        self.std = nn.Parameter(torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "class MarketResearchModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, emb_sizes = [3,4], layers_list=[64, 32, 1], default_values=default_values, drop = 0.6):\n",
    "        super(MarketResearchModel, self).__init__()\n",
    "\n",
    "        # Imputation and scaling layers\n",
    "        self.imputer = ImputationLayer(default_values)  # Replace with actual means\n",
    "        self.scaler = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embedding_1 = nn.Embedding(num_embeddings=emb_sizes[0], embedding_dim=10)  # for class feature -6 to -3\n",
    "        self.embedding_2 = nn.Embedding(num_embeddings=emb_sizes[1], embedding_dim=10)  # for class feature -3 to -1\n",
    "\n",
    "        # Input size for FFN\n",
    "        input_size = num_numeric_features + 20\n",
    "\n",
    "        # Build feedforward layers dynamically\n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        for out_dim in layers_list:\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                layers.append(nn.BatchNorm1d(out_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        if layers_list[-1] != 1:\n",
    "            layers.append(nn.Linear(in_dim, 1))\n",
    "        # layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.ff = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_numeric = x[:, :-2]\n",
    "        # x_cat1 = x[:, -5:-3].long()\n",
    "        # x_cat2 = x[:, -3:-1].long()\n",
    "        x_cat1 = x[:,-2:-1].long()\n",
    "        x_cat2 = x[:,-1:].long()\n",
    "        # print(x_numeric.shape, x_cat1.shape, x_cat2.shape)\n",
    "        x_numeric = self.imputer(x_numeric)\n",
    "        x_numeric = self.scaler(x_numeric)\n",
    "\n",
    "        emb1 = self.embedding_1(x_cat1).squeeze(1)\n",
    "        emb2 = self.embedding_2(x_cat2).squeeze(1)\n",
    "        # print(emb1.shape, emb2.shape, x_numeric.shape)\n",
    "        x = torch.cat([x_numeric, emb1, emb2], dim=1)\n",
    "        return self.ff(x).squeeze(1)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GLULayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GLULayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim * 2)\n",
    "        self.bn = nn.BatchNorm1d(output_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.fc(x))\n",
    "        out, gate = x.chunk(2, dim=-1)\n",
    "        return out * torch.sigmoid(gate)\n",
    "\n",
    "class FeatureTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.bn(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.relu(x + res)\n",
    "\n",
    "class TabInspiredMarketModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_numeric_features,\n",
    "        emb_sizes=[3,4],\n",
    "        default_values=default_values,\n",
    "        hidden_dim=128,\n",
    "        depth=4,\n",
    "        layers_list=[64,32,1],\n",
    "        drop=0.6\n",
    "    ):\n",
    "        super(TabInspiredMarketModel, self).__init__()\n",
    "\n",
    "        # Imputation + scaling\n",
    "        self.imputer = ImputationLayer(default_values)\n",
    "        self.scaler  = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # Embeddings\n",
    "        self.embedding_1 = nn.Embedding(emb_sizes[0], 5)\n",
    "        self.embedding_2 = nn.Embedding(emb_sizes[1], 5)\n",
    "\n",
    "        # Initial GLU block\n",
    "        input_dim = num_numeric_features + 10\n",
    "        self.glu_layer = GLULayer(input_dim, hidden_dim)\n",
    "\n",
    "        # TabNet‑style transformer blocks\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[FeatureTransformerBlock(hidden_dim) for _ in range(depth)]\n",
    "        )\n",
    "\n",
    "        # Dynamically built FF head\n",
    "        ff_layers = []\n",
    "        in_dim = hidden_dim\n",
    "        for out_dim in layers_list:\n",
    "            ff_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                ff_layers.append(nn.BatchNorm1d(out_dim))\n",
    "                ff_layers.append(nn.ReLU())\n",
    "                ff_layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        # if the last layer isn’t single‑unit, add one more\n",
    "        if layers_list[-1] != 1:\n",
    "            ff_layers.append(nn.Linear(in_dim, 1))\n",
    "        # ff_layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.output = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # split numeric / cat\n",
    "        x_num  = x[:, :-2]\n",
    "        cat1   = x[:, -2:-1].long()\n",
    "        cat2   = x[:, -1:  ].long()\n",
    "\n",
    "        # impute + scale\n",
    "        x_num = self.imputer(x_num)\n",
    "        x_num = self.scaler(x_num)\n",
    "\n",
    "        # embed cats\n",
    "        e1 = self.embedding_1(cat1).squeeze(1)\n",
    "        e2 = self.embedding_2(cat2).squeeze(1)\n",
    "\n",
    "        # concat\n",
    "        x = torch.cat([x_num, e1, e2], dim=1)\n",
    "\n",
    "        # GLU + transformer blocks\n",
    "        x = self.glu_layer(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "\n",
    "        # final head\n",
    "        return self.output(x).squeeze(1)\n",
    "\n",
    "class TabInspiredMarketModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_numeric_features,\n",
    "        emb_sizes=[3,4],\n",
    "        default_values=default_values,\n",
    "        hidden_dim=128,\n",
    "        depth=4,\n",
    "        layers_list=[64,32,1],\n",
    "        drop=0.3,\n",
    "        n_heads=8\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Imputation & Scaling\n",
    "        self.imputer = ImputationLayer(default_values)\n",
    "        self.scaler  = TrainableScaler(num_features=num_numeric_features)\n",
    "\n",
    "        # 2) Categoricals → Embeddings\n",
    "        self.embedding_1 = nn.Embedding(emb_sizes[0], 5)\n",
    "        self.embedding_2 = nn.Embedding(emb_sizes[1], 5)\n",
    "\n",
    "        # 3) Project each scalar feature → hidden_dim token\n",
    "        self.num_proj  = nn.Linear(1,     hidden_dim)\n",
    "        self.cat_proj1 = nn.Linear(5,     hidden_dim)\n",
    "        self.cat_proj2 = nn.Linear(5,     hidden_dim)\n",
    "\n",
    "        # 4) Self‑Attention across the (N_numeric + 2) tokens\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=n_heads,\n",
    "            dropout=drop,\n",
    "            batch_first=False  # nn.MultiheadAttention defaults to (seq_len, batch, embed_dim)\n",
    "        )\n",
    "\n",
    "        # 5) GLU + TabNet‑style blocks\n",
    "        self.glu_layer         = GLULayer(hidden_dim, hidden_dim)\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[FeatureTransformerBlock(hidden_dim) for _ in range(depth)]\n",
    "        )\n",
    "\n",
    "        # 6) Dynamically built FFN head\n",
    "        ff_layers = []\n",
    "        in_dim = hidden_dim\n",
    "        for out_dim in layers_list:\n",
    "            ff_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != 1:\n",
    "                ff_layers.append(nn.BatchNorm1d(out_dim))\n",
    "                ff_layers.append(nn.ReLU())\n",
    "                ff_layers.append(nn.Dropout(drop))\n",
    "            in_dim = out_dim\n",
    "        if layers_list[-1] != 1:\n",
    "            ff_layers.append(nn.Linear(in_dim, 1))\n",
    "        self.output = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split numeric vs. categorical indices\n",
    "        x_num = x[:, :-2]                     # [B, N_num]\n",
    "        cat1  = x[:, -2:-1].long()            # [B, 1]\n",
    "        cat2  = x[:, -1:  ].long()            # [B, 1]\n",
    "\n",
    "        # 1) Impute & scale\n",
    "        x_num = self.imputer(x_num)           # [B, N_num]\n",
    "        x_num = self.scaler(x_num)            # [B, N_num]\n",
    "\n",
    "        # 2) Embed categories\n",
    "        e1 = self.embedding_1(cat1).squeeze(1)  # [B, 5]\n",
    "        e2 = self.embedding_2(cat2).squeeze(1)  # [B, 5]\n",
    "\n",
    "        # 3) Build token sequence\n",
    "        num_tokens = self.num_proj(x_num.unsqueeze(-1))  # [B, N_num, H]\n",
    "        c1_token   = self.cat_proj1(e1).unsqueeze(1)     # [B, 1, H]\n",
    "        c2_token   = self.cat_proj2(e2).unsqueeze(1)     # [B, 1, H]\n",
    "\n",
    "        tokens = torch.cat([num_tokens, c1_token, c2_token], dim=1)  # [B, N_num+2, H]\n",
    "        tokens_t = tokens.transpose(0, 1)                            # [seq_len, B, H]\n",
    "\n",
    "        # 4) Self-attention\n",
    "        attn_out, _ = self.attention(tokens_t, tokens_t, tokens_t)  # [seq_len, B, H]\n",
    "        x = attn_out.mean(dim=0)                                    # [B, H]\n",
    "\n",
    "        # 5) GLU + Transformer blocks\n",
    "        x = self.glu_layer(x)                                       # [B, H]\n",
    "        x = self.transformer_blocks(x)                              # [B, H]\n",
    "\n",
    "        # 6) Final FF head\n",
    "        return self.output(x).squeeze(1)                            # [B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "408b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketResearchModel = TabInspiredMarketModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0381df59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TabInspiredMarketModel.__init__(self, num_numeric_features, emb_sizes=[3, 4], default_values=Year_Birth              1968.838545\n",
       "Income                 52024.465806\n",
       "Kidhome                    0.449904\n",
       "Teenhome                   0.499681\n",
       "Dates                    549.746011\n",
       "Recency                   49.345884\n",
       "MntWines                 304.301813\n",
       "MntFruits                 25.941289\n",
       "MntMeatProducts          165.313901\n",
       "MntFishProducts           37.271219\n",
       "MntSweetProducts          27.125080\n",
       "MntGoldProds              44.187781\n",
       "NumWebPurchases            4.032546\n",
       "NumCatalogPurchases        2.674537\n",
       "NumStorePurchases          5.776005\n",
       "NumDealsPurchases          2.332482\n",
       "NumWebVisitsMonth          5.325463\n",
       "AcceptedCmp1               0.063178\n",
       "AcceptedCmp2               0.012125\n",
       "AcceptedCmp3               0.072112\n",
       "AcceptedCmp4               0.076579\n",
       "AcceptedCmp5               0.070198\n",
       "Complain                   0.010211\n",
       "dtype: float64, hidden_dim=128, depth=4, layers_list=[64, 32, 1], drop=0.3, n_heads=8)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarketResearchModel.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e77973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = data.mean(numeric_only=True)\n",
    "default_values = means[lists[:-2]]\n",
    "model = MarketResearchModel(num_numeric_features=len(lists)-2, emb_sizes=[3,4], layers_list=[64, 32, 1], default_values=default_values).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27ed6e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "TabInspiredMarketModel                   [3, 25]                   [3]                       --                        --                        --\n",
       "├─ImputationLayer: 1-1                   [3, 23]                   [3, 23]                   23                        --                        --\n",
       "├─TrainableScaler: 1-2                   [3, 23]                   [3, 23]                   46                        --                        --\n",
       "├─Embedding: 1-3                         [3, 1]                    [3, 1, 5]                 15                        --                        45\n",
       "├─Embedding: 1-4                         [3, 1]                    [3, 1, 5]                 20                        --                        60\n",
       "├─Linear: 1-5                            [3, 23, 1]                [3, 23, 128]              256                       --                        768\n",
       "├─Linear: 1-6                            [3, 5]                    [3, 128]                  768                       --                        2,304\n",
       "├─Linear: 1-7                            [3, 5]                    [3, 128]                  768                       --                        2,304\n",
       "├─MultiheadAttention: 1-8                [25, 3, 128]              [25, 3, 128]              66,048                    --                        --\n",
       "├─GLULayer: 1-9                          [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    └─Linear: 2-1                       [3, 128]                  [3, 256]                  33,024                    --                        99,072\n",
       "│    └─BatchNorm1d: 2-2                  [3, 256]                  [3, 256]                  512                       --                        1,536\n",
       "├─Sequential: 1-10                       [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    └─FeatureTransformerBlock: 2-3      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-1                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-2             [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-3                 [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-4                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-4      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-5                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-6             [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-7                 [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-8                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-5      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-9                  [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-10            [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-11                [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-12                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    └─FeatureTransformerBlock: 2-6      [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-13                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "│    │    └─BatchNorm1d: 3-14            [3, 128]                  [3, 128]                  256                       --                        768\n",
       "│    │    └─Dropout: 3-15                [3, 128]                  [3, 128]                  --                        --                        --\n",
       "│    │    └─Linear: 3-16                 [3, 128]                  [3, 128]                  16,512                    --                        49,536\n",
       "├─Sequential: 1-11                       [3, 128]                  [3, 1]                    --                        --                        --\n",
       "│    └─Linear: 2-7                       [3, 128]                  [3, 64]                   8,256                     --                        24,768\n",
       "│    └─BatchNorm1d: 2-8                  [3, 64]                   [3, 64]                   128                       --                        384\n",
       "│    └─ReLU: 2-9                         [3, 64]                   [3, 64]                   --                        --                        --\n",
       "│    └─Dropout: 2-10                     [3, 64]                   [3, 64]                   --                        --                        --\n",
       "│    └─Linear: 2-11                      [3, 64]                   [3, 32]                   2,080                     --                        6,240\n",
       "│    └─BatchNorm1d: 2-12                 [3, 32]                   [3, 32]                   64                        --                        192\n",
       "│    └─ReLU: 2-13                        [3, 32]                   [3, 32]                   --                        --                        --\n",
       "│    └─Dropout: 2-14                     [3, 32]                   [3, 32]                   --                        --                        --\n",
       "│    └─Linear: 2-15                      [3, 32]                   [3, 1]                    33                        --                        99\n",
       "=====================================================================================================================================================================\n",
       "Total params: 245,161\n",
       "Trainable params: 245,161\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.54\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.13\n",
       "Params size (MB): 0.72\n",
       "Estimated Total Size (MB): 0.85\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "summary(model, input_size=(3, len(lists)), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06a631e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21020\\2073335113.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m     from . import (\n\u001b[0;32m     81\u001b[0m         \u001b[0m__check_build\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     __all__ = [\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Make _safe_indexing importable from here for backward compat as this particular\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchunk_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mInvalidParameterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_isfinite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFiniteStatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy_isfinite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"array_api_compat.numpy\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    606\u001b[0m \"\"\"  # noqa: E501\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 610\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_morestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Import unused here but needs to stay until end of deprecation periode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_mstats_common\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_find_repeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheilslopes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiegelslopes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_continuous_distns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\monar\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m  12166\u001b[0m \u001b[0mrel_breitwigner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_breitwigner_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rel_breitwigner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12169\u001b[0m \u001b[1;31m# Collect names of classes and objects in this module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 12170\u001b[1;33m \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  12171\u001b[0m \u001b[0m_distn_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_distn_gen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_distribution_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12173\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_distn_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_distn_gen_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'rv_histogram'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_acc = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "        # print(dataset[0][\"features\"].shape[0] - 2, emb_sizes, config['layers_list'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "            best_config = config\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Validation Accuracy: {best_acc:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [15, 25],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d25ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import warnings\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Suppose your DataFrame is df and your binary target column is 'Target'\n",
    "y = data['Target'].values\n",
    "\n",
    "# Compute weights for each class label (0 and 1)\n",
    "classes = np.unique(y)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "w0, w1 = class_weights\n",
    "# --- Training & Evaluation ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "        x = x_all[:, :-2]\n",
    "        cat1 = x_all[:, -2].long()\n",
    "        cat2 = x_all[:, -1].long()\n",
    "        x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "        x_all = x_all.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_all)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Reuse evaluate for both train and validation\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_all, y = batch[\"features\"], batch[\"target\"]\n",
    "            x = x_all[:, :-2]\n",
    "            cat1 = x_all[:, -2].long()\n",
    "            cat2 = x_all[:, -1].long()\n",
    "            x, y, cat1, cat2 = x.to(device), y.to(device), cat1.to(device), cat2.to(device)\n",
    "            x_all = x_all.to(device)\n",
    "            pred = model(x_all)\n",
    "            # Apply sigmoid activation to get probabilities\n",
    "            pred = torch.sigmoid(pred)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    preds = torch.cat(all_preds) > 0.5\n",
    "    labels = torch.cat(all_labels)\n",
    "    return accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "def run_tuning(dataset, emb_sizes, param_grid, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    best_global_score = 0\n",
    "    best_model_state = None\n",
    "    best_config = None\n",
    "\n",
    "    val_len = int(0.2 * len(dataset))\n",
    "    train_len = len(dataset) - val_len\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    for config in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTraining config: {config}\")\n",
    "        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config['batch_size'])\n",
    "\n",
    "        model = MarketResearchModel(\n",
    "            num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "            emb_sizes=emb_sizes,\n",
    "            layers_list=config['layers_list']\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(w1/w0).to(device))\n",
    "\n",
    "        best_config_score = 0\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            train_acc = evaluate(model, train_loader, device)\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            epoch_score = min(train_acc, val_acc)\n",
    "            best_config_score = max(best_config_score, epoch_score)\n",
    "            # print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} | Train Acc={train_acc:.4f} | Val Acc={val_acc:.4f} | Min Acc={epoch_score:.4f}\")\n",
    "            if epoch_score > best_global_score:\n",
    "                best_global_score = best_config_score\n",
    "                best_model_state = model.state_dict()\n",
    "                best_config = config\n",
    "\n",
    "        print(f\"Best Min(train, val) accuracy for config: {best_config_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"\\nBest Config: {best_config} | Best Min Acc: {best_global_score:.4f}\")\n",
    "    return best_model_state, best_config\n",
    "\n",
    "# --- Example Run ---\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 1e-2],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32]\n",
    "    ],\n",
    "    'epochs': [25, 35],                                # Training duration\n",
    "}\n",
    "\n",
    "# To run: best_state, best_params = run_tuning(dataset, emb_sizes=[3, 4], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8256466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8083\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7807\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7831\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7855\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8115\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7951\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8147\n",
      "\n",
      "Training config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7987\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7796\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7879\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7815\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7687\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7831\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7827\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8006\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7891\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8006\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7668\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8054\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7568\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7923\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7520\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7955\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7380\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 25, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8019\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7815\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8022\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7636\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.7859\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7767\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [256, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.7700\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 35, 'layers_list': [128, 128, 64, 32], 'lr': 0.01}\n",
      "Best Min(train, val) accuracy for config: 0.8051\n",
      "\n",
      "Best Config: {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001} | Best Min Acc: 0.8307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('imputer.impute',\n",
       "               tensor([1.9688e+03, 5.2024e+04, 4.4990e-01, 4.9968e-01, 5.4975e+02, 4.9346e+01,\n",
       "                       3.0460e+02, 2.5941e+01, 1.6541e+02, 3.7271e+01, 2.7125e+01, 4.4283e+01,\n",
       "                       4.0325e+00, 2.6745e+00, 5.7760e+00, 2.3325e+00, 5.3255e+00, 6.3178e-02,\n",
       "                       1.2125e-02, 7.2112e-02, 7.6579e-02, 7.0198e-02, 1.0211e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('scaler.mean',\n",
       "               tensor([-3.0499e-05, -1.0238e-06, -4.2948e-05, -2.2048e-03,  4.6394e-05,\n",
       "                       -1.6666e-03,  5.8338e-05,  1.7489e-05,  3.7192e-05, -1.0846e-05,\n",
       "                        6.0739e-05, -4.4894e-06,  1.9130e-03,  1.4218e-05, -3.3947e-05,\n",
       "                       -1.9254e-04, -2.5995e-03, -2.0811e-03,  9.2507e-05,  2.1943e-02,\n",
       "                       -4.3273e-03, -1.0172e-02, -6.3790e-05], device='cuda:0')),\n",
       "              ('scaler.std',\n",
       "               tensor([ 0.8879,  1.6519,  0.6460,  0.0257,  1.1131,  0.1214,  0.6902,  0.9798,\n",
       "                        1.0779,  1.0050,  1.0284,  0.8863,  0.0212,  0.8693,  0.8083,  0.0710,\n",
       "                        0.0286,  0.0205,  0.4811,  0.0038, -0.0318, -0.0276,  0.9499],\n",
       "                      device='cuda:0')),\n",
       "              ('embedding_1.weight',\n",
       "               tensor([[ 0.6738, -0.9576,  1.7890, -1.0090, -0.7615,  0.0515,  0.3811, -1.2652,\n",
       "                         0.1315,  1.0034],\n",
       "                       [-0.2761,  2.3895,  0.0605,  0.5959, -0.2769,  0.0128, -0.4977,  0.2234,\n",
       "                         0.2883,  0.8804],\n",
       "                       [ 0.7641,  0.6655,  0.2201,  0.2389, -0.1426, -0.0164, -0.7585, -0.9290,\n",
       "                         0.9223, -0.8896],\n",
       "                       [-0.1291,  0.8222, -0.0918,  0.8704,  0.1889,  0.5084, -0.1828,  0.7833,\n",
       "                        -1.3526, -0.8706],\n",
       "                       [-0.5510,  0.0860, -2.5076, -2.1432,  0.6094,  0.5707,  1.8806, -0.7619,\n",
       "                        -0.0121, -1.4607]], device='cuda:0')),\n",
       "              ('embedding_2.weight',\n",
       "               tensor([[-0.9614,  2.1056, -0.1725,  0.5816,  0.7110,  1.3269,  0.6279, -1.0441,\n",
       "                        -0.4217,  0.3220],\n",
       "                       [ 0.1105, -1.8366, -1.1718, -0.2642, -3.2714,  0.5886,  0.0455,  0.3020,\n",
       "                         0.9831, -1.3934],\n",
       "                       [ 1.5168,  1.5172,  0.9976,  2.7821,  1.0010,  0.1280, -0.7838, -1.6063,\n",
       "                        -1.7559,  0.3571],\n",
       "                       [-0.1545, -0.0257,  0.9410, -0.3492, -0.7850,  0.4516, -0.9435,  0.1995,\n",
       "                        -2.3640, -0.1665],\n",
       "                       [ 1.3486, -0.8951,  1.5955, -0.9024, -0.2621,  1.5015,  1.1351, -0.4718,\n",
       "                         0.0099, -0.3581]], device='cuda:0')),\n",
       "              ('ff.0.weight',\n",
       "               tensor([[-0.0153,  0.0377, -0.1321,  ..., -0.1531, -0.0999,  0.1166],\n",
       "                       [-0.0741,  0.1396, -0.1383,  ..., -0.0234, -0.0472, -0.0195],\n",
       "                       [ 0.2014, -0.0042,  0.0351,  ...,  0.2349,  0.0887, -0.1953],\n",
       "                       ...,\n",
       "                       [ 0.1746, -0.0209,  0.2962,  ...,  0.1153, -0.0235, -0.0857],\n",
       "                       [-0.1959, -0.0138, -0.0171,  ..., -0.2682,  0.0013,  0.0291],\n",
       "                       [-0.1603, -0.0351, -0.0271,  ...,  0.0747,  0.0379,  0.2212]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.0.bias',\n",
       "               tensor([ 0.1388, -0.1026,  0.1045,  0.0150,  0.0731, -0.1186,  0.0797,  0.0462,\n",
       "                       -0.1324,  0.0612,  0.0667,  0.1379, -0.1106,  0.1313, -0.1479, -0.1190,\n",
       "                        0.1461, -0.0559,  0.0093,  0.0994, -0.1187,  0.1441,  0.0193, -0.0832,\n",
       "                        0.0825, -0.1375,  0.1034,  0.0692, -0.0202, -0.0345,  0.0433, -0.1241,\n",
       "                        0.0826, -0.0668, -0.0817,  0.1048,  0.0831,  0.0852,  0.0885,  0.1221,\n",
       "                        0.1265,  0.0752, -0.0937, -0.0316,  0.1483,  0.0707, -0.1345,  0.0124,\n",
       "                       -0.0757, -0.0897, -0.1397,  0.0060,  0.0375,  0.0618, -0.1187,  0.1486,\n",
       "                        0.0784, -0.0273, -0.1179,  0.0682,  0.0513, -0.0133,  0.0772, -0.0436,\n",
       "                        0.0762,  0.0543, -0.0064,  0.0543,  0.0703, -0.0083, -0.0149, -0.1243,\n",
       "                       -0.1409,  0.1342, -0.1368, -0.1057,  0.0405, -0.0865, -0.0002, -0.1320,\n",
       "                        0.1370, -0.0159, -0.1270,  0.1387, -0.0764,  0.0118, -0.1364,  0.0267,\n",
       "                       -0.0975,  0.0626, -0.1496, -0.0200, -0.1501,  0.0487,  0.0285, -0.1242,\n",
       "                        0.0692,  0.0359, -0.0800,  0.0186, -0.1117, -0.0599,  0.1164,  0.1126,\n",
       "                       -0.0169,  0.1085,  0.0195,  0.0633,  0.0455, -0.1424,  0.0322,  0.1093,\n",
       "                       -0.0672, -0.1005, -0.1196,  0.0635,  0.1468,  0.0054,  0.0826,  0.0249,\n",
       "                        0.0090, -0.1136,  0.0933, -0.1105,  0.1475,  0.0784,  0.0723,  0.0032],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.weight',\n",
       "               tensor([0.9365, 0.9454, 0.9674, 1.0082, 0.9969, 0.9729, 0.9958, 0.9286, 0.9647,\n",
       "                       0.9667, 1.0443, 0.9424, 0.9184, 0.9242, 0.9492, 1.0762, 1.0240, 0.9731,\n",
       "                       1.0187, 0.9581, 0.8987, 0.9984, 0.9535, 1.0016, 1.0106, 0.9906, 1.0743,\n",
       "                       1.0446, 1.0455, 1.0011, 1.0058, 1.1167, 0.9857, 1.0648, 1.0335, 0.9806,\n",
       "                       1.0887, 0.9308, 0.9795, 0.9738, 1.1179, 0.9540, 0.9734, 1.0192, 1.1706,\n",
       "                       1.0699, 1.0078, 1.0615, 0.9758, 0.9439, 0.9470, 0.8924, 1.0828, 0.9635,\n",
       "                       0.9871, 1.0027, 0.9662, 0.9316, 0.9660, 1.1013, 1.0313, 0.9842, 1.1299,\n",
       "                       1.0853, 1.0591, 1.0509, 1.1226, 0.9650, 0.9600, 0.9640, 0.9162, 0.9456,\n",
       "                       0.9889, 0.9665, 0.9669, 0.9523, 1.0657, 1.0636, 1.0565, 0.9477, 0.9222,\n",
       "                       0.9966, 0.9465, 0.9792, 1.0122, 0.9940, 1.0543, 0.9795, 0.9641, 1.0102,\n",
       "                       0.9987, 0.9387, 0.9686, 0.9332, 0.9366, 0.9563, 1.0374, 1.0581, 1.0294,\n",
       "                       0.9326, 0.9570, 0.9700, 0.9758, 1.0335, 0.9661, 0.9688, 1.1512, 0.9907,\n",
       "                       0.9938, 0.9272, 0.9466, 0.9220, 0.9807, 0.9371, 0.9366, 0.8990, 0.9887,\n",
       "                       0.9781, 1.0241, 0.9519, 1.0223, 1.0507, 0.9810, 0.9718, 0.9414, 1.0065,\n",
       "                       1.0051, 1.0004], device='cuda:0')),\n",
       "              ('ff.1.bias',\n",
       "               tensor([-0.0790, -0.0345, -0.0835, -0.0364, -0.0536, -0.0484, -0.0390, -0.0418,\n",
       "                       -0.0564, -0.0615,  0.0126, -0.0575, -0.0639, -0.1185, -0.0547,  0.1546,\n",
       "                       -0.0166, -0.0803, -0.0479, -0.0151, -0.1001,  0.0459, -0.0296, -0.0036,\n",
       "                       -0.0026, -0.0112,  0.0550,  0.0651,  0.0377, -0.0148, -0.0027,  0.0394,\n",
       "                       -0.0440,  0.0535,  0.0688, -0.0245, -0.0037, -0.0743, -0.0552, -0.0573,\n",
       "                       -0.0082, -0.0681, -0.0168,  0.0349,  0.0440,  0.0582, -0.0002,  0.0358,\n",
       "                       -0.0083, -0.0273, -0.0504, -0.1125,  0.0725, -0.0248, -0.0344, -0.0450,\n",
       "                       -0.0213, -0.0684, -0.0388,  0.0269,  0.0363, -0.0423, -0.0028,  0.0866,\n",
       "                        0.1400, -0.0290,  0.0691, -0.0173, -0.0671, -0.0964, -0.1112, -0.0648,\n",
       "                       -0.0334, -0.0491, -0.0741, -0.0430, -0.0416, -0.0212, -0.0167, -0.0702,\n",
       "                       -0.0715,  0.0004, -0.0792, -0.0587, -0.0552, -0.0402, -0.0106, -0.0559,\n",
       "                       -0.0430, -0.0424, -0.0004, -0.0365, -0.0666, -0.0679, -0.0615, -0.0776,\n",
       "                        0.0433,  0.0864, -0.0027, -0.0883, -0.0615, -0.0205, -0.0380,  0.0251,\n",
       "                       -0.0568, -0.0154,  0.0372, -0.0552, -0.0108, -0.0661, -0.0857, -0.1022,\n",
       "                       -0.0343, -0.0838, -0.0528, -0.1011, -0.0043, -0.0360,  0.0011, -0.0557,\n",
       "                       -0.0091, -0.0406, -0.0505,  0.0307, -0.0714, -0.0694, -0.0026, -0.0487],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.1.running_mean',\n",
       "               tensor([ 1.2678e+03,  4.1540e+03,  2.1833e+02,  8.8464e+01, -1.0896e+03,\n",
       "                        2.8589e+02, -6.2235e+02, -1.1087e+03,  1.1923e+02,  8.7652e+02,\n",
       "                        7.9491e+01,  6.8681e+02, -2.9427e+03,  8.7178e+01,  1.4407e+03,\n",
       "                        3.1589e+02, -4.6027e+01,  1.6800e+03,  5.0187e-01, -1.7306e+02,\n",
       "                        1.7363e+03,  4.9755e+01, -2.7658e+03, -7.5177e+02, -3.8425e+02,\n",
       "                       -3.9649e+02,  8.8864e+00, -4.2275e+02,  5.1950e+02,  2.8739e+02,\n",
       "                       -6.6489e+02,  1.5200e+02,  7.5964e+02,  8.3537e+01,  2.0543e+02,\n",
       "                        8.3780e+02, -4.4082e+02, -8.7719e+02, -2.9328e+03,  1.5990e+03,\n",
       "                       -1.2624e+02, -1.1254e+03, -2.7586e+02,  1.7255e+02,  9.6181e+01,\n",
       "                       -4.2030e+02,  2.8976e+03,  2.1386e+02,  2.1627e+03, -7.9045e+02,\n",
       "                       -5.5540e+02,  1.5230e+03,  2.8895e+02,  2.6919e+02, -3.8052e+02,\n",
       "                       -4.8536e+02,  4.3938e+03, -1.0189e+03,  1.0715e+03, -2.5125e+02,\n",
       "                        1.2375e+01, -3.0733e+02, -2.1008e+02, -1.6462e+02, -1.8514e+02,\n",
       "                        6.8781e+02, -3.4896e+01, -8.0393e+02, -5.4800e+02,  1.9929e+02,\n",
       "                        1.1337e+03, -9.8913e+02, -1.5830e+03,  4.0014e+02, -1.1026e+03,\n",
       "                       -1.1012e+03,  2.0123e+02, -5.6520e+02,  3.1983e+02,  8.3797e+02,\n",
       "                       -8.7363e+02, -1.3800e+03, -3.3241e+03, -4.4260e+02, -2.0255e+02,\n",
       "                       -3.2894e+03, -4.3283e+02,  6.6941e+02,  5.6881e+02, -2.1035e+02,\n",
       "                        7.7004e+01, -4.4910e+02,  3.2087e+02,  1.8002e+03,  1.2150e+02,\n",
       "                        3.6361e+03, -2.3157e+02, -3.7785e+02,  3.0674e+01,  3.6897e+02,\n",
       "                       -1.0848e+03, -2.3520e+03, -5.9709e+03, -2.5080e+02, -3.8653e+02,\n",
       "                       -4.7220e+03, -2.3164e+02, -1.1622e+03,  7.1302e+02,  2.0215e+03,\n",
       "                        7.4185e+02, -4.7445e+02,  3.1291e+03, -8.6610e+02, -8.8784e+02,\n",
       "                        1.6566e+02, -5.3228e+03, -8.8626e+02,  7.1053e+01,  9.9477e+02,\n",
       "                       -3.9861e+02, -3.2267e+02,  2.6448e+03, -7.0516e+01,  1.7366e+03,\n",
       "                       -2.8982e+02, -8.0081e+02, -1.4984e+03], device='cuda:0')),\n",
       "              ('ff.1.running_var',\n",
       "               tensor([ 308481.9688, 3597737.5000,   36302.9883,   42614.3672,  115320.6484,\n",
       "                         12905.2676,  111862.4375,  200724.9688,   32762.7109,  153666.0938,\n",
       "                         19590.6289,  116956.5469, 1242820.5000,   55804.9609,  191226.7969,\n",
       "                         25154.1113,   36291.1094,  529913.5000,   43026.5391,   37986.9844,\n",
       "                        604531.7500,   23491.0527, 1682277.3750,  135560.5000,   75117.9219,\n",
       "                         44788.3750,   23010.7031,   64919.3516,   26381.4473,   58965.8945,\n",
       "                         53056.7656,   43338.3281,   49526.9375,   28741.7695,   27670.5098,\n",
       "                         75422.3047,   44973.7695,  136582.3281, 1945436.3750,  493797.2812,\n",
       "                         25478.8633,  407616.3438,   70775.2109,   45130.9570,   21676.2090,\n",
       "                         58730.6992, 1272456.0000,   32252.7227,  993355.3750,   91789.8828,\n",
       "                         99094.7734,  395703.7500,   24112.3633,   40155.2891,   79601.3750,\n",
       "                         19450.0098, 3887782.0000,  242391.1875,  184362.0625,   39719.0703,\n",
       "                         34014.7852,   38563.1133,   32776.7656,   39392.4727,   28993.9258,\n",
       "                        141313.4844,   21545.9883,   65602.8672,   79690.1875,   40204.5898,\n",
       "                        188081.7031,  197076.3750,  663767.3125,   16341.4160,  251337.6719,\n",
       "                        157805.4062,   23460.4688,   34842.7031,   32952.2031,   64947.5469,\n",
       "                        198734.7344,  346371.1875, 2100010.7500,   42522.3867,   40668.8750,\n",
       "                       2266202.0000,   28734.8652,  110998.1172,   89251.7109,   67566.8750,\n",
       "                         32992.4375,   80427.7500,   19302.6387,  667835.1875,   28158.5918,\n",
       "                       2160923.7500,   51322.7852,   66893.3203,   68493.2109,   32523.8301,\n",
       "                         88309.6406, 1207158.7500, 7845741.0000,   32095.1172,   47744.8867,\n",
       "                       5270218.5000,   43006.8672,  262567.5625,  112219.7344,  874053.6875,\n",
       "                         95556.1016,  107376.7344, 2312760.0000,  135800.7188,  205992.0000,\n",
       "                         49673.5625, 4963264.0000,  144201.2500,   72338.9844,  167428.5625,\n",
       "                         95733.5078,   28838.6270, 1168695.6250,   67084.5625,  665431.7500,\n",
       "                         89512.0703,   44920.7656,  250527.9844], device='cuda:0')),\n",
       "              ('ff.1.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.4.weight',\n",
       "               tensor([[ 0.0231, -0.0411, -0.0074,  ..., -0.0575,  0.0884, -0.0068],\n",
       "                       [ 0.0487, -0.1084, -0.0050,  ..., -0.1030, -0.0229,  0.0756],\n",
       "                       [ 0.0338, -0.0537, -0.0461,  ..., -0.0527, -0.0328,  0.0201],\n",
       "                       ...,\n",
       "                       [ 0.0849,  0.0232,  0.0644,  ...,  0.0437,  0.0754, -0.0562],\n",
       "                       [-0.0310,  0.0591, -0.0496,  ...,  0.0112,  0.0171, -0.0016],\n",
       "                       [-0.0458, -0.0053, -0.0472,  ..., -0.0866, -0.0701,  0.0134]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.4.bias',\n",
       "               tensor([-0.0019,  0.0757, -0.0601, -0.0152, -0.0262, -0.0716, -0.0178,  0.0785,\n",
       "                        0.0344,  0.0577,  0.0598,  0.0575, -0.0692, -0.0316, -0.0004,  0.0785,\n",
       "                       -0.0358,  0.0611, -0.0560,  0.0761, -0.0147,  0.0348, -0.0400, -0.0298,\n",
       "                       -0.0252,  0.0504, -0.0073,  0.0345,  0.0438,  0.0827, -0.0115,  0.0065,\n",
       "                        0.0447, -0.0032,  0.0575, -0.0030, -0.0482,  0.0061,  0.0903,  0.0541,\n",
       "                       -0.0474,  0.0477, -0.0166, -0.0529,  0.0710,  0.0475, -0.0894, -0.0392,\n",
       "                        0.0754, -0.0798,  0.0733,  0.0332,  0.0585, -0.0764, -0.0024,  0.0314,\n",
       "                       -0.0704,  0.0697,  0.0841, -0.0210,  0.0061, -0.0471,  0.0166,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.weight',\n",
       "               tensor([1.0172, 0.9867, 1.0310, 0.9092, 1.0172, 0.9907, 0.9738, 1.0065, 1.0041,\n",
       "                       1.0419, 0.9785, 0.9960, 1.0007, 1.0319, 0.9358, 1.0870, 0.9787, 0.9530,\n",
       "                       1.0533, 1.0156, 0.9809, 1.0297, 0.9898, 0.9704, 1.0538, 0.9821, 0.9820,\n",
       "                       1.0502, 1.0351, 1.0158, 1.0465, 1.0322, 1.0394, 0.9975, 0.8932, 0.8989,\n",
       "                       0.9820, 0.9756, 0.9560, 1.0347, 0.9981, 0.9908, 1.0326, 1.0189, 1.0537,\n",
       "                       1.0095, 0.9478, 1.0474, 1.0289, 0.9109, 1.0272, 0.9866, 0.9885, 0.9816,\n",
       "                       1.0116, 1.0632, 1.0461, 1.0042, 1.0054, 1.0133, 1.0062, 0.9279, 0.9360,\n",
       "                       1.0385], device='cuda:0')),\n",
       "              ('ff.5.bias',\n",
       "               tensor([-0.0047, -0.0232, -0.0446, -0.0858,  0.0282, -0.0193, -0.0004,  0.0033,\n",
       "                       -0.0084,  0.0441, -0.0473, -0.0390,  0.0089, -0.0147, -0.0345,  0.0667,\n",
       "                        0.0149, -0.0374, -0.0034, -0.0439, -0.0597,  0.0041, -0.0139, -0.0529,\n",
       "                        0.0639, -0.0011, -0.0025, -0.0339,  0.0033, -0.0163,  0.0149,  0.0067,\n",
       "                        0.0884, -0.0206, -0.1129, -0.0784, -0.0226, -0.0250, -0.0111,  0.0572,\n",
       "                        0.0024,  0.0692,  0.0104, -0.0290,  0.0210,  0.0121, -0.0427,  0.0783,\n",
       "                        0.0033, -0.0790,  0.0213, -0.0446, -0.0331, -0.0034,  0.0156,  0.0134,\n",
       "                        0.1029, -0.0194, -0.0152, -0.0081,  0.0470, -0.0643, -0.0400,  0.0142],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_mean',\n",
       "               tensor([ 0.0819,  0.1804, -0.4772, -0.6101, -0.3008,  0.2108,  0.2133,  0.5344,\n",
       "                       -0.4505, -0.1833,  0.5550,  0.0989, -0.0590,  0.0618, -0.4867, -0.1422,\n",
       "                        0.3214, -0.4065, -0.5887, -0.2406,  0.2547, -0.5363, -0.6108,  0.3373,\n",
       "                       -0.6399,  0.0154, -0.6820, -0.1368, -0.0172,  0.4684,  0.0887,  0.7985,\n",
       "                        0.1810, -0.3006, -0.0334,  0.1870,  0.2057, -0.1851,  0.2099,  0.6588,\n",
       "                        0.1316, -0.0559, -0.2391, -0.1731,  0.5077, -0.1250,  0.2248, -0.4493,\n",
       "                        0.7387,  0.0762, -0.1371,  0.1984,  0.5650, -0.6038, -0.6098, -0.1977,\n",
       "                       -0.1055, -0.2997, -0.3490,  0.0093,  0.4037, -0.6665,  0.1693,  0.1043],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.5.running_var',\n",
       "               tensor([0.9847, 1.2156, 2.1239, 0.8790, 1.1754, 1.7929, 2.0417, 2.6536, 1.6806,\n",
       "                       2.4264, 1.6802, 1.2156, 1.4891, 1.6398, 1.1587, 2.3768, 1.9464, 1.7519,\n",
       "                       2.8961, 2.4059, 1.5341, 1.7140, 1.3100, 1.2945, 1.3361, 0.9477, 1.5960,\n",
       "                       2.0894, 1.4907, 2.0492, 1.6629, 2.1529, 1.1154, 2.0109, 0.5045, 0.3666,\n",
       "                       2.0824, 1.8649, 1.8414, 2.5514, 1.9924, 2.5713, 1.8918, 1.8980, 3.2337,\n",
       "                       2.3881, 1.3412, 1.2353, 1.6173, 0.7498, 1.2050, 1.0480, 1.6487, 1.2789,\n",
       "                       1.0237, 2.0882, 1.0804, 2.0189, 2.7277, 2.1238, 2.1056, 1.4677, 1.9589,\n",
       "                       2.0727], device='cuda:0')),\n",
       "              ('ff.5.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.8.weight',\n",
       "               tensor([[-0.0940, -0.1412,  0.0479,  ..., -0.1060,  0.0275, -0.0107],\n",
       "                       [ 0.0663,  0.0273, -0.0108,  ..., -0.0078, -0.0203, -0.0399],\n",
       "                       [ 0.1064, -0.0102,  0.0807,  ...,  0.0379,  0.0032, -0.0586],\n",
       "                       ...,\n",
       "                       [ 0.0433,  0.1190,  0.1905,  ...,  0.1097, -0.0569, -0.1091],\n",
       "                       [ 0.0609, -0.1010, -0.0400,  ...,  0.0064,  0.0003, -0.0401],\n",
       "                       [ 0.1131,  0.0386,  0.1315,  ..., -0.0408, -0.0828,  0.0161]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.8.bias',\n",
       "               tensor([-7.7659e-02, -5.5473e-05,  1.5628e-02, -1.8603e-02,  1.0167e-01,\n",
       "                        2.9450e-02, -6.3916e-02,  1.2605e-01,  5.1127e-03, -8.5162e-02,\n",
       "                       -4.1072e-02, -1.0402e-01, -1.1317e-01,  2.5333e-02,  1.0930e-01,\n",
       "                        5.4927e-02, -4.7519e-03, -9.9562e-02,  1.2116e-01,  4.8417e-02,\n",
       "                        1.1597e-01, -1.0592e-01,  1.5283e-02,  3.5716e-02,  1.1558e-01,\n",
       "                        8.9208e-02,  2.3907e-02, -6.4477e-02, -1.0990e-01, -5.9243e-03,\n",
       "                       -9.1548e-02,  2.8768e-02], device='cuda:0')),\n",
       "              ('ff.9.weight',\n",
       "               tensor([1.0148, 0.9851, 0.9617, 1.0823, 0.9513, 1.0514, 1.1191, 0.9480, 1.0477,\n",
       "                       0.9582, 1.0312, 1.1536, 1.0778, 1.1251, 1.1587, 1.0389, 1.0505, 1.0042,\n",
       "                       1.0199, 1.0685, 0.9751, 1.2015, 1.0797, 1.1402, 1.0111, 1.1202, 1.0796,\n",
       "                       1.0193, 0.9703, 1.0362, 1.0682, 0.9796], device='cuda:0')),\n",
       "              ('ff.9.bias',\n",
       "               tensor([ 5.5272e-02, -3.6396e-03, -8.0552e-03,  7.0043e-02, -4.4919e-02,\n",
       "                        3.5666e-02,  1.0308e-01, -5.9634e-02,  5.7273e-02, -5.7233e-02,\n",
       "                        5.4829e-02,  1.5220e-01,  7.4164e-02,  8.4681e-02,  1.2034e-01,\n",
       "                        7.6376e-02,  9.3998e-02,  2.2328e-02,  5.3214e-02,  5.7039e-02,\n",
       "                       -1.6607e-05,  1.9520e-01,  9.0955e-02,  1.5454e-01,  3.1493e-03,\n",
       "                        1.3814e-01,  7.3680e-02,  4.1650e-02, -4.6734e-02,  5.2859e-02,\n",
       "                        9.6464e-02, -2.0020e-02], device='cuda:0')),\n",
       "              ('ff.9.running_mean',\n",
       "               tensor([-1.0197e-01, -1.0460e-01, -2.8072e-02, -1.6518e-01, -1.3431e-01,\n",
       "                       -2.8967e-01, -3.8401e-01, -8.5669e-02, -1.3851e-01, -2.2051e-01,\n",
       "                       -2.5291e-01,  8.7660e-02, -4.1551e-01, -1.7487e-01,  3.3998e-02,\n",
       "                       -2.7326e-02,  1.7139e-01, -1.2011e-01,  1.3437e-01,  4.2134e-02,\n",
       "                       -3.6449e-02, -1.0544e-01, -3.9150e-04,  9.2810e-02,  1.5923e-02,\n",
       "                       -2.0545e-01,  2.1977e-01, -3.5611e-01, -3.8920e-01,  7.5240e-02,\n",
       "                       -3.1362e-01, -1.0082e-01], device='cuda:0')),\n",
       "              ('ff.9.running_var',\n",
       "               tensor([2.4231, 2.5473, 1.9340, 2.3294, 1.6164, 2.0636, 2.5954, 1.6030, 2.5339,\n",
       "                       2.1966, 2.3131, 3.0338, 2.4262, 3.4352, 3.1029, 2.8732, 1.9828, 2.2973,\n",
       "                       1.7869, 2.1666, 1.8796, 3.1645, 1.3817, 2.4135, 2.1650, 2.0257, 2.0509,\n",
       "                       2.2713, 1.7819, 1.9557, 1.9880, 1.6861], device='cuda:0')),\n",
       "              ('ff.9.num_batches_tracked', tensor(1400, device='cuda:0')),\n",
       "              ('ff.12.weight',\n",
       "               tensor([[-0.1817,  0.1327,  0.0970,  0.0835,  0.1234,  0.0954, -0.1327,  0.1218,\n",
       "                         0.1129,  0.0946, -0.2065,  0.1163, -0.1990,  0.0999, -0.1337, -0.2089,\n",
       "                        -0.1794,  0.1133, -0.1729,  0.0711,  0.1101, -0.1575, -0.1300, -0.1586,\n",
       "                         0.0757, -0.1332, -0.1437,  0.0811,  0.1173,  0.0905, -0.1078,  0.1241]],\n",
       "                      device='cuda:0')),\n",
       "              ('ff.12.bias', tensor([-0.2138], device='cuda:0'))]),\n",
       " {'batch_size': 32, 'epochs': 35, 'layers_list': [128, 64, 32], 'lr': 0.001})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tuning(dataset, emb_sizes=[5, 5], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2487f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8435\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 128, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [32, 64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8182\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 256, 256, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8435\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16, 8], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Training config: {'batch_size': 64, 'epochs': 250, 'layers_list': [256, 128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8371\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8341\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8278\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 512, 512, 256, 128, 64, 32], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 256, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 128, 64, 128, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8403\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 128, 64, 32, 16], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [32, 64, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 256, 256, 256], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8307\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8333\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [512, 256, 128, 128, 256, 512], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8339\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [1024, 512, 256, 128, 64, 32, 16, 8], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8309\n",
      "\n",
      "Training config: {'batch_size': 128, 'epochs': 250, 'layers_list': [256, 128, 256, 128, 256, 128], 'lr': 0.001}\n",
      "Best Min(train, val) accuracy for config: 0.8275\n",
      "\n",
      "Best Config: {'batch_size': 64, 'epochs': 250, 'layers_list': [512, 256, 128, 64, 32], 'lr': 0.001} | Best Min Acc: 0.8435\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4],                          # Learning rates\n",
    "    'batch_size': [32, 64, 128, 256],                       # Batch sizes\n",
    "    'layers_list': [                                   # Network depths (shallow → deep)\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32],\n",
    "        [256, 256, 128, 64, 32],                       # New: deeper and wider\n",
    "        [512, 256, 128, 64, 32],                       # New: even wider\n",
    "        [512, 512, 256, 128, 64, 32],                  # New: deeper\n",
    "        [1024, 512, 256, 128, 64, 32],                 # New: very deep\n",
    "        [512, 512, 512, 256, 128, 64, 32],             # New: 7-layer net\n",
    "    ],\n",
    "    'epochs': [100],                                # Training duration\n",
    "}\n",
    "param_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'batch_size': [64, 128],\n",
    "    'layers_list': [\n",
    "        # Baseline and shallow\n",
    "        [64, 32],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [128, 128, 64, 32],\n",
    "\n",
    "        # Deeper & wider\n",
    "        [256, 256, 128, 64, 32],\n",
    "        [512, 256, 128, 64, 32],\n",
    "        [512, 512, 256, 128, 64, 32],\n",
    "        [1024, 512, 256, 128, 64, 32],\n",
    "        [512, 512, 512, 256, 128, 64, 32],\n",
    "\n",
    "        # 🧱 Bottleneck-style (wide → narrow → wide)\n",
    "        [512, 256, 128, 256, 512],\n",
    "        [256, 128, 64, 128, 256],\n",
    "\n",
    "        # 🔻 Pyramidal (gradually reducing width)\n",
    "        [1024, 512, 256, 128, 64, 32, 16],\n",
    "        [512, 256, 128, 64, 32, 16],\n",
    "        [256, 128, 64, 32, 16],\n",
    "\n",
    "        # 🔺 Inverse pyramid (upscaling – not typical, but may help for expressive tasks)\n",
    "        [64, 128, 256, 512],\n",
    "        [32, 64, 128, 256, 512],\n",
    "\n",
    "        # 🌀 Residual-style symmetry (no skips, just same-sized stages)\n",
    "        [256, 256, 256, 256],\n",
    "        [128, 256, 128, 256, 128],\n",
    "        [512, 256, 128, 128, 256, 512],\n",
    "\n",
    "        # 🪜 Steady downstep\n",
    "        [1024, 512, 256, 128, 64, 32, 16, 8],\n",
    "\n",
    "        # 🔁 Repeating block pattern\n",
    "        [256, 128, 256, 128, 256, 128],\n",
    "    ],\n",
    "    'epochs': [250],\n",
    "}\n",
    "\n",
    "best_state, best_params = run_tuning(dataset, emb_sizes=[5, 5], param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d1e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = torch.load('best_state.pth')\n",
    "best_params = torch.load('best_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state, 'best_state.pth')\n",
    "torch.save(best_params, 'best_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f41850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the model using best_config and load weights\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_model = MarketResearchModel(\n",
    "    num_numeric_features=dataset[0][\"features\"].shape[0] - 2,\n",
    "    emb_sizes=[3, 4],  # Use the same emb_sizes you used during tuning\n",
    "    layers_list=best_params['layers_list']\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "best_model.load_state_dict(best_state)\n",
    "best_model.eval()\n",
    "test_set = CustomerDataset(test, lists, target_col='ID')\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ada728",
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketResearchModel = TabInspiredMarketModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81f436f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "TabInspiredMarketModel                             --\n",
       "├─ImputationLayer: 1-1                             23\n",
       "├─TrainableScaler: 1-2                             46\n",
       "├─Embedding: 1-3                                   25\n",
       "├─Embedding: 1-4                                   25\n",
       "├─Linear: 1-5                                      64\n",
       "├─Linear: 1-6                                      192\n",
       "├─Linear: 1-7                                      192\n",
       "├─MultiheadAttention: 1-8                          3,168\n",
       "│    └─NonDynamicallyQuantizableLinear: 2-1        1,056\n",
       "├─GLULayer: 1-9                                    --\n",
       "│    └─Linear: 2-2                                 2,112\n",
       "│    └─BatchNorm1d: 2-3                            128\n",
       "├─Sequential: 1-10                                 --\n",
       "│    └─FeatureTransformerBlock: 2-4                --\n",
       "│    │    └─Linear: 3-1                            1,056\n",
       "│    │    └─Linear: 3-2                            1,056\n",
       "│    │    └─BatchNorm1d: 3-3                       64\n",
       "│    │    └─Dropout: 3-4                           --\n",
       "├─Sequential: 1-11                                 --\n",
       "│    └─Linear: 2-5                                 528\n",
       "│    └─BatchNorm1d: 2-6                            32\n",
       "│    └─ReLU: 2-7                                   --\n",
       "│    └─Dropout: 2-8                                --\n",
       "│    └─Linear: 2-9                                 544\n",
       "│    └─BatchNorm1d: 2-10                           64\n",
       "│    └─ReLU: 2-11                                  --\n",
       "│    └─Dropout: 2-12                               --\n",
       "│    └─Linear: 2-13                                33\n",
       "===========================================================================\n",
       "Total params: 10,408\n",
       "Trainable params: 10,408\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120537bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "# layers_list_now = [512,256,128,128,256,512]\n",
    "# layers_list_now = [512, 256, 64, 256, 512]\n",
    "# layers_list_now = [64, 32]\n",
    "# # bt_size = 32\n",
    "# bt_size = 128\n",
    "# lr = 0.001\n",
    "layers_list_now = best_params['layers_list']\n",
    "bt_size = best_params['batch_size']\n",
    "lr=best_params['lr']\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from altair import layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "# For progress bars (optional)\n",
    "from tqdm import tqdm\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "best_val_acc = 0\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Reproducibility & Device\n",
    "# -----------------------------------------------------------------------------\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Train/Validation Split\n",
    "# -----------------------------------------------------------------------------\n",
    "# `train` is your full DataFrame\n",
    "train_df, val_df = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Datasets & Loaders\n",
    "# -----------------------------------------------------------------------------\n",
    "# `lists` is your list of feature columns in order; target_col='ID'\n",
    "train_set = CustomerDataset(train_df, lists, target_col='Target')\n",
    "val_set   = CustomerDataset(val_df,   lists, target_col='Target')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=bt_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=bt_size, shuffle=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Model, Loss, Optimizer\n",
    "# -----------------------------------------------------------------------------\n",
    "model = MarketResearchModel(\n",
    "    num_numeric_features=train_set[0][\"features\"].shape[0] - 2,\n",
    "    emb_sizes=[5, 5],\n",
    "    layers_list=layers_list_now,\n",
    "    # depth=2,  # Set to 2 for the new model\n",
    "    # hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(w1/w0).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Training Loop (inline, no helper funcs)\n",
    "# -----------------------------------------------------------------------------\n",
    "# epochs = best_params['epochs']\n",
    "epochs = 3000  # Set to 100 epochs for training\n",
    "higest_state = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False):\n",
    "        x_all = batch[\"features\"].to(device)\n",
    "        y_all = batch[\"target\"].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_all)\n",
    "        loss = criterion(outputs, y_all)\n",
    "        outputs = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * y_all.size(0)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        train_correct += (preds == y_all).sum().item()\n",
    "        train_total += y_all.size(0)\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # — Validate —\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]  \", leave=False):\n",
    "            x_all = batch[\"features\"].to(device)\n",
    "            y_all = batch[\"target\"].float().to(device)\n",
    "\n",
    "            outputs = model(x_all)\n",
    "            loss = criterion(outputs, y_all)\n",
    "            outputs = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "            val_loss += loss.item() * y_all.size(0)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            val_correct += (preds == y_all).sum().item()\n",
    "            val_total += y_all.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_list.append(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_model_state = model.state_dict()\n",
    "    best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    # Clear previous output and plot\n",
    "    clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epoch + 1), train_acc_list, label='Train Accuracy')\n",
    "    plt.plot(range(1, epoch + 1), val_acc_list, label='Validation Accuracy')\n",
    "    plt.title(f'Epoch {epoch}/{epochs}  |  Best Val Acc: {best_val_acc:.4f}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Also print current and best in compact form\n",
    "    # print(f'Epoch {epoch}/{epochs} → Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Best Val Acc: {best_val_acc:.4f}')\n",
    "    # print(f\"Epoch {epoch}/{epochs} → \"\n",
    "    #       f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "    #       f\"Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Save Final Model\n",
    "# -----------------------------------------------------------------------------\n",
    "torch.save(model.state_dict(), \"final_best_model.pt\")\n",
    "print(\"✅ Model trained and saved to 'final_best_model.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2775ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004457652303121"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs = []\n",
    "Targets = []\n",
    "for i in test_loader:\n",
    "    x_all = i['features'].to(device)\n",
    "    x_all = x_all.to(device)\n",
    "    pred = best_model(x_all)\n",
    "    pred = pred > 0.5\n",
    "    pred = pred.int().cpu().numpy()\n",
    "    Targets += pred.tolist()\n",
    "    IDs += i['target'].tolist()\n",
    "submission = pd.DataFrame({'ID': IDs, 'Target': Targets})\n",
    "# comp = pd.read_csv(r'submission1.csv')\n",
    "comp = pd.read_csv(r'MLP_embed-84.csv')\n",
    "comp = comp.sort_values(by='ID', ignore_index=True)\n",
    "submission = submission.sort_values(by='ID', ignore_index=True)\n",
    "(comp['Target'] == submission['Target']).mean()  # Check accuracy of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a91aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'MLP_embed-84_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee662f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
