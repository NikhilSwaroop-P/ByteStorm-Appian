{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5138c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train=pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\train.csv')\n",
    "test=pd.read_csv(r'appian-x-iit-madras-hackathon-april-2025\\test.csv')\n",
    "\n",
    "train.replace('Alone', 'Single', inplace=True)\n",
    "test.replace('Absurd', 'Single', inplace=True)\n",
    "train.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('YOLO', 'Single', inplace=True)\n",
    "test.replace('Alone', 'Single', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb072142",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique values in each column\n",
    "for col in train.columns:\n",
    "    print(f\"{col}: {train[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ac62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the unique values in the target column\n",
    "print(train['Education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Marital_Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3143299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92fe4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Graduation\n",
      "1: PhD\n",
      "2: Master\n",
      "3: Basic\n",
      "4: 2n Cycle\n",
      "0: Single\n",
      "1: Together\n",
      "2: Married\n",
      "3: Divorced\n",
      "4: Widow\n"
     ]
    }
   ],
   "source": [
    "Education = {}\n",
    "Marital_status = {}\n",
    "A = train['Education'].unique()\n",
    "B = train['Marital_Status'].unique()\n",
    "# A = test['Education'].unique()\n",
    "# B = test['Marital_Status'].unique()\n",
    "for i, category in enumerate(A):\n",
    "    l = [0]*len(A)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Education[category] = l\n",
    "for i, category in enumerate(B):\n",
    "    l = [0]*len(B)\n",
    "    l[i] = 1\n",
    "    print(f\"{i}: {category}\")\n",
    "    Marital_status[category] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education = {}\n",
    "# Marital_status = {}\n",
    "# # A = train['Education'].unique()\n",
    "# # B = train['Marital_Status'].unique()\n",
    "# A = test['Education'].unique()\n",
    "# B = test['Marital_Status'].unique()\n",
    "# for i, category in enumerate(A):\n",
    "#     l = [0]*len(A)\n",
    "#     l[i] = 1\n",
    "#     print(f\"{i}: {category}\")\n",
    "#     Education[category] = l\n",
    "# for i, category in enumerate(B):\n",
    "#     l = [0]*len(B)\n",
    "#     l[i] = 1\n",
    "#     print(f\"{i}: {category}\")\n",
    "#     Marital_status[category] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddcab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb53516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bcbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dt_Customer_1'] = pd.to_datetime(train['Dt_Customer'],format='mixed')\n",
    "train['Dt_Customer_1'] = train['Dt_Customer_1']-min(train['Dt_Customer_1'])\n",
    "train['Dates']=train['Dt_Customer_1'].dt.days\n",
    "train['Marital_Status'] = train['Marital_Status'].map(Marital_status)\n",
    "train['Education'] = train['Education'].map(Education)\n",
    "\n",
    "test['Dt_Customer_1'] = pd.to_datetime(test['Dt_Customer'],format='mixed')\n",
    "test['Dt_Customer_1'] = test['Dt_Customer_1']-min(test['Dt_Customer_1'])\n",
    "test['Dates']=test['Dt_Customer_1'].dt.days\n",
    "test['Marital_Status'] = test['Marital_Status'].map(Marital_status)\n",
    "test['Education'] = test['Education'].map(Education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e87ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b272176",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552d5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    'Education',\n",
    "    'Marital_Status',\n",
    "    'Target'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffbbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = train.mean(numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "# default_list = [1]*23\n",
    "default_list = means[lists[:-3]]\n",
    "\n",
    "class Imputation_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Imputation_layer, self).__init__()\n",
    "        self.impute = nn.Parameter(torch.tensor(default_list, dtype=torch.float32), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        mask = torch.isnan(x)\n",
    "        # print(x.shape, self.impute.shape)\n",
    "        # print(mask.shape)\n",
    "        x[mask] = self.impute.expand(x.shape[0], -1)[mask]\n",
    "        return x\n",
    "class TrainableScaler(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(num_features))\n",
    "        self.std = nn.Parameter(torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "    \n",
    "class Model0(nn.Module):\n",
    "    def __init__(self, in_features=34, layers_list=[64,128,128,64,32]):\n",
    "        super(Model0, self).__init__()\n",
    "        self.imputer = Imputation_layer()\n",
    "        self.scaler = TrainableScaler(in_features-11)\n",
    "        # self.edu_linear = nn.Linear(5, 5)\n",
    "        self.edu_linear = nn.Sequential(\n",
    "            nn.Linear(5, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # self.marital_linear = nn.Linear(6, 6)\n",
    "        self.marital_linear = nn.Sequential(\n",
    "            nn.Linear(5, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.main_linears = nn.Sequential(\n",
    "            nn.Linear(in_features - 11 + 20, layers_list[0]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        for i in range(1,len(layers_list)):\n",
    "            self.main_linears.append(nn.Linear(layers_list[i-1], layers_list[i]))\n",
    "            self.main_linears.append(nn.ReLU())\n",
    "        final_fc = nn.Linear(layers_list[-1], 1)\n",
    "        self.main_linears.append(final_fc)\n",
    "        self.main_linears.append(nn.Sigmoid())\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_num = torch.cat(x[:-2])\n",
    "        x_num = torch.transpose(x_num, 0, 1)\n",
    "        x_num = x_num.float()\n",
    "        x_edu = torch.transpose(x[-2], 0, 1)\n",
    "        x_marital = torch.transpose(x[-1], 0, 1)\n",
    "        x_num = self.imputer(x_num)\n",
    "        x_num = self.scaler(x_num)\n",
    "        x_edu = self.edu_linear(x_edu).squeeze(1)\n",
    "        # x_marital = self.marital_linear(x_marital).squeeze(1)\n",
    "        # print(x_num.shape, x_edu.shape, x_marital.shape)\n",
    "        # x = torch.cat((x_num, x_edu, x_marital), dim=1)\n",
    "        x = torch.cat((x_num, x_edu), dim=1)\n",
    "        x = self.main_linears(x)\n",
    "        return x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3158a86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assume you have computed default imputation values for numeric columns.\n",
    "# In your case, there are 23 numeric features.\n",
    "# For example, default_list can be computed from the means of these columns.\n",
    "# default_list = [1.0] * 23  # Replace with your computed values if available.\n",
    "\n",
    "###############################################################################\n",
    "# Trainable imputation layer for numeric features\n",
    "###############################################################################\n",
    "class ImputationLayer(nn.Module):\n",
    "    def __init__(self, impute_init):\n",
    "        super(ImputationLayer, self).__init__()\n",
    "        # impute_init: list of length 23 for numeric features.\n",
    "        self.impute = nn.Parameter(torch.tensor(impute_init, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [b, 23]\n",
    "        mask = torch.isnan(x)\n",
    "        # Expand imputation parameters to match batch dimension\n",
    "        impute_values = self.impute.unsqueeze(0).expand_as(x)\n",
    "        # Replace NaNs with trainable imputation values\n",
    "        return torch.where(mask, impute_values, x)\n",
    "\n",
    "###############################################################################\n",
    "# Trainable scaler for numeric features (learnable mean and std)\n",
    "###############################################################################\n",
    "class TrainableScaler(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(TrainableScaler, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.zeros(num_features))\n",
    "        self.std = nn.Parameter(torch.ones(num_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "###############################################################################\n",
    "# Improved model for a list of 25 inputs as specified\n",
    "###############################################################################\n",
    "class Model0(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_numeric=23,        # numeric features count\n",
    "                 cat_dim=5,            # each categorical input is of dimension 5\n",
    "                 layers_list=[128, 256, 256, 128, 64, 32],  # main network hidden layers\n",
    "                 impute_init=None):\n",
    "        super(Model0, self).__init__()\n",
    "        \n",
    "        if impute_init is None:\n",
    "            impute_init = [1.0] * in_numeric\n",
    "        \n",
    "        # Numeric branch: imputation then scaling.\n",
    "        self.imputer = ImputationLayer(impute_init)\n",
    "        self.scaler  = TrainableScaler(in_numeric)\n",
    "        \n",
    "        # Categorical branches: Process each of the last 2 inputs.\n",
    "        # We assume each categorical input is a tensor of shape [b, 5] after squeezing.\n",
    "        # We'll project them to a 10-dimensional output.\n",
    "        self.edu_linear = nn.Sequential(\n",
    "            nn.Linear(cat_dim, 10),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.marital_linear = nn.Sequential(\n",
    "            nn.Linear(cat_dim, 10),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Combined input dimension after processing:\n",
    "        # Numeric: 23, Education: 10, Marital: 10 → 23+10+10 = 43.\n",
    "        combined_input_dim = in_numeric + 10 + 10\n",
    "        \n",
    "        # Build the main fully connected network.\n",
    "        layers = []\n",
    "        current_dim = combined_input_dim\n",
    "        for hidden_dim in layers_list:\n",
    "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            current_dim = hidden_dim\n",
    "        # Final output layer for a binary target.\n",
    "        layers.append(nn.Linear(current_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.main_linears = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: a list of 25 elements\n",
    "           - Elements 0 to 22: numeric features, each of shape [1, b]\n",
    "           - Element 23: first categorical feature, shape [1, b, 5]\n",
    "           - Element 24: second categorical feature, shape [1, b, 5]\n",
    "        The batch dimension is assumed to be in the second position in the numeric inputs.\n",
    "        \"\"\"\n",
    "        # Process numeric features: stack elements 0 to 22.\n",
    "        numeric_list = []\n",
    "        for i in range(23):\n",
    "            # Squeeze the first dimension so each tensor becomes [b] then unsqueeze to [b, 1]\n",
    "            numeric_i = x[i].squeeze(0).unsqueeze(1)\n",
    "            numeric_list.append(numeric_i)\n",
    "        # Concatenate along feature dimension: shape becomes [b, 23]\n",
    "        x_num = torch.cat(numeric_list, dim=1)\n",
    "        \n",
    "        # Process categorical features (element 23 and 24).\n",
    "        # Each is of shape [1, b, 5]; squeeze the first dimension → [b, 5]\n",
    "        x_edu = x[23].squeeze(0)\n",
    "        x_marital = x[24].squeeze(0)\n",
    "        \n",
    "        # Numeric branch processing.\n",
    "        x_num = self.imputer(x_num)  # impute NaNs, shape [b, 23]\n",
    "        x_num = self.scaler(x_num)   # scale numerics, shape [b, 23]\n",
    "        \n",
    "        # Process categorical branches.\n",
    "        # Note: BatchNorm1d expects the batch dimension first.\n",
    "        x_edu = self.edu_linear(x_edu)         # shape [b, 10]\n",
    "        x_marital = self.marital_linear(x_marital)  # shape [b, 10]\n",
    "        \n",
    "        # Concatenate numeric and categorical outputs: shape [b, 23+10+10] = [b, 43]\n",
    "        x_combined = torch.cat([x_num, x_edu, x_marital], dim=1)\n",
    "        \n",
    "        # Feed into main network.\n",
    "        out = self.main_linears(x_combined)  # shape [b, 1]\n",
    "        return out.squeeze(1)  # final output shape: [b]\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    # Assume b (batch dimension) is, for example, 4.\n",
    "    b = 4\n",
    "    # Create dummy inputs.\n",
    "    # For numeric inputs: list of 23 tensors, each shape [1, b]\n",
    "    numeric_inputs = [torch.randn(1, b) for _ in range(23)]\n",
    "    \n",
    "    # For categorical inputs: 2 tensors, each shape [1, b, 5]\n",
    "    cat_input1 = torch.randn(1, b, 5)\n",
    "    cat_input2 = torch.randn(1, b, 5)\n",
    "    \n",
    "    # Create the list of inputs: total 25 elements.\n",
    "    inputs = numeric_inputs + [cat_input1, cat_input2]\n",
    "    \n",
    "    model = Model0(in_numeric=23, cat_dim=5,\n",
    "                   layers_list=[128, 256, 256, 128, 64, 32],\n",
    "                   impute_init=[1.0]*23)\n",
    "    \n",
    "    output = model(inputs)\n",
    "    print(\"Output shape:\", output.shape)  # Expected: [b], i.e. [4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3006c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = []\n",
    "lists = [\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    'Education',\n",
    "    'Marital_Status',\n",
    "    'Target'\n",
    "]\n",
    "for i in lists:\n",
    "    test_case.append(torch.tensor(train[i][:2], dtype=torch.float32).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e67054da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1957., 1954.]]),\n",
       " tensor([[58138., 46344.]]),\n",
       " tensor([[0., 1.]]),\n",
       " tensor([[0., 1.]]),\n",
       " tensor([[ 92., 938.]]),\n",
       " tensor([[58., 38.]]),\n",
       " tensor([[635.,  11.]]),\n",
       " tensor([[88.,  1.]]),\n",
       " tensor([[546.,   6.]]),\n",
       " tensor([[172.,   2.]]),\n",
       " tensor([[88.,  1.]]),\n",
       " tensor([[88.,  6.]]),\n",
       " tensor([[8., 1.]]),\n",
       " tensor([[10.,  1.]]),\n",
       " tensor([[4., 2.]]),\n",
       " tensor([[3., 2.]]),\n",
       " tensor([[7., 5.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[0., 0.]]),\n",
       " tensor([[[1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]]]),\n",
       " tensor([[[1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9d033b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = Model0(in_features=34, layers_list=[64,128,256,128,64,32])\n",
    "model(test_case).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b32d88e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Model0                                   --\n",
       "├─ImputationLayer: 1-1                   23\n",
       "├─TrainableScaler: 1-2                   46\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-1                       60\n",
       "│    └─BatchNorm1d: 2-2                  20\n",
       "│    └─ReLU: 2-3                         --\n",
       "│    └─Dropout: 2-4                      --\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-5                       60\n",
       "│    └─BatchNorm1d: 2-6                  20\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Dropout: 2-8                      --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─Linear: 2-9                       5,632\n",
       "│    └─BatchNorm1d: 2-10                 256\n",
       "│    └─ReLU: 2-11                        --\n",
       "│    └─Dropout: 2-12                     --\n",
       "│    └─Linear: 2-13                      33,024\n",
       "│    └─BatchNorm1d: 2-14                 512\n",
       "│    └─ReLU: 2-15                        --\n",
       "│    └─Dropout: 2-16                     --\n",
       "│    └─Linear: 2-17                      65,792\n",
       "│    └─BatchNorm1d: 2-18                 512\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─Dropout: 2-20                     --\n",
       "│    └─Linear: 2-21                      32,896\n",
       "│    └─BatchNorm1d: 2-22                 256\n",
       "│    └─ReLU: 2-23                        --\n",
       "│    └─Dropout: 2-24                     --\n",
       "│    └─Linear: 2-25                      8,256\n",
       "│    └─BatchNorm1d: 2-26                 128\n",
       "│    └─ReLU: 2-27                        --\n",
       "│    └─Dropout: 2-28                     --\n",
       "│    └─Linear: 2-29                      2,080\n",
       "│    └─BatchNorm1d: 2-30                 64\n",
       "│    └─ReLU: 2-31                        --\n",
       "│    └─Dropout: 2-32                     --\n",
       "│    └─Linear: 2-33                      33\n",
       "│    └─Sigmoid: 2-34                     --\n",
       "=================================================================\n",
       "Total params: 149,670\n",
       "Trainable params: 149,670\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f4a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, columns: list):\n",
    "        self.data = dataframe[columns].copy()\n",
    "        self.columns = columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tensor_list = [torch.tensor(row[col], dtype=torch.float32) for col in self.columns]\n",
    "        return tensor_list\n",
    "\n",
    "def get_dataloaders(df, columns, batch_size=32, test_split=0.2, shuffle=True):\n",
    "    dataset = CustomDataset(df, columns)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "\n",
    "    train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle, collate_fn=lambda x: list(zip(*x)))\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=lambda x: list(zip(*x)))\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9456c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_dataloaders(train, lists, batch_size=64, test_split=0.3, shuffle=True)\n",
    "\n",
    "# Accessing one batch\n",
    "for batch in test_loader:\n",
    "    # Each batch[i] is a tuple of tensors for the i-th column4\n",
    "    # Convert to tensors if needed\n",
    "    batch = [torch.stack(col).unsqueeze(0) for col in batch]\n",
    "    # print(batch[0].shape)  # list of tensors\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device='cuda'):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in pbar:\n",
    "        inputs = [torch.stack(col).unsqueeze(0).to(device) for col in batch[:-1]]\n",
    "        # inputs = torch.cat(inputs, dim=1)\n",
    "        if inputs[0].shape[1] == 1:\n",
    "            continue\n",
    "        targets = torch.stack(batch[-1]).to(device).float().squeeze()\n",
    "        # print(inputs[0].shape, targets.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = (outputs > 0.5).float()\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "        acc = correct / total if total > 0 else 0\n",
    "        pbar.set_postfix(loss=loss.item(), accuracy=acc)\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_acc = correct / total\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device='cuda'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = [torch.stack(col).unsqueeze(0).to(device) for col in batch[:-1]]\n",
    "            # inputs = torch.cat(inputs, dim=1)\n",
    "            if inputs[0].shape[1] == 1:\n",
    "                continue\n",
    "            targets = torch.stack(batch[-1]).to(device).float().squeeze()\n",
    "            # print(inputs[0].shape, targets.shape)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b770d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model0(in_features=34, layers_list=[64,64,128,256,256,128,32]).to('cuda')\n",
    "model = Model0(in_numeric=23, cat_dim=5,\n",
    "               layers_list=[256, 512, 512, 256, 128, 64, 32],\n",
    "               impute_init=[1.0]*23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e08e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = Model0().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6821f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "052def21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6577 | Train Acc: 0.6171\n",
      "Val   Loss: 0.6681 | Val   Acc: 0.6191\n",
      "✅ Checkpoint saved at epoch 1 (min acc: 0.6171)\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6026 | Train Acc: 0.6791\n",
      "Val   Loss: 0.5854 | Val   Acc: 0.7213\n",
      "✅ Checkpoint saved at epoch 2 (min acc: 0.6791)\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5821 | Train Acc: 0.6882\n",
      "Val   Loss: 0.5734 | Val   Acc: 0.7149\n",
      "✅ Checkpoint saved at epoch 3 (min acc: 0.6882)\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5648 | Train Acc: 0.7019\n",
      "Val   Loss: 0.5570 | Val   Acc: 0.7149\n",
      "✅ Checkpoint saved at epoch 4 (min acc: 0.7019)\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5468 | Train Acc: 0.7238\n",
      "Val   Loss: 0.5517 | Val   Acc: 0.7426\n",
      "✅ Checkpoint saved at epoch 5 (min acc: 0.7238)\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5681 | Train Acc: 0.7265\n",
      "Val   Loss: 0.5483 | Val   Acc: 0.7383\n",
      "✅ Checkpoint saved at epoch 6 (min acc: 0.7265)\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5411 | Train Acc: 0.7265\n",
      "Val   Loss: 0.5738 | Val   Acc: 0.7043\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5200 | Train Acc: 0.7420\n",
      "Val   Loss: 0.5452 | Val   Acc: 0.7234\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5313 | Train Acc: 0.7402\n",
      "Val   Loss: 0.5737 | Val   Acc: 0.7447\n",
      "✅ Checkpoint saved at epoch 9 (min acc: 0.7402)\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5255 | Train Acc: 0.7411\n",
      "Val   Loss: 0.6140 | Val   Acc: 0.7404\n",
      "✅ Checkpoint saved at epoch 10 (min acc: 0.7404)\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5279 | Train Acc: 0.7411\n",
      "Val   Loss: 0.5551 | Val   Acc: 0.7532\n",
      "✅ Checkpoint saved at epoch 11 (min acc: 0.7411)\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4993 | Train Acc: 0.7621\n",
      "Val   Loss: 0.5485 | Val   Acc: 0.7064\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5042 | Train Acc: 0.7429\n",
      "Val   Loss: 0.6659 | Val   Acc: 0.7064\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4992 | Train Acc: 0.7621\n",
      "Val   Loss: 0.7008 | Val   Acc: 0.6574\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5043 | Train Acc: 0.7694\n",
      "Val   Loss: 0.5203 | Val   Acc: 0.7681\n",
      "✅ Checkpoint saved at epoch 15 (min acc: 0.7681)\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4975 | Train Acc: 0.7666\n",
      "Val   Loss: 0.6711 | Val   Acc: 0.6468\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4859 | Train Acc: 0.7402\n",
      "Val   Loss: 0.5374 | Val   Acc: 0.7638\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4766 | Train Acc: 0.7721\n",
      "Val   Loss: 0.4935 | Val   Acc: 0.7660\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4675 | Train Acc: 0.7712\n",
      "Val   Loss: 0.5082 | Val   Acc: 0.7830\n",
      "✅ Checkpoint saved at epoch 19 (min acc: 0.7712)\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4946 | Train Acc: 0.7758\n",
      "Val   Loss: 0.6356 | Val   Acc: 0.7000\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4629 | Train Acc: 0.7703\n",
      "Val   Loss: 0.4885 | Val   Acc: 0.7745\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4603 | Train Acc: 0.7612\n",
      "Val   Loss: 0.4805 | Val   Acc: 0.7936\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4682 | Train Acc: 0.7721\n",
      "Val   Loss: 0.5194 | Val   Acc: 0.7574\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4626 | Train Acc: 0.7821\n",
      "Val   Loss: 0.8249 | Val   Acc: 0.6489\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4911 | Train Acc: 0.7630\n",
      "Val   Loss: 0.5763 | Val   Acc: 0.7766\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4598 | Train Acc: 0.7876\n",
      "Val   Loss: 0.5144 | Val   Acc: 0.7617\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4461 | Train Acc: 0.7821\n",
      "Val   Loss: 0.5513 | Val   Acc: 0.6894\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4349 | Train Acc: 0.7940\n",
      "Val   Loss: 0.4826 | Val   Acc: 0.7596\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4584 | Train Acc: 0.7876\n",
      "Val   Loss: 0.5458 | Val   Acc: 0.7064\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4577 | Train Acc: 0.7885\n",
      "Val   Loss: 0.5920 | Val   Acc: 0.7170\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4503 | Train Acc: 0.7931\n",
      "Val   Loss: 0.4688 | Val   Acc: 0.7830\n",
      "✅ Checkpoint saved at epoch 31 (min acc: 0.7830)\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4515 | Train Acc: 0.7767\n",
      "Val   Loss: 0.5037 | Val   Acc: 0.7553\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4386 | Train Acc: 0.7922\n",
      "Val   Loss: 0.6052 | Val   Acc: 0.6915\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4611 | Train Acc: 0.7803\n",
      "Val   Loss: 0.5092 | Val   Acc: 0.7596\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4492 | Train Acc: 0.7840\n",
      "Val   Loss: 0.4516 | Val   Acc: 0.7872\n",
      "✅ Checkpoint saved at epoch 35 (min acc: 0.7840)\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4137 | Train Acc: 0.8031\n",
      "Val   Loss: 0.5230 | Val   Acc: 0.7894\n",
      "✅ Checkpoint saved at epoch 36 (min acc: 0.7894)\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4218 | Train Acc: 0.8031\n",
      "Val   Loss: 0.4639 | Val   Acc: 0.7894\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4264 | Train Acc: 0.8013\n",
      "Val   Loss: 0.4731 | Val   Acc: 0.7957\n",
      "✅ Checkpoint saved at epoch 38 (min acc: 0.7957)\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4133 | Train Acc: 0.7940\n",
      "Val   Loss: 0.6965 | Val   Acc: 0.7085\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4250 | Train Acc: 0.8067\n",
      "Val   Loss: 0.4962 | Val   Acc: 0.7745\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4077 | Train Acc: 0.8095\n",
      "Val   Loss: 0.4826 | Val   Acc: 0.7809\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4260 | Train Acc: 0.8049\n",
      "Val   Loss: 0.4503 | Val   Acc: 0.7809\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4334 | Train Acc: 0.8104\n",
      "Val   Loss: 0.4951 | Val   Acc: 0.7766\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3931 | Train Acc: 0.8259\n",
      "Val   Loss: 0.4606 | Val   Acc: 0.8021\n",
      "✅ Checkpoint saved at epoch 44 (min acc: 0.8021)\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3915 | Train Acc: 0.8104\n",
      "Val   Loss: 0.4204 | Val   Acc: 0.8213\n",
      "✅ Checkpoint saved at epoch 45 (min acc: 0.8104)\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3900 | Train Acc: 0.8222\n",
      "Val   Loss: 0.4396 | Val   Acc: 0.7787\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3781 | Train Acc: 0.8140\n",
      "Val   Loss: 0.4942 | Val   Acc: 0.8000\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3784 | Train Acc: 0.8241\n",
      "Val   Loss: 0.4120 | Val   Acc: 0.8106\n",
      "✅ Checkpoint saved at epoch 48 (min acc: 0.8106)\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3680 | Train Acc: 0.8213\n",
      "Val   Loss: 0.4791 | Val   Acc: 0.7894\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3872 | Train Acc: 0.8149\n",
      "Val   Loss: 0.4050 | Val   Acc: 0.7660\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3899 | Train Acc: 0.8222\n",
      "Val   Loss: 0.3903 | Val   Acc: 0.8170\n",
      "✅ Checkpoint saved at epoch 51 (min acc: 0.8170)\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3718 | Train Acc: 0.8195\n",
      "Val   Loss: 0.4093 | Val   Acc: 0.8106\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3612 | Train Acc: 0.8259\n",
      "Val   Loss: 0.6440 | Val   Acc: 0.7511\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3681 | Train Acc: 0.8350\n",
      "Val   Loss: 0.3890 | Val   Acc: 0.8319\n",
      "✅ Checkpoint saved at epoch 54 (min acc: 0.8319)\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3838 | Train Acc: 0.8168\n",
      "Val   Loss: 0.4479 | Val   Acc: 0.8043\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3799 | Train Acc: 0.8195\n",
      "Val   Loss: 0.3861 | Val   Acc: 0.8021\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3848 | Train Acc: 0.8122\n",
      "Val   Loss: 0.3848 | Val   Acc: 0.8191\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3638 | Train Acc: 0.8387\n",
      "Val   Loss: 0.4016 | Val   Acc: 0.8213\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3558 | Train Acc: 0.8295\n",
      "Val   Loss: 0.3925 | Val   Acc: 0.7936\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3571 | Train Acc: 0.8250\n",
      "Val   Loss: 0.3820 | Val   Acc: 0.8298\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3710 | Train Acc: 0.8350\n",
      "Val   Loss: 0.4251 | Val   Acc: 0.7617\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3446 | Train Acc: 0.8450\n",
      "Val   Loss: 0.4504 | Val   Acc: 0.8043\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3676 | Train Acc: 0.8396\n",
      "Val   Loss: 0.4132 | Val   Acc: 0.7936\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3818 | Train Acc: 0.8195\n",
      "Val   Loss: 0.4471 | Val   Acc: 0.7468\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3552 | Train Acc: 0.8414\n",
      "Val   Loss: 0.3936 | Val   Acc: 0.8170\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3629 | Train Acc: 0.8268\n",
      "Val   Loss: 0.4029 | Val   Acc: 0.8362\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3422 | Train Acc: 0.8222\n",
      "Val   Loss: 0.3864 | Val   Acc: 0.7894\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3848 | Train Acc: 0.8387\n",
      "Val   Loss: 0.3869 | Val   Acc: 0.8234\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3698 | Train Acc: 0.8323\n",
      "Val   Loss: 0.3921 | Val   Acc: 0.8191\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3568 | Train Acc: 0.8250\n",
      "Val   Loss: 0.4074 | Val   Acc: 0.8234\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3506 | Train Acc: 0.8314\n",
      "Val   Loss: 0.4070 | Val   Acc: 0.7809\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3472 | Train Acc: 0.8341\n",
      "Val   Loss: 0.3834 | Val   Acc: 0.7766\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3773 | Train Acc: 0.8213\n",
      "Val   Loss: 0.3737 | Val   Acc: 0.8213\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3649 | Train Acc: 0.8341\n",
      "Val   Loss: 0.4113 | Val   Acc: 0.8213\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3526 | Train Acc: 0.8232\n",
      "Val   Loss: 0.3837 | Val   Acc: 0.8128\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3518 | Train Acc: 0.8323\n",
      "Val   Loss: 0.5239 | Val   Acc: 0.8064\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3574 | Train Acc: 0.8268\n",
      "Val   Loss: 0.4160 | Val   Acc: 0.7532\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3505 | Train Acc: 0.8387\n",
      "Val   Loss: 0.3862 | Val   Acc: 0.8213\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3453 | Train Acc: 0.8450\n",
      "Val   Loss: 0.4423 | Val   Acc: 0.8191\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3611 | Train Acc: 0.8350\n",
      "Val   Loss: 0.3680 | Val   Acc: 0.8213\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3343 | Train Acc: 0.8459\n",
      "Val   Loss: 0.3769 | Val   Acc: 0.8319\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3778 | Train Acc: 0.8350\n",
      "Val   Loss: 0.3689 | Val   Acc: 0.7787\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3212 | Train Acc: 0.8505\n",
      "Val   Loss: 0.4562 | Val   Acc: 0.7915\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3246 | Train Acc: 0.8332\n",
      "Val   Loss: 0.4828 | Val   Acc: 0.8106\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3406 | Train Acc: 0.8241\n",
      "Val   Loss: 0.3756 | Val   Acc: 0.8064\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3329 | Train Acc: 0.8469\n",
      "Val   Loss: 0.3725 | Val   Acc: 0.8106\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3765 | Train Acc: 0.8341\n",
      "Val   Loss: 0.3813 | Val   Acc: 0.8085\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3540 | Train Acc: 0.8341\n",
      "Val   Loss: 0.5034 | Val   Acc: 0.7532\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3745 | Train Acc: 0.8286\n",
      "Val   Loss: 0.3818 | Val   Acc: 0.8043\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3526 | Train Acc: 0.8459\n",
      "Val   Loss: 0.6071 | Val   Acc: 0.7596\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3362 | Train Acc: 0.8387\n",
      "Val   Loss: 0.4000 | Val   Acc: 0.8234\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3381 | Train Acc: 0.8505\n",
      "Val   Loss: 0.3875 | Val   Acc: 0.7766\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3363 | Train Acc: 0.8450\n",
      "Val   Loss: 0.4718 | Val   Acc: 0.8043\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3310 | Train Acc: 0.8387\n",
      "Val   Loss: 0.4172 | Val   Acc: 0.8106\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3470 | Train Acc: 0.8377\n",
      "Val   Loss: 0.3797 | Val   Acc: 0.8064\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3457 | Train Acc: 0.8332\n",
      "Val   Loss: 0.3855 | Val   Acc: 0.7936\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3555 | Train Acc: 0.8387\n",
      "Val   Loss: 0.4881 | Val   Acc: 0.8021\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3195 | Train Acc: 0.8441\n",
      "Val   Loss: 0.3762 | Val   Acc: 0.8298\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3676 | Train Acc: 0.8396\n",
      "Val   Loss: 0.4139 | Val   Acc: 0.7915\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3445 | Train Acc: 0.8241\n",
      "Val   Loss: 0.3947 | Val   Acc: 0.7979\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = Model0().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "num_epochs = 100\n",
    "best_score = 0.0 # to store the best min(train_acc, val_acc)\n",
    "checkpoint_path = \"best_model.pt\"\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Check if this epoch's min(train_acc, val_acc) is the best so far\n",
    "    score = min(train_acc, val_acc)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "            'loss': val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"✅ Checkpoint saved at epoch {epoch+1} (min acc: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53b7013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monar\\AppData\\Local\\Temp\\ipykernel_21952\\4085352592.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load(checkpoint_path)['optimizer_state_dict'])\n",
      "C:\\Users\\monar\\AppData\\Local\\Temp\\ipykernel_21952\\4085352592.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.load_state_dict(torch.load(checkpoint_path)['optimizer_state_dict'])\n",
    "model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c892fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monar\\AppData\\Local\\Temp\\ipykernel_21952\\1188143922.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model0(\n",
       "  (imputer): ImputationLayer()\n",
       "  (scaler): TrainableScaler()\n",
       "  (edu_linear): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (marital_linear): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (main_linears): Sequential(\n",
       "    (0): Linear(in_features=43, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout(p=0.2, inplace=False)\n",
       "    (16): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Dropout(p=0.2, inplace=False)\n",
       "    (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (21): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): Dropout(p=0.2, inplace=False)\n",
       "    (24): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (25): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Dropout(p=0.2, inplace=False)\n",
       "    (28): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (29): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature lists based on notebook analysis\n",
    "NUMERICAL_COLS = [\n",
    "    'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Dates', 'Recency',\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "    'MntSweetProducts', 'MntGoldProds', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumDealsPurchases', 'NumWebVisitsMonth', 'AcceptedCmp1',\n",
    "    'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Complain'\n",
    "]\n",
    "EDU_COL = 'Education'\n",
    "MARITAL_COL = 'Marital_Status'\n",
    "TARGET_COL = 'Target'\n",
    "DATE_COL = 'Dt_Customer'\n",
    "ID_COL = 'ID'  # ID column for submission file\n",
    "\n",
    "N_NUM_FEATURES = len(NUMERICAL_COLS) # Should be 23\n",
    "N_EDU_FEATURES = 5 # Based on notebook encoding\n",
    "N_MARITAL_FEATURES = 6 # Based on notebook encoding\n",
    "TOTAL_FEATURES = N_NUM_FEATURES + N_EDU_FEATURES + N_MARITAL_FEATURES # Should be 34\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Applies preprocessing steps from the notebook.\"\"\"\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Keep the ID column for later if it exists\n",
    "    id_values = None\n",
    "    if ID_COL in df_processed.columns:\n",
    "        id_values = df_processed[ID_COL].copy()\n",
    "\n",
    "    # 1. Handle Date Feature ('Dt_Customer')\n",
    "    try:\n",
    "        df_processed['Dt_Customer_1'] = pd.to_datetime(df_processed[DATE_COL], format='mixed', errors='coerce')\n",
    "        min_date = df_processed['Dt_Customer_1'].min()\n",
    "        df_processed['Dates'] = (df_processed['Dt_Customer_1'] - min_date).dt.days\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date column {DATE_COL}: {e}\")\n",
    "        # Handle cases where date conversion might fail entirely - fill with 0 or median?\n",
    "        df_processed['Dates'] = 0 # Simple fallback\n",
    "\n",
    "    # Check for NaNs introduced by date conversion errors\n",
    "    if df_processed['Dates'].isnull().any():\n",
    "        print(f\"Warning: NaNs found in 'Dates' column after conversion. Filling with 0.\")\n",
    "        df_processed['Dates'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # 2. Handle Categorical Features ('Education', 'Marital_Status')\n",
    "    # Define mappings (ensure consistency with notebook)\n",
    "    unique_edu = df_processed[EDU_COL].unique()\n",
    "    unique_marital = df_processed[MARITAL_COL].unique()\n",
    "\n",
    "    # Handle potential NaNs in categorical columns before mapping\n",
    "    if df_processed[EDU_COL].isnull().any():\n",
    "        print(f\"Warning: NaNs found in {EDU_COL}. Filling with a placeholder 'Unknown'.\")\n",
    "        df_processed[EDU_COL].fillna('Unknown', inplace=True)\n",
    "        if 'Unknown' not in unique_edu:\n",
    "             unique_edu = np.append(unique_edu, 'Unknown')\n",
    "\n",
    "    if df_processed[MARITAL_COL].isnull().any():\n",
    "        print(f\"Warning: NaNs found in {MARITAL_COL}. Filling with a placeholder 'Unknown'.\")\n",
    "        df_processed[MARITAL_COL].fillna('Unknown', inplace=True)\n",
    "        if 'Unknown' not in unique_marital:\n",
    "             unique_marital = np.append(unique_marital, 'Unknown')\n",
    "\n",
    "\n",
    "    Education_map = {category: [1 if i == idx else 0 for i in range(N_EDU_FEATURES)] # Use fixed size\n",
    "                     for idx, category in enumerate(unique_edu) if idx < N_EDU_FEATURES}\n",
    "    Marital_status_map = {category: [1 if i == idx else 0 for i in range(N_MARITAL_FEATURES)] # Use fixed size\n",
    "                          for idx, category in enumerate(unique_marital) if idx < N_MARITAL_FEATURES}\n",
    "\n",
    "    # Add default mapping for any unexpected values (e.g., 'Unknown' if it exceeds N_EDU_FEATURES)\n",
    "    default_edu_encoding = [0] * N_EDU_FEATURES\n",
    "    default_marital_encoding = [0] * N_MARITAL_FEATURES\n",
    "\n",
    "    df_processed[EDU_COL] = df_processed[EDU_COL].apply(lambda x: Education_map.get(x, default_edu_encoding))\n",
    "    df_processed[MARITAL_COL] = df_processed[MARITAL_COL].apply(lambda x: Marital_status_map.get(x, default_marital_encoding))\n",
    "\n",
    "\n",
    "    # Ensure the lengths match the model definition (handle potential discrepancies)\n",
    "    # Note: Mapping logic now uses fixed N_EDU_FEATURES/N_MARITAL_FEATURES\n",
    "    # if len(unique_edu) > N_EDU_FEATURES:\n",
    "    #      print(f\"Warning: More unique Education levels found ({len(unique_edu)}) than expected ({N_EDU_FEATURES}). Check data/mapping.\")\n",
    "    # if len(unique_marital) > N_MARITAL_FEATURES:\n",
    "    #      print(f\"Warning: More unique Marital Statuses found ({len(unique_marital)}) than expected ({N_MARITAL_FEATURES}). Check data/mapping.\")\n",
    "\n",
    "    # Keep only necessary columns (features + target)\n",
    "    all_feature_cols = NUMERICAL_COLS + [EDU_COL, MARITAL_COL]\n",
    "    if TARGET_COL in df_processed.columns:\n",
    "        final_cols = all_feature_cols + [TARGET_COL]\n",
    "    else:\n",
    "        final_cols = all_feature_cols # For test data\n",
    "\n",
    "    # Check if all expected columns exist after potential removals/errors\n",
    "    missing_cols = [col for col in final_cols if col not in df_processed.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: The following columns are missing after preprocessing: {missing_cols}\")\n",
    "        # Decide how to handle this, e.g., raise error or try to continue\n",
    "        raise ValueError(f\"Missing columns after preprocessing: {missing_cols}\")\n",
    "\n",
    "    df_final = df_processed[final_cols].copy()\n",
    "\n",
    "    # Note: Imputation is handled by the Imputation_layer within the model\n",
    "\n",
    "    return df_final, id_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad51ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "        # Extract features and target, convert to numpy for efficiency\n",
    "        self.numerical_features = self.dataframe[NUMERICAL_COLS].values.astype(np.float32)\n",
    "        # Stack the list of lists into a 2D numpy array\n",
    "        self.edu_features = np.array(self.dataframe[EDU_COL].tolist(), dtype=np.float32)\n",
    "        self.marital_features = np.array(self.dataframe[MARITAL_COL].tolist(), dtype=np.float32)\n",
    "\n",
    "        if TARGET_COL in self.dataframe.columns:\n",
    "            self.targets = self.dataframe[TARGET_COL].values.astype(np.float32)\n",
    "        else:\n",
    "            self.targets = None # No targets in test set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num = torch.tensor(self.numerical_features[idx, :], dtype=torch.float32)\n",
    "        edu = torch.tensor(self.edu_features[idx, :], dtype=torch.float32)\n",
    "        mar = torch.tensor(self.marital_features[idx, :], dtype=torch.float32)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            target = torch.tensor([self.targets[idx]], dtype=torch.float32) # Shape [1] for BCEWithLogitsLoss\n",
    "            return num, edu, mar, target\n",
    "        else:\n",
    "            return num, edu, mar # Return only features for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    \"\"\"Generate predictions using a trained model.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for batch_data in test_loader:\n",
    "            # Adjust for the new model's forward method\n",
    "            # Move all inputs to device\n",
    "            inputs = [x.to(device) for x in batch_data]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Convert outputs to binary predictions (model now includes sigmoid)\n",
    "            predictions = (outputs >= 0.5).int().cpu().numpy()\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "823d0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Convert predictions to a DataFrame\n",
    "lists = [\n",
    "    'ID',\n",
    "    'Year_Birth',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Dates',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'AcceptedCmp1',\n",
    "    'AcceptedCmp2',\n",
    "    'AcceptedCmp3',\n",
    "    'AcceptedCmp4',\n",
    "    'AcceptedCmp5',\n",
    "    'Complain',\n",
    "    'Education',\n",
    "    'Marital_Status'\n",
    "]\n",
    "test_loader_test,_ = get_dataloaders(test, lists, batch_size=1, test_split=0, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1907512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "dis = {}\n",
    "# with torch.no_grad():\n",
    "for i in test_loader_test:\n",
    "\n",
    "    batch = [torch.stack(col).unsqueeze(0).to(device) for col in i[1:]]\n",
    "    out = model(batch)\n",
    "    pred = out>0.5\n",
    "    pred = pred.int().cpu().numpy()\n",
    "    all_predictions.extend(pred.tolist())\n",
    "    dis[i[0][0]] = pred.tolist()[0]\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b88d6c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(3389.): 1,\n",
       " tensor(3968.): 1,\n",
       " tensor(2495.): 0,\n",
       " tensor(1172.): 1,\n",
       " tensor(4608.): 0,\n",
       " tensor(9847.): 1,\n",
       " tensor(2156.): 0,\n",
       " tensor(10609.): 0,\n",
       " tensor(5272.): 0,\n",
       " tensor(7007.): 0,\n",
       " tensor(1818.): 0,\n",
       " tensor(3657.): 0,\n",
       " tensor(6544.): 0,\n",
       " tensor(9860.): 1,\n",
       " tensor(10722.): 1,\n",
       " tensor(2254.): 0,\n",
       " tensor(8584.): 0,\n",
       " tensor(10897.): 1,\n",
       " tensor(5150.): 0,\n",
       " tensor(10469.): 1,\n",
       " tensor(10241.): 0,\n",
       " tensor(10069.): 0,\n",
       " tensor(10307.): 0,\n",
       " tensor(3661.): 0,\n",
       " tensor(8720.): 0,\n",
       " tensor(10652.): 0,\n",
       " tensor(9727.): 0,\n",
       " tensor(1890.): 0,\n",
       " tensor(4084.): 0,\n",
       " tensor(1458.): 0,\n",
       " tensor(3517.): 0,\n",
       " tensor(5010.): 0,\n",
       " tensor(1958.): 0,\n",
       " tensor(4333.): 0,\n",
       " tensor(9405.): 0,\n",
       " tensor(8008.): 0,\n",
       " tensor(8969.): 0,\n",
       " tensor(5396.): 1,\n",
       " tensor(7397.): 1,\n",
       " tensor(10352.): 0,\n",
       " tensor(5092.): 1,\n",
       " tensor(4001.): 0,\n",
       " tensor(3859.): 1,\n",
       " tensor(1399.): 0,\n",
       " tensor(6710.): 0,\n",
       " tensor(11092.): 0,\n",
       " tensor(3829.): 0,\n",
       " tensor(7004.): 0,\n",
       " tensor(6663.): 0,\n",
       " tensor(4065.): 1,\n",
       " tensor(10560.): 0,\n",
       " tensor(7861.): 1,\n",
       " tensor(6147.): 0,\n",
       " tensor(10640.): 0,\n",
       " tensor(8360.): 0,\n",
       " tensor(7610.): 0,\n",
       " tensor(8299.): 0,\n",
       " tensor(9971.): 0,\n",
       " tensor(6461.): 0,\n",
       " tensor(1250.): 0,\n",
       " tensor(10757.): 0,\n",
       " tensor(8486.): 0,\n",
       " tensor(10821.): 0,\n",
       " tensor(1867.): 1,\n",
       " tensor(1834.): 0,\n",
       " tensor(7788.): 0,\n",
       " tensor(10868.): 0,\n",
       " tensor(10157.): 0,\n",
       " tensor(87.): 0,\n",
       " tensor(8439.): 0,\n",
       " tensor(7592.): 0,\n",
       " tensor(6097.): 1,\n",
       " tensor(5423.): 0,\n",
       " tensor(8933.): 0,\n",
       " tensor(10164.): 1,\n",
       " tensor(3722.): 0,\n",
       " tensor(7187.): 0,\n",
       " tensor(3799.): 1,\n",
       " tensor(6250.): 1,\n",
       " tensor(1378.): 1,\n",
       " tensor(269.): 0,\n",
       " tensor(2948.): 0,\n",
       " tensor(2980.): 0,\n",
       " tensor(5796.): 0,\n",
       " tensor(6355.): 0,\n",
       " tensor(5534.): 1,\n",
       " tensor(6575.): 1,\n",
       " tensor(5790.): 0,\n",
       " tensor(6200.): 0,\n",
       " tensor(2431.): 0,\n",
       " tensor(3878.): 0,\n",
       " tensor(2831.): 0,\n",
       " tensor(10477.): 0,\n",
       " tensor(3828.): 1,\n",
       " tensor(8212.): 0,\n",
       " tensor(9323.): 1,\n",
       " tensor(8514.): 0,\n",
       " tensor(1170.): 0,\n",
       " tensor(4971.): 0,\n",
       " tensor(6568.): 0,\n",
       " tensor(11031.): 0,\n",
       " tensor(4827.): 1,\n",
       " tensor(8895.): 0,\n",
       " tensor(7873.): 0,\n",
       " tensor(521.): 0,\n",
       " tensor(2471.): 0,\n",
       " tensor(9710.): 1,\n",
       " tensor(5186.): 1,\n",
       " tensor(7408.): 1,\n",
       " tensor(2115.): 0,\n",
       " tensor(6215.): 0,\n",
       " tensor(10870.): 1,\n",
       " tensor(10141.): 0,\n",
       " tensor(10176.): 1,\n",
       " tensor(7990.): 0,\n",
       " tensor(3130.): 0,\n",
       " tensor(6103.): 0,\n",
       " tensor(2186.): 1,\n",
       " tensor(10250.): 0,\n",
       " tensor(2961.): 0,\n",
       " tensor(78.): 0,\n",
       " tensor(10686.): 0,\n",
       " tensor(7732.): 0,\n",
       " tensor(9829.): 0,\n",
       " tensor(5847.): 0,\n",
       " tensor(1891.): 1,\n",
       " tensor(4547.): 0,\n",
       " tensor(5370.): 1,\n",
       " tensor(8619.): 0,\n",
       " tensor(1064.): 0,\n",
       " tensor(9284.): 1,\n",
       " tensor(3265.): 0,\n",
       " tensor(8625.): 0,\n",
       " tensor(3138.): 1,\n",
       " tensor(9292.): 0,\n",
       " tensor(6859.): 0,\n",
       " tensor(1744.): 0,\n",
       " tensor(1381.): 0,\n",
       " tensor(7233.): 1,\n",
       " tensor(4994.): 1,\n",
       " tensor(11181.): 0,\n",
       " tensor(9931.): 0,\n",
       " tensor(7899.): 1,\n",
       " tensor(8722.): 1,\n",
       " tensor(5093.): 0,\n",
       " tensor(5394.): 0,\n",
       " tensor(5250.): 0,\n",
       " tensor(7313.): 0,\n",
       " tensor(2929.): 0,\n",
       " tensor(6262.): 0,\n",
       " tensor(2285.): 1,\n",
       " tensor(4480.): 0,\n",
       " tensor(5062.): 0,\n",
       " tensor(2478.): 0,\n",
       " tensor(10968.): 1,\n",
       " tensor(6437.): 0,\n",
       " tensor(3426.): 0,\n",
       " tensor(3422.): 1,\n",
       " tensor(4837.): 1,\n",
       " tensor(5734.): 0,\n",
       " tensor(5453.): 1,\n",
       " tensor(11187.): 0,\n",
       " tensor(3010.): 1,\n",
       " tensor(1459.): 1,\n",
       " tensor(6409.): 1,\n",
       " tensor(4427.): 1,\n",
       " tensor(642.): 0,\n",
       " tensor(4268.): 0,\n",
       " tensor(9242.): 1,\n",
       " tensor(24.): 0,\n",
       " tensor(10127.): 1,\n",
       " tensor(8832.): 0,\n",
       " tensor(3969.): 0,\n",
       " tensor(4351.): 0,\n",
       " tensor(2870.): 1,\n",
       " tensor(8780.): 0,\n",
       " tensor(6870.): 0,\n",
       " tensor(7002.): 0,\n",
       " tensor(10742.): 0,\n",
       " tensor(5283.): 0,\n",
       " tensor(3074.): 0,\n",
       " tensor(2202.): 0,\n",
       " tensor(11148.): 0,\n",
       " tensor(1168.): 0,\n",
       " tensor(8605.): 0,\n",
       " tensor(9595.): 1,\n",
       " tensor(7966.): 1,\n",
       " tensor(10789.): 0,\n",
       " tensor(8537.): 0,\n",
       " tensor(954.): 0,\n",
       " tensor(3009.): 1,\n",
       " tensor(11133.): 1,\n",
       " tensor(6715.): 1,\n",
       " tensor(5623.): 0,\n",
       " tensor(4127.): 1,\n",
       " tensor(7943.): 0,\n",
       " tensor(3678.): 1,\n",
       " tensor(3091.): 0,\n",
       " tensor(3409.): 0,\n",
       " tensor(5883.): 0,\n",
       " tensor(4867.): 0,\n",
       " tensor(7393.): 0,\n",
       " tensor(2162.): 0,\n",
       " tensor(7679.): 0,\n",
       " tensor(1655.): 0,\n",
       " tensor(9668.): 0,\n",
       " tensor(3107.): 0,\n",
       " tensor(8175.): 0,\n",
       " tensor(10001.): 0,\n",
       " tensor(4227.): 0,\n",
       " tensor(10949.): 1,\n",
       " tensor(2262.): 0,\n",
       " tensor(8858.): 1,\n",
       " tensor(1165.): 0,\n",
       " tensor(2337.): 0,\n",
       " tensor(3117.): 0,\n",
       " tensor(2452.): 1,\n",
       " tensor(4328.): 0,\n",
       " tensor(1055.): 0,\n",
       " tensor(2878.): 0,\n",
       " tensor(6983.): 0,\n",
       " tensor(3433.): 0,\n",
       " tensor(9648.): 1,\n",
       " tensor(6173.): 1,\n",
       " tensor(4865.): 1,\n",
       " tensor(3491.): 1,\n",
       " tensor(1626.): 0,\n",
       " tensor(2181.): 0,\n",
       " tensor(4541.): 0,\n",
       " tensor(5684.): 0,\n",
       " tensor(1646.): 0,\n",
       " tensor(832.): 0,\n",
       " tensor(9952.): 0,\n",
       " tensor(6237.): 1,\n",
       " tensor(3599.): 1,\n",
       " tensor(1619.): 0,\n",
       " tensor(3570.): 0,\n",
       " tensor(8925.): 1,\n",
       " tensor(7349.): 0,\n",
       " tensor(10448.): 1,\n",
       " tensor(3565.): 0,\n",
       " tensor(2154.): 0,\n",
       " tensor(9119.): 0,\n",
       " tensor(3011.): 0,\n",
       " tensor(10323.): 0,\n",
       " tensor(2952.): 0,\n",
       " tensor(1630.): 0,\n",
       " tensor(7960.): 0,\n",
       " tensor(7881.): 1,\n",
       " tensor(4168.): 0,\n",
       " tensor(5939.): 0,\n",
       " tensor(1570.): 1,\n",
       " tensor(1665.): 1,\n",
       " tensor(10091.): 0,\n",
       " tensor(5991.): 1,\n",
       " tensor(3334.): 1,\n",
       " tensor(7181.): 0,\n",
       " tensor(1087.): 0,\n",
       " tensor(7485.): 0,\n",
       " tensor(6977.): 1,\n",
       " tensor(5177.): 0,\n",
       " tensor(7620.): 0,\n",
       " tensor(4931.): 1,\n",
       " tensor(9467.): 0,\n",
       " tensor(6457.): 0,\n",
       " tensor(2802.): 0,\n",
       " tensor(6742.): 0,\n",
       " tensor(8143.): 0,\n",
       " tensor(10841.): 0,\n",
       " tensor(2656.): 0,\n",
       " tensor(8372.): 0,\n",
       " tensor(10281.): 0,\n",
       " tensor(6347.): 0,\n",
       " tensor(4687.): 0,\n",
       " tensor(10057.): 0,\n",
       " tensor(5316.): 0,\n",
       " tensor(5454.): 0,\n",
       " tensor(8230.): 0,\n",
       " tensor(7419.): 0,\n",
       " tensor(10691.): 0,\n",
       " tensor(5667.): 1,\n",
       " tensor(1964.): 0,\n",
       " tensor(6729.): 0,\n",
       " tensor(1403.): 0,\n",
       " tensor(2634.): 0,\n",
       " tensor(9907.): 0,\n",
       " tensor(1100.): 0,\n",
       " tensor(255.): 0,\n",
       " tensor(5079.): 0,\n",
       " tensor(2681.): 0,\n",
       " tensor(5209.): 1,\n",
       " tensor(6815.): 1,\n",
       " tensor(2549.): 0,\n",
       " tensor(3170.): 0,\n",
       " tensor(9289.): 0,\n",
       " tensor(5782.): 1,\n",
       " tensor(8685.): 0,\n",
       " tensor(6892.): 1,\n",
       " tensor(1052.): 1,\n",
       " tensor(252.): 0,\n",
       " tensor(5544.): 1,\n",
       " tensor(7019.): 0,\n",
       " tensor(1513.): 0,\n",
       " tensor(2666.): 1,\n",
       " tensor(9612.): 0,\n",
       " tensor(9729.): 1,\n",
       " tensor(2829.): 1,\n",
       " tensor(6289.): 0,\n",
       " tensor(10680.): 0,\n",
       " tensor(4796.): 0,\n",
       " tensor(10951.): 1,\n",
       " tensor(762.): 0,\n",
       " tensor(4478.): 0,\n",
       " tensor(1045.): 0,\n",
       " tensor(7849.): 0,\n",
       " tensor(3283.): 0,\n",
       " tensor(1990.): 1,\n",
       " tensor(10676.): 1,\n",
       " tensor(7270.): 0,\n",
       " tensor(10177.): 1,\n",
       " tensor(1406.): 0,\n",
       " tensor(5180.): 0,\n",
       " tensor(5299.): 1,\n",
       " tensor(8852.): 0,\n",
       " tensor(10678.): 1,\n",
       " tensor(5513.): 0,\n",
       " tensor(8812.): 0,\n",
       " tensor(123.): 0,\n",
       " tensor(6679.): 0,\n",
       " tensor(7129.): 0,\n",
       " tensor(9817.): 0,\n",
       " tensor(9064.): 1,\n",
       " tensor(2429.): 1,\n",
       " tensor(5866.): 0,\n",
       " tensor(4552.): 0,\n",
       " tensor(7005.): 0,\n",
       " tensor(569.): 1,\n",
       " tensor(10340.): 0,\n",
       " tensor(7530.): 0,\n",
       " tensor(3006.): 0,\n",
       " tensor(4838.): 0,\n",
       " tensor(1407.): 0,\n",
       " tensor(10790.): 0,\n",
       " tensor(2375.): 0,\n",
       " tensor(1000.): 1,\n",
       " tensor(3104.): 1,\n",
       " tensor(8079.): 0,\n",
       " tensor(7919.): 1,\n",
       " tensor(1041.): 1,\n",
       " tensor(2909.): 1,\n",
       " tensor(692.): 0,\n",
       " tensor(3032.): 0,\n",
       " tensor(2415.): 0,\n",
       " tensor(4860.): 0,\n",
       " tensor(983.): 0,\n",
       " tensor(2565.): 1,\n",
       " tensor(492.): 1,\n",
       " tensor(4749.): 1,\n",
       " tensor(8080.): 0,\n",
       " tensor(902.): 0,\n",
       " tensor(4426.): 1,\n",
       " tensor(1103.): 1,\n",
       " tensor(5117.): 0,\n",
       " tensor(10701.): 1,\n",
       " tensor(6497.): 1,\n",
       " tensor(4973.): 0,\n",
       " tensor(6428.): 0,\n",
       " tensor(5959.): 0,\n",
       " tensor(2632.): 1,\n",
       " tensor(3262.): 1,\n",
       " tensor(8416.): 0,\n",
       " tensor(898.): 0,\n",
       " tensor(531.): 1,\n",
       " tensor(295.): 0,\n",
       " tensor(9432.): 0,\n",
       " tensor(7629.): 0,\n",
       " tensor(9576.): 0,\n",
       " tensor(5626.): 0,\n",
       " tensor(10339.): 0,\n",
       " tensor(3498.): 1,\n",
       " tensor(2781.): 1,\n",
       " tensor(4385.): 0,\n",
       " tensor(8602.): 0,\n",
       " tensor(7505.): 0,\n",
       " tensor(7165.): 0,\n",
       " tensor(8397.): 0,\n",
       " tensor(3520.): 1,\n",
       " tensor(153.): 0,\n",
       " tensor(10785.): 0,\n",
       " tensor(4055.): 0,\n",
       " tensor(3254.): 0,\n",
       " tensor(2493.): 0,\n",
       " tensor(2814.): 0,\n",
       " tensor(7842.): 0,\n",
       " tensor(10500.): 0,\n",
       " tensor(5896.): 0,\n",
       " tensor(4338.): 0,\n",
       " tensor(6214.): 0,\n",
       " tensor(7734.): 0,\n",
       " tensor(10394.): 1,\n",
       " tensor(7101.): 1,\n",
       " tensor(3783.): 0,\n",
       " tensor(10104.): 0,\n",
       " tensor(8524.): 0,\n",
       " tensor(10598.): 0,\n",
       " tensor(10913.): 0,\n",
       " tensor(1773.): 0,\n",
       " tensor(2546.): 0,\n",
       " tensor(5517.): 0,\n",
       " tensor(1839.): 0,\n",
       " tensor(7872.): 1,\n",
       " tensor(3507.): 0,\n",
       " tensor(4712.): 0,\n",
       " tensor(6866.): 0,\n",
       " tensor(10513.): 0,\n",
       " tensor(8334.): 0,\n",
       " tensor(1612.): 0,\n",
       " tensor(10304.): 0,\n",
       " tensor(10356.): 0,\n",
       " tensor(10067.): 0,\n",
       " tensor(9507.): 1,\n",
       " tensor(8070.): 0,\n",
       " tensor(544.): 0,\n",
       " tensor(10129.): 0,\n",
       " tensor(1071.): 1,\n",
       " tensor(4023.): 0,\n",
       " tensor(1544.): 1,\n",
       " tensor(11091.): 0,\n",
       " tensor(4470.): 0,\n",
       " tensor(2345.): 0,\n",
       " tensor(2715.): 0,\n",
       " tensor(6257.): 0,\n",
       " tensor(6906.): 1,\n",
       " tensor(3503.): 0,\n",
       " tensor(2694.): 0,\n",
       " tensor(2326.): 0,\n",
       " tensor(332.): 0,\n",
       " tensor(3919.): 1,\n",
       " tensor(10207.): 0,\n",
       " tensor(3690.): 1,\n",
       " tensor(1008.): 1,\n",
       " tensor(6349.): 0,\n",
       " tensor(5832.): 0,\n",
       " tensor(6507.): 0,\n",
       " tensor(975.): 0,\n",
       " tensor(5628.): 1,\n",
       " tensor(10099.): 0,\n",
       " tensor(1215.): 0,\n",
       " tensor(8286.): 0,\n",
       " tensor(10711.): 0,\n",
       " tensor(5558.): 1,\n",
       " tensor(1139.): 1,\n",
       " tensor(5393.): 0,\n",
       " tensor(1321.): 0,\n",
       " tensor(2747.): 0,\n",
       " tensor(1419.): 0,\n",
       " tensor(1241.): 0,\n",
       " tensor(7428.): 0,\n",
       " tensor(8775.): 0,\n",
       " tensor(9167.): 1,\n",
       " tensor(10092.): 1,\n",
       " tensor(10643.): 0,\n",
       " tensor(4369.): 0,\n",
       " tensor(2686.): 0,\n",
       " tensor(4201.): 0,\n",
       " tensor(5441.): 0,\n",
       " tensor(626.): 0,\n",
       " tensor(7042.): 0,\n",
       " tensor(7396.): 1,\n",
       " tensor(10858.): 1,\n",
       " tensor(4377.): 1,\n",
       " tensor(10398.): 0,\n",
       " tensor(8659.): 0,\n",
       " tensor(5831.): 1,\n",
       " tensor(6248.): 1,\n",
       " tensor(4548.): 0,\n",
       " tensor(10521.): 0,\n",
       " tensor(405.): 1,\n",
       " tensor(6183.): 0,\n",
       " tensor(6292.): 1,\n",
       " tensor(5015.): 0,\n",
       " tensor(4915.): 0,\n",
       " tensor(10478.): 1,\n",
       " tensor(1440.): 0,\n",
       " tensor(4095.): 0,\n",
       " tensor(4676.): 1,\n",
       " tensor(10906.): 0,\n",
       " tensor(8235.): 1,\n",
       " tensor(1631.): 1,\n",
       " tensor(5474.): 0,\n",
       " tensor(3945.): 1,\n",
       " tensor(5136.): 1,\n",
       " tensor(2612.): 1,\n",
       " tensor(9797.): 0,\n",
       " tensor(1951.): 0,\n",
       " tensor(3524.): 0,\n",
       " tensor(10413.): 0,\n",
       " tensor(4261.): 1,\n",
       " tensor(2109.): 1,\n",
       " tensor(1158.): 0,\n",
       " tensor(4198.): 0,\n",
       " tensor(1515.): 0,\n",
       " tensor(8093.): 0,\n",
       " tensor(500.): 1,\n",
       " tensor(4656.): 1,\n",
       " tensor(6261.): 0,\n",
       " tensor(1404.): 0,\n",
       " tensor(10872.): 1,\n",
       " tensor(1448.): 0,\n",
       " tensor(10556.): 0,\n",
       " tensor(5223.): 0,\n",
       " tensor(10432.): 0,\n",
       " tensor(6203.): 0,\n",
       " tensor(340.): 1,\n",
       " tensor(2736.): 0,\n",
       " tensor(5631.): 0,\n",
       " tensor(10084.): 0,\n",
       " tensor(8341.): 0,\n",
       " tensor(5802.): 0,\n",
       " tensor(3578.): 0,\n",
       " tensor(4967.): 0,\n",
       " tensor(8312.): 0,\n",
       " tensor(2570.): 1,\n",
       " tensor(8527.): 0,\n",
       " tensor(13.): 0,\n",
       " tensor(7118.): 1,\n",
       " tensor(7022.): 1,\n",
       " tensor(2499.): 0,\n",
       " tensor(1772.): 1,\n",
       " tensor(4619.): 1,\n",
       " tensor(9303.): 0,\n",
       " tensor(6912.): 0,\n",
       " tensor(550.): 0,\n",
       " tensor(6673.): 0,\n",
       " tensor(4643.): 0,\n",
       " tensor(5721.): 1,\n",
       " tensor(8041.): 1,\n",
       " tensor(10061.): 1,\n",
       " tensor(1764.): 0,\n",
       " tensor(8910.): 1,\n",
       " tensor(9246.): 0,\n",
       " tensor(5892.): 0,\n",
       " tensor(9923.): 0,\n",
       " tensor(7807.): 1,\n",
       " tensor(3112.): 0,\n",
       " tensor(9166.): 0,\n",
       " tensor(8726.): 0,\n",
       " tensor(4286.): 1,\n",
       " tensor(977.): 1,\n",
       " tensor(8135.): 0,\n",
       " tensor(5350.): 1,\n",
       " tensor(7327.): 0,\n",
       " tensor(1916.): 0,\n",
       " tensor(7261.): 0,\n",
       " tensor(6417.): 0,\n",
       " tensor(3766.): 1,\n",
       " tensor(477.): 1,\n",
       " tensor(5247.): 0,\n",
       " tensor(9216.): 0,\n",
       " tensor(2591.): 0,\n",
       " tensor(1351.): 1,\n",
       " tensor(2886.): 1,\n",
       " tensor(9706.): 0,\n",
       " tensor(7901.): 0,\n",
       " tensor(3427.): 1,\n",
       " tensor(5185.): 0,\n",
       " tensor(2130.): 0,\n",
       " tensor(48.): 0,\n",
       " tensor(8207.): 0,\n",
       " tensor(5113.): 1,\n",
       " tensor(4102.): 0,\n",
       " tensor(6343.): 1,\n",
       " tensor(9955.): 0,\n",
       " tensor(9014.): 0,\n",
       " tensor(6616.): 0,\n",
       " tensor(4974.): 1,\n",
       " tensor(9723.): 1,\n",
       " tensor(9150.): 0,\n",
       " tensor(7832.): 1,\n",
       " tensor(4418.): 1,\n",
       " tensor(4786.): 1,\n",
       " tensor(1081.): 1,\n",
       " tensor(8395.): 0,\n",
       " tensor(9589.): 0,\n",
       " tensor(10814.): 1,\n",
       " tensor(3286.): 0,\n",
       " tensor(2295.): 0,\n",
       " tensor(9256.): 1,\n",
       " tensor(9790.): 1,\n",
       " tensor(10702.): 0,\n",
       " tensor(164.): 0,\n",
       " tensor(271.): 1,\n",
       " tensor(7441.): 0,\n",
       " tensor(7500.): 1,\n",
       " tensor(4390.): 1,\n",
       " tensor(2079.): 1,\n",
       " tensor(2712.): 0,\n",
       " tensor(176.): 0,\n",
       " tensor(8566.): 0,\n",
       " tensor(4609.): 1,\n",
       " tensor(607.): 1,\n",
       " tensor(4954.): 0,\n",
       " tensor(2406.): 0,\n",
       " tensor(736.): 0,\n",
       " tensor(4331.): 1,\n",
       " tensor(3850.): 0,\n",
       " tensor(737.): 1,\n",
       " tensor(2711.): 0,\n",
       " tensor(9905.): 0,\n",
       " tensor(3790.): 0,\n",
       " tensor(2088.): 1,\n",
       " tensor(10595.): 0,\n",
       " tensor(9291.): 0,\n",
       " tensor(3298.): 1,\n",
       " tensor(6958.): 0,\n",
       " tensor(10659.): 0,\n",
       " tensor(9986.): 0,\n",
       " tensor(6950.): 0,\n",
       " tensor(4686.): 1,\n",
       " tensor(5294.): 0,\n",
       " tensor(5872.): 1,\n",
       " tensor(9645.): 0,\n",
       " tensor(10163.): 1,\n",
       " tensor(5120.): 0,\n",
       " tensor(2639.): 0,\n",
       " tensor(800.): 0,\n",
       " tensor(9362.): 1,\n",
       " tensor(3266.): 0,\n",
       " tensor(2118.): 0,\n",
       " tensor(6382.): 0,\n",
       " tensor(5302.): 1,\n",
       " tensor(5138.): 0,\n",
       " tensor(3571.): 1,\n",
       " tensor(8462.): 0,\n",
       " tensor(3434.): 0,\n",
       " tensor(3798.): 0,\n",
       " tensor(2797.): 1,\n",
       " tensor(263.): 0,\n",
       " tensor(7947.): 0,\n",
       " tensor(7600.): 0,\n",
       " tensor(9481.): 0,\n",
       " tensor(6168.): 0,\n",
       " tensor(1876.): 0,\n",
       " tensor(940.): 0,\n",
       " tensor(322.): 0,\n",
       " tensor(1146.): 1,\n",
       " tensor(7124.): 0,\n",
       " tensor(1092.): 1,\n",
       " tensor(1518.): 1,\n",
       " tensor(10779.): 0,\n",
       " tensor(3276.): 0,\n",
       " tensor(1743.): 0,\n",
       " tensor(10905.): 1,\n",
       " tensor(9298.): 1,\n",
       " tensor(9916.): 0,\n",
       " tensor(4764.): 0,\n",
       " tensor(9029.): 0,\n",
       " tensor(10311.): 1,\n",
       " tensor(1131.): 0,\n",
       " tensor(7699.): 1,\n",
       " tensor(7366.): 1,\n",
       " tensor(17.): 0,\n",
       " tensor(2631.): 0,\n",
       " tensor(8799.): 0,\n",
       " tensor(10509.): 0,\n",
       " tensor(2002.): 0,\n",
       " tensor(6281.): 1,\n",
       " tensor(7433.): 0,\n",
       " tensor(9423.): 0,\n",
       " tensor(4122.): 0,\n",
       " tensor(6721.): 1,\n",
       " tensor(7532.): 0,\n",
       " tensor(3595.): 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3d85601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  Target\n",
      "0       13       0\n",
      "1       17       0\n",
      "2       24       0\n",
      "3       48       0\n",
      "4       78       0\n",
      "..     ...     ...\n",
      "668  11092       0\n",
      "669  11133       1\n",
      "670  11148       0\n",
      "671  11181       0\n",
      "672  11187       0\n",
      "\n",
      "[673 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_dict = dis\n",
    "processed_dict = {key.int().item(): value for key, value in example_dict.items()}\n",
    "\n",
    "# Create DataFrame from the dictionary items.\n",
    "df = pd.DataFrame(list(processed_dict.items()), columns=[\"ID\", \"Target\"])\n",
    "\n",
    "# Sort the DataFrame by the 'ID' column.\n",
    "df = df.sort_values(by=\"ID\").reset_index(drop=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "083a0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "full_loader = get_dataloaders(train, lists, batch_size=3, test_split=0)[0]\n",
    "model.eval()\n",
    "all_predictionst = []\n",
    "# with torch.no_grad():\n",
    "for i in full_loader:\n",
    "\n",
    "    batch = [torch.stack(col).unsqueeze(0).to(device) for col in i]\n",
    "    out = model(batch)\n",
    "    pred = out>0.5\n",
    "    pred = pred.int().cpu().numpy()\n",
    "    all_predictionst.extend(pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6115812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(all_predictionst, columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6babb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          1\n",
       "4          0\n",
       "...      ...\n",
       "1562       0\n",
       "1563       0\n",
       "1564       0\n",
       "1565       0\n",
       "1566       0\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7da469f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552010210593491"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission['Target'] == train['Target']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32523e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['ID'], columns=['ID'])\n",
    "submission_df['Target'] = all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90db1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hem = pd.read_csv(r'submission (5).csv')\n",
    "hem = hem.sort_values(by=\"ID\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d0648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3fe84519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match accuracy: 87.37%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (submission_df['Target'] == hem['Target']).mean()\n",
    "print(f\"Match accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9da2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0507369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
